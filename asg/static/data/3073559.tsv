ref_title	ref_context	ref_entry	abstract	intro	ref_link	label	topic_word	topic_bigram	topic_trigram	description
Improving malware classification: Bridging the static/dynamic gap	[]	Blake Anderson, Curtis Storlie, and Terran Lane. 2012. Improving malware classification: Bridging the static/dynamic gap. Proceedings of 5th ACM Workshop on Security and Artificial Intelligence (AISec).	Malware classification systems have typically used some machine learning algorithm in conjunction with either static or dynamic features collected from the binary. Recently, more advanced malware has introduced mechanisms to avoid detection in these views by using obfuscation techniques to avoid static detection and execution-stalling techniques to avoid dynamic detection. In this paper we construct a classification framework that is able to incorporate both static and dynamic views into a unified framework in the hopes that, while a malicious executable can disguise itself in some views, disguising itself in every view while maintaining malicious intent will prove to be substantially more difficult. Our method uses kernels to place a similarity metric on each distinct view and then employs multiple kernel learning to find a weighted combination of the data sources which yields the best classification accuracy in a support vector machine classifier. Our approach opens up new avenues of malware research which will allow the research community to elegantly look at multiple facets of malware simultaneously, and which can easily be extended to integrate any new data sources that may become popular in the future.	I.5.2 <NO>: Classifier design and evaluation; K.6.5 <NO>: Invasive software (e.g., viruses, worms, Trojan horses	https://doi.org/10.1145/2381896.2381900	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Anderson, et al. [NO] constructs a classification framework that is able to incorporate both static and dynamic views into a unified framework in the hopes that, while a malicious executable can disguise itself in some views, disguising itself in every view while maintaining malicious intent will prove to be substantially more difficult. 
A survey on heuristic malware detection techniques	[]	Zahra Bazrafshan, Hashem Hashemi, Seyed Mehdi Hazrati Fard, and Ali Hamzeh. 2013. A survey on heuristic malware detection techniques. Proceedings of the 5th Conference on Information and Knowledge Technology (IKT).	Malware is a malicious code which is developed to harm a computer or network. The number of malwares is growing so fast and this amount of growth makes the computer security researchers invent new methods to protect computers and networks. There are three main methods used to malware detection: Signature based, Behavioral based and Heuristic ones. Signature based malware detection is the most common method used by commercial antiviruses but it can be used in the cases which are completely known and documented. Behavioral malware detection was introduced to cover deficiencies of signature based method. However, because of some shortcomings, the heuristic methods have been introduced. In this paper, we discuss the state of the art heuristic malware detection methods and briefly overview various features used in these methods such as API Calls, OpCodes, N-Grams etc. and discuss their advantages and disadvantages. Keywords-Malware Detection, Computer Security, API Call, NGram, OpCode, Control Flow Graph.	"Nowadays pattern matching is the most common method in malware detection, and signature based detection is the most popular method in this area <NO>. Signature is a unique feature for each file, something like a fingerprint of an executable. Signature based methods use the patterns extracted from various malwares to identify them and are more efficient and faster than any other methods. These signatures are often extracted with special sensitivity for being unique, so those detection methods that use this signature have small error rate. Where this small error rate is the main reason that most common commercial antiviruses use this technique <NO>.
These methods are unable to detect unknown malware variants and also requires high amount of manpower, time, and money to extract unique signatures. These are the main disadvantages of these methods. Also, inability to confront against the malwares that mutate their codes in each infection such as polymorphic and metamorphic one is another disadvantage. To tackle these challenges, research societies propose completely new malware detection family."	http://scholar.google.com/scholar?hl=en&q=Zahra+Bazrafshan%2C+Hashem+Hashemi%2C+Seyed+Mehdi+Hazrati+Fard%2C+and+Ali+Hamzeh.+2013.+A+survey+on+heuristic+malware+detection+techniques.+In+Proceedings+of+the+5th+Conference+on+Information+and+Knowledge+Technology+%28IKT%29.+10.1109%2FIKT.2013.6620049	1	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']	Bazrafshan, et al. [NO] discusses the state of the art heuristic malware detection methods and briefly overview various features used in these methods such as api calls, opcodes, n-grams etc. 
Web tap: Detecting covert web traffic	[]	Kevin Borders, and Atul Prakash. 2004. Web tap: Detecting covert web traffic. Proceedings of the 11th ACM Conference on Computer and Communications Security.	As network security is a growing concern, system administrators lock down their networks by closing inbound ports and only allowing outbound communication over selected protocols such as HTTP. Hackers, in turn, are forced to find ways to communicate with compromised workstations by tunneling through web requests. While several tools attempt to analyze inbound traffic for denial-of-service and other attacks on web servers, Web Tap’s focus is on detecting attempts to send significant amounts of information out via HTTP tunnels to rogue Web servers from within an otherwise firewalled network. A related goal of Web Tap is to help detect spyware programs, which often send out personal data to servers using HTTP transactions and may open up security holes in the network. Based on the analysis of HTTP traffic over a training period, we designed filters to help detect anomalies in outbound HTTP traffic using metrics such as request regularity, bandwidth usage, interrequest delay time, and transaction size. Subsequently, Web Tap was evaluated on several available HTTP covert tunneling programs as well as a test backdoor program, which creates a remote shell from outside the network to a protected machine using only outbound HTTP transactions. Web Tap’s filters detected all the tunneling programs tested after modest use. Web Tap also analyzed the activity of approximately thirty faculty and students who agreed to use it as a proxy server over a 40 day period. It successfully detected a significant number of spyware and aware programs. This paper presents the design of Web Tap, results from its evaluation, as well as potential limits to Web Tap’s capabilities.	"Network security has been an increasing concern for network administrators and executives alike. Consequently, Firewalls and proxy servers have become prevalent among high-security networks (and even private homes). Many networks require all traffic to the internet to go through an HTTP proxy server or mail server, allowing no direct access to the internal network. This makes the job of a hacker much more difficult than before, where direct access to network machines was available.
When a hacker attacks a network with no direct access to the internet, the first step is getting a user to access a malicious file or web site. This can be done effectively by e-mailing a Trojan horse program or a link to a page which exploits the browser <NO>. Once the machine is compromised, the next step is to establish a path of communication. Traditionally, this would be done by installing a backdoor program such as BackOrifice <NO>. The problem with using such programs on firewalled networks is that they listen for an incoming connection on a specific port. All incoming traffic, however, is blocked. This means that the only way to communicate with a compromised machine is to have it make a callback (outbound connection). Often, the only two ways out of the network are through a mail server or through a proxy server. Since e-mail is often more closely logged and filtered, the hacker may find outbound HTTP transactions to be the best avenue for communication with a compromised workstation.
Spyware is also a huge problem for both system administrators and users alike <NO>. Besides annoying users by popping up advertisements, spyware can leak information about a user’s behavior or even send data on the machine to outside servers. Spyware programs can also degrade system performance and take valuable time and effort to remove. In addition to these lesser threats, Security holes have been found in Gator and eZula (two popular spyware programs) that would allow a hacker to execute arbitrary code on a target machine <NO>.
Web Tap is a network-level anomaly detection system that takes advantage of legitimate web request patterns to detect covert communication, backdoors, and spyware activity that is tunneled through outbound HTTP connections. We note that, unlike the previous work on securing web servers (e.g., <NO>), Web Tap’s focus is on analyzing outbound HTTP traffic from protected network machines to outside web servers, rather than guarding web servers against hostile attacks. The goal is to make it more difficult for hackers or malicious users to run Trojan and HTTP tunnel programs within an organization that leak information to the outside. Web Tap is designed for deployment at an organization’s HTTP proxy server (either passively or actively) to help detect anomalies in outbound traffic.
To evaluate Web Tap, we used it to look at web traffic from 30 clients over a 40-day period as well as traffic from known Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. CCS’04, October 25-29, 2004, Washington, DC, USA. Copyright 2004 ACM 1-58113-961-6/04/0010…$5.00.
HTTP tunneling programs. We were successful at detecting different types of spyware and adware as well as many data mining and advertisement servers. During the 40 days of observation, Web Tap generated alerts for adware clients such as Weatherbug, Kazaa, Lycos search bar, Google search bar, and Gator. It also was able to find programs which may be unwanted in a workplace environment such as iTunes, BitTorrent, and AIM Express. In addition to non-browser clients, Web Tap detected data mining and advertisement sites such as coremetrics.com, ru4.com abetterinternet.com, and doubleclick.net. Two of the three known HTTP tunneling programs tested, Wsh <NO> and Firepass <NO>, immediately caused Web Tap to raise an alert. The third HTTP tunnel, Hopster <NO>, was detected an hour and twenty minutes after it began running. A custom HTTP tunnel that we designed, which does a better job of mimicking legitimate browser requests, was detected within seven hours. When the backdoor was actively used to transfer files, it was detected almost immediately.
The rest of the paper is presented as follows. Section 2 discusses related work. Section 3 gives a threat model. Section 4 presents the design of filtering methods, based on measurements during the one week training phase. Section 5 provides an evaluation of Web Tap for an extended period after the evaluation phase. Section 6 talks about vulnerabilities in Web Tap filters. Section 7 outlines future work and Section 8 concludes."	https://doi.org/10.1145/1030083.1030100	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Borders, et al. [NO] designs filters to help detect anomalies in outbound http traffic using metrics such as request regularity, bandwidth usage, interrequest delay time, and transaction size. 
Polyglot: Automatic extraction of protocol message format using dynamic binary analysis	[', Polyglot <NO> and Panorama <NO>), Siren <NO> and oth-']	Juan Caballero, Heng Yin, Zhenkai Liang, and Dawn Song. 2007. Polyglot: Automatic extraction of protocol message format using dynamic binary analysis. Proceedings of the 14th ACM Conference on Computer and Communications Security (CCS).	Protocol reverse engineering, the process of extracting the application-level protocol used by an implementation, without access to the protocol specification, is important for many network security applications. Recent work [17] has proposed protocol reverse engineering by using clustering on network traces. That kind of approach is limited by the lack of semantic information on network traces. In this paper we propose a new approach using program binaries. Our approach, shadowing, uses dynamic analysis and is based on a unique intuition—the way that an implementation of the protocol processes the received application data reveals a wealth of information about the protocol message format. We have implemented our approach in a system called Polyglot and evaluated it extensively using real-world implementations of five different protocols: DNS, HTTP, IRC, Samba and ICQ. We compare our results with the manually crafted message format, included in Wireshark, one of the state-ofthe-art protocol analyzers. The differences we find are small and usually due to different implementations handling fields in different ways. Finding such differences between implementations is an added benefit, as they are important for problems such as fingerprint generation, fuzzing, and error detection.	Security	https://doi.org/10.1145/1315245.1315286	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Caballero, et al. [NO] proposes a new approach using program binaries. 
Mining specifications of malicious behavior	['So far, several data mining and machine-learning approaches have been used in malware detection <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'tion <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'In order to overcome the disadvantages of the widely-used signature-based malware detection method, data mining and machine learning approaches are proposed for malware detection <NO>.', 'Recent advances in malware analysis <NO> show', '<NO> propose a technique by comparing the execution behavior of a known malware against the execution behaviors of a set of benign programs.', 'Principal dynamic techniques include virtual machine inspection <NO>, function call monitoring <NO>, <NO>, dynamic binary instrumentation <NO> and information flow tracking <NO>.', 'introspection <NO>, information flow tracking <NO>, <NO>, instruction trace monitoring <NO>–<NO>.', 'Capturing information flow in dependence graphs: Existing techniques for constructing dependence graphs from programs provide only data-flow (and sometimes controlflow) dependencies between operations <NO>, <NO>, <NO>.']	Mihai Christodorescu, Somesh Jha, and Christopher Kruegel. 2007. Mining specifications of malicious behavior. Proceedings of ESEC/FSE.	Malware detectors require a specification of malicious behavior. Typically, these specifications are manually constructed by investigating known malware. We present an automatic technique to overcome this laborious manual process. Our technique derives such a specification by comparing the execution behavior of a known malware against the execution behaviors of a set of benign programs. In other words, we mine the malicious behavior present in a known malware that is not present in a set of benign programs. The output of our algorithm can be used by malware detectors to detect malware variants. Since our algorithm provides a succinct description of malicious behavior present in a malware, it can also be used by security analysts for understanding the malware. We have implemented a prototype based on our algorithm and tested it on several malware programs. Experimental results obtained from our prototype indicate that our algorithm is effective in extracting malicious behaviors that can be used to detect malware variants.	"Malicious software (malware) is code that achieves the harmful intent of an attacker. Typical examples include viruses, worms, trojans, and spyware. Although the history of malware reaches back more than two decades, the advent of large-scale computer worm epidemics and waves of email viruses have elevated the problem to a major security threat. Recently, this threat has also acquired an economic dimension as attackers benefit financially from compromised machines (e.g., by selling hosts as email relays to spammers).
Historically, detection tools such as virus scanners have performed poorly, particularly when facing previously unknown malware programs or novel variants of existing ones. The fundamental cause is the disconnect between the malware specification used for detection and the actual malware behavior (which is the attacker’s goal). Certain malicious behavior desired by an attacker (e.g., virus self replication through mass-mailing) can be realized in many different ways. However, current detectors focus only on the specific characteristics of individual malware instances, e.g., on the presence of particular instruction sequences. Therefore, they fail to detect different manifestations of the same malicious behavior. Attackers are quick to exploit this weakness by using program obfuscation techniques such as polymorphism and metamorphism <NO>. Recent research results have highlighted how shortcomings in both network-based and host-based detection techniques can be effectively exploited by attackers to evade detection <NO>.
Advanced detection techniques such as semantics-aware malware detection <NO> and malicious-code model checking <NO> counter the obfuscation techniques of attackers by using higher-level specifications of malicious behavior. Instead of focusing on individual characteristics of particular malware instances, these detectors specify general behavior exhibited by an entire family of malicious code. Examples of such specifications include self-unpacking and selfpropagation via email. The power of these approaches resides in the use of high-level specifications that abstract details specific to a malware instance. Thus, obfuscation transformations, which preserve the behavior of the malware but may change its form, are no longer effective techniques for evading detection.
Unfortunately, the high-level specifications of malicious behavior used by these advanced malware detectors are currently manually developed. Creating specifications manually is a time-consuming task that requires expert knowledge, which reduces the appeal and deployment of these new detection techniques. To address this limitation, this paper
introduces a technique to automatically derive specifications of malicious behavior from a given malware sample. Such a specification can then be used by a malware detector, allowing for the creation of an end-to-end tool-chain to update malware detectors when a new malware appears. Since our technique provides a succinct description of the malicious intent of a malware, it can also be used by security analysts for malware understanding.
We cast malicious-specification mining as the problem of finding differences between a malware sample and a set of benign programs. This approach supports the requirement that the specification of malicious behavior must capture aspects that are specific to the malware and absent from any benign programs. The software-engineering research community has put a lot of effort in analyzing commonalities and differences between programs and many techniques for clone detection <NO> and program differencing <NO> have been proposed. The differencing techniques are closest to our goal of mining specifications of malicious behavior, but they fall short because they generally require access to source code and because they produce differences between low-level elements of the program (e.g., individual statements) or between structural elements (e.g., type hierarchy, procedures). Since we do not have the malware source code and since the malware writer controls the structure of the program, mining malicious specifications requires a new approach.
Our mining technique takes into account an adversarial setting in which the malware writer tries to make his software hard to analyze and detect. We define a new graph representation of program behavior and a mining algorithm that constructs a malicious specification. The representation explicitly captures the system calls made by the program and summarizes all other program code, because system calls are the primary interaction with the operating system. Our algorithm infers the system-call graphs from execution traces, then derives a specification by computing the minimal differences between the system-call graphs of malicious and benign programs.
This paper makes the following contributions:
• A language for specifying malicious behavior in terms of dependences between system calls (Section 3).
• An algorithm, called MiniMal1 that mines specifications of malicious behavior from dependence graphs (Section 4).
• An experimental evaluation that shows that specifications extracted MiniMal are qualitatively equivalent to those manually developed by Symantec’s expert virus analysts and can be used with a malware detector to identify subsequent malware variants (Section 5)."	https://doi.org/10.1145/1287624.1287628	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Christodorescu, et al. [NO] presents an automatic technique to overcome this laborious manual process. 
On deriving unknown vulnerabilities from zero-day polymorphic and metamorphic worm exploits	['Although signature detection techniques are widely used, they are not effective against zero-day attacks (new malicious code), polymorphic attacks (different encryptions of the same binary), or metamorphic attacks (different code for the same functionality) <NO>.']	Jedidiah R. Crandall, Zhendong Su, S. Felix Wu, and Frederic T. Chong. 2005. On deriving unknown vulnerabilities from zero-day polymorphic and metamorphic worm exploits. Proceedings of the 12th ACM Conference on Computer and Communications Security (CCS).	Vulnerabilities that allow worms to hijack the control flow of each host that they spread to are typically discovered months before the worm outbreak, but are also typically discovered by third party researchers. A determined attacker could discover vulnerabilities as easily and create zero-day worms for vulnerabilities unknown to network defenses. It is important for an analysis tool to be able to generalize from a new exploit observed and derive protection for the vulnerability. Many researchers have observed that certain predicates of the exploit vector must be present for the exploit to work and that therefore these predicates place a limit on the amount of polymorphism and metamorphism available to the attacker. We formalize this idea and subject it to quantitative analysis with a symbolic execution tool called DACODA. Using DACODA we provide an empirical analysis of 14 exploits (seven of them actual worms or attacks from the Internet, caught by Minos with no prior knowledge of the vulnerabilities and no false positives observed over a period of six months) for four operating systems. Evaluation of our results in the light of these two models leads us to conclude that 1) single contiguous byte string signatures are not effective for content filtering, and tokenbased byte string signatures composed of smaller substrings are only semantically rich enough to be effective for content filtering if the vulnerability lies in a part of a protocol that is not commonly used, and that 2) practical exploit analysis must account for multiple processes, multithreading, and kernel processing of network data necessitating a focus on primitives instead of vulnerabilities. 	Zero-day worms that exploit unknown vulnerabilities are a very real threat. Typically vulnerabilities are discovered by “white hat” hackers using fuzz testing <NO>, reverse engineering, or source code analysis and then the software vendors are notified. The same techniques for discovering these vulnerabilities could be as easily employed by “black hat” hackers, especially now that computer criminals are increasingly seeking profit rather than mischief. None of the 14 exploits analyzed in this paper are for vulnerabilities discovered by the vendors of the software being attacked. A vulnerability gives the attacker an important primitive (a primitive is an ability the attacker has, such as the ability to write an arbitrary value to an arbitrary location in a process’ address space), and then the attacker can build different exploits using this primitive. The host contains information about the vulnerability and primitive that cannot be determined from network traffic alone. It is impossible to generalize how the attack might morph in the future without this information. In order to respond effectively during an incipient worm outbreak, an automated analysis tool must be able to generalize one instance of an exploit and derive protection for the exploited vulnerability, since a worm can build multiple exploits for the same vulnerability from primitives.	https://doi.org/10.1145/1102120.1102152	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	R. et al. [NO] formalizes this idea and subject it to quantitative analysis with a symbolic execution tool called dacoda. 
Adversarial classification	[]	Nilesh Dalvi, Pedro Domingos, Mausam, Sumit Sanghai, and Deepak Verma. 2004. Adversarial classification. Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 99–108.	Essentially all data mining algorithms assume that the datagenerating process is independent of the data miner’s activities. However, in many domains, including spam detection, intrusion detection, fraud detection, surveillance and counter-terrorism, this is far from the case: the data is actively manipulated by an adversary seeking to make the classifier produce false negatives. In these domains, the performance of a classifier can degrade rapidly after it is deployed, as the adversary learns to defeat it. Currently the only solution to this is repeated, manual, ad hoc reconstruction of the classifier. In this paper we develop a formal framework and algorithms for this problem. We view classification as a game between the classifier and the adversary, and produce a classifier that is optimal given the adversary’s optimal strategy. Experiments in a spam detection domain show that this approach can greatly outperform a classifier learned in the standard way, and (within the parameters of the problem) automatically adapt the classifier to the adversary’s evolving manipulations.	"Many major applications of KDD share a characteristic that has so far received little attention from the research community: the presence of an adversary actively manipulating the data to defeat the data miner. In these domains, deployment of a KDD system causes the data to change so as to make the system ineffective. For example, in the domain of email spam detection, standard classifiers like naive Bayes were initially quite successful (e.g., <NO>). Unfortunately, spammers soon learned to fool them by inserting “non-spam” words into emails, breaking up “spam” ones with spurious punctuation, etc. Once spam filters were modified to detect these tricks, spammers started using new ones <NO>. Effectively, spammers and data miners are engaged in a never-ending game where data miners continually come up with new ways to detect spam, and spammers continually come up with new ways to avoid detection.
Similar arms races are found in many other domains: computer intrusion detection, where new attacks circumvent the defenses put in place against old ones <NO>; fraud detection, where perpetrators learn to avoid the actions that previously gave them away <NO>; counter-terrorism, where terrorists disguise their identity and activities in ever-shifting ways <NO>; aerial surveillance, where targets are camouflaged with increasing sophistication <NO>; comparison shopping, where merchants continually change their Web sites to avoid wrapping by shopbots <NO>; file sharing, where media companies try to detect and frustrate illegal copying, and users find ways to circumvent the obstacles <NO>; Web search, where webmasters manipulate pages and links to inflate their rankings, and search engines reengineer their ranking functions to deflate them back again <NO>; etc.
In many of these domains, researchers have noted the presence of adaptive adversaries and the need to take them into account (e.g., <NO>), but to our knowledge no systematic approach for this has so far been developed. The result is that the performance of deployed KDD systems in adversarial domains can degrade rapidly over time, and much human effort and cost is incurred in repeatedly bringing the systems back up to the desired performance level. This paper proposes a first step towards automating this process. While complete automation will never be possible, we believe our approach and its future extensions have the potential to significantly improve the speed and cost-effectiveness of keeping KDD systems up to date with their adversaries.
Notice that adversarial problems cannot simply be solved by learners that account for concept drift (e.g., <NO>): while these learners allow the data-generating process to change
over time, they do not allow this change to be a function of the classifier itself.
We first formalize the problem as a game between a costsensitive classifier and a cost-sensitive adversary (Section 2). Focusing on the naive Bayes classifier (Section 3), we describe the optimal strategy for the adversary against a standard (adversary-unaware) classifier (Section 4), and the optimal strategy for a classifier playing against this strategy (Section 5). We provide efficient algorithms for computing or approximating these strategies. Experiments in a spam detection domain illustrate the sometimes very large utility gains that an adversary-aware classifier can yield, and its ability to co-evolve with the adversary (Section 6). We conclude with a discussion of future research directions (Section 7)."	https://doi.org/10.1145/2381896.2381900	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Dalvi, et al. [NO] develops a formal framework and algorithms for this problem. 
Semantics-based online malware detection: Towards efficient real-time protection against malware	[]	Sanjeev Das, Yang Liu, Wei Zhang, and Mahintham Chandramohan. 2016. Semantics-based online malware detection: Towards efficient real-time protection against malware. IEEE Transactions on Information Forensics and Security 11, 2 (2016), 289–302.	Recently, malware has increasingly become a critical threat to embedded systems, while the conventional software solutions, such as antivirus and patches, have not been so successful in defending the ever-evolving and advanced malicious programs. In this paper, we propose a hardwareenhanced architecture, GuardOL, to perform online malware detection. GuardOL is a combined approach using processor and field-programmable gate array (FPGA). Our approach aims to capture the malicious behavior (i.e., highlevel semantics) of malware. To this end, we first propose the frequency-centric model for feature construction using system call patterns of known malware and benign samples. We then develop a machine learning approach (using multilayer perceptron) in FPGA to train classifier using these features. At runtime, the trained classifier is used to classify the unknown samples as malware or benign, with early prediction. The experimental results show that our solution can achieve high classification accuracy, fast detection, low power consumption, and flexibility for easy functionality upgrade to adapt to new malware samples. One of the main advantages of our design is the support of early prediction—detecting 46% of malware within first 30% of their execution, while 97% of the samples at 100% of their execution, with <3% false positives.	Since the early days of computing, malware has evolved from the simple exploits into the complex ones in the forms of — virus, worm, trojan, adware, spyware, backdoor, flooder, botnet, rootkit and bootkits <NO>. Over the years, the motivation of malware authors has changed from exploits-for-fun to money-making business. With the arms race between security professionals and malware writers, the present day malware has highly evolved, which uses sophisticated techniques to exploit the vulnerabilities. Malware uses several channels to penetrate in the system, e.g., phising emails, usb, memory card, corrupt downloaded files, click on links, repackaged into normal applications, browser utilities, abusing application stores or exploiting old vulnerabilities <NO>. Our work is based on the behavior of the malware in the host system, i.e., after they have penetrated in the system.	http://scholar.google.com/scholar?hl=en&q=Sanjeev+Das%2C+Yang+Liu%2C+Wei+Zhang%2C+and+Mahintham+Chandramohan.+2016.+Semantics-based+online+malware+detection%3A+Towards+efficient+real-time+protection+against+malware.+IEEE+Transactions+on+Information+Forensics+and+Security+11%2C+2+%282016%29%2C+289%2D%2D302.+10.1109%2FTIFS.2015.2491300	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Das, et al. [NO] proposes a hardwareenhanced architecture, guardol, to perform online malware detection. 
Ether: Malware analysis via hardware virtualization extensions	['We choose the Intel Pin program <NO> because it allowed us to collect both instructions and system calls simultaneously, but it does not make an effort to be a transparent tracing tool like the Ether framework <NO>.', 'introspection <NO>, information flow tracking <NO>, <NO>, instruction trace monitoring <NO>–<NO>.']	Artem Dinaburg, Paul Royal, Monirul Sharif, and Wenke Lee. 2008. Ether: Malware analysis via hardware virtualization extensions. Proceedings of the 15th ACM Conference on Computer and Communications Security (CCS).	Malware has become the centerpiece of most security threats on the Internet. Malware analysis is an essential technology that extracts the runtime behavior of malware, and supplies signatures to detection systems and provides evidence for recovery and cleanup. The focal point in the malware analysis battle is how to detect versus how to hide a malware analyzer from malware during runtime. State-of-the-art analyzers reside in or emulate part of the guest operating system and its underlying hardware, making them easy to detect and evade. In this paper, we propose a transparent and external approach to malware analysis, which is motivated by the intuition that for a malware analyzer to be transparent, it must not induce any side-effects that are unconditionally detectable by malware. Our analyzer, Ether, is based on a novel application of hardware virtualization extensions such as Intel VT, and resides completely outside of the target OS environment. Thus, there are no in-guest software components vulnerable to detection, and there are no shortcomings that arise from incomplete or inaccurate system emulation. Our experiments are based on our study of obfuscation techniques used to create 25,000 recent malware samples. The results show that Ether remains transparent and defeats the obfuscation tools that evade existing approaches.	"Malware–the increasingly common vehicle by which criminal organizations facilitate online crime–has become an artifact whose use intersects multiple major security threats (e.g., botnets) faced by information security practitioners. Given the financially motivated nature of these threats, methods of recovery now mandate more than just remediation: knowing what occurred after an asset became compromised is as valuable as knowing it was compromised. Concisely, independent of simple detection, there exists a pronounced need to understand the intentions or runtime behavior of modern malware.
Recent advances in malware analysis <NO> show promise in understanding modern malware, but before these and other approaches can be used to determine what a malware instance does or might do, the runtime behavior of that instance and/or an unobstructed view of its code must be obtained. However, malware authors are incentivized to complicate attempts at understanding the internal workings of their creations. Therefore, modern malware contain a myriad of anti-debugging, anti-instrumentation, and anti-VM techniques to stymie attempts at runtime observation <NO>. Similarly, techniques that use a malware instance’s static code model are challenged by runtime-generated code, which often requires execution to discover.
In the obfuscation/deobfuscation game played between attackers and defenders, numerous anti-evasion techniques have been applied in the creation of robust in-guest API call tracers and automated deobfuscation tools <NO>. More recent frameworks <NO> and their discrete components <NO> attempt to offer or mimic a level of transparency analogous to that of a non-instrumented OS running on physical hardware. However, given that nearly all of these approaches reside in or emulate part of the guest OS or its underlying hardware, little effort is required by a knowledgeable adversary to detect their existence and evade <NO>.
In this paper we present a transparent, external approach to malware analysis. Our approach is motivated by the intuition that for a malware analyzer to be transparent, it must not induce any side-effects that are unconditionally detectable by its observation target. In formalizing this intuition, we model the structural properties and execution semantics of modern programs to derive the requirements for transparent malware analysis. An analyzer that satisfies these transparency requirements can obtain an execution trace of a program identical to that if it were run in an environment with no analyzer present. Approaches unable to fulfill these requirements are vulnerable to one or more de-
tection attacks–categorical, formal abstractions of detection techniques employed by modern malware.
Creating a transparent malware analyzer required us to diverge from existing approaches that employ in-guest components, API virtualization or partial or full system emulation, because none of these implementations satisfy all the transparency requirements. Based on novel application of hardware virtualization extensions such as Intel VT <NO>, our analyzer–called Ether–resides completely outside of the target OS environment– there are no in-guest software components vulnerable to detection or attack. Additionally, in contrast to other external approaches, the hardware-assisted nature of our approach implicitly avoids many shortcomings that arise from incomplete or inaccurate system emulation.
To demonstrate the efficacy of our approach we tested Ether with other academic and commercial approaches. Our testing included the analysis of specific in-the-wild malware instances that attempt to detect instrumentation and/or a virtual environment. In addition, we also surveyed over 25,000 recent malware samples to identify the distribution of obfuscation tools used in their creation; this knowledge was then used to create a synthetic sample set that represents the majority of the original corpus. The results of testing (presented in Section 5) show that Ether is able to remain transparent and defeat a large percentage of the obfuscation tools that evade existing approaches.
Our work represents the following contributions:
• A formal framework for describing program execution and analyzing the requirements for transparent malware analysis.
• Implementation of Ether, an external, transparent malware analyzer that operates using hardware virtualization extensions to offer both fine- (single instruction) and coarse- (system call) granularity tracing. To motivate the use of our approach by the information security community, the GPL’ed source code for Ether is available for download at http://ether.gtisc.gatech.edu.
• Broad-scale evaluation of current approaches using a proxy set of samples representing the majority of a recent, large malware corpus. Copies of discrete samples referenced in this paper and the 25,000 malware sample corpus used for our survey are available to any academic or industry professional at an accredited organization.
The remainder of this paper is organized as follows. Section 2 describes related work. Section 3 presents our model for programs and their execution, formal requirements for transparency, and abstract representations of failures in transparency that lead to detection attacks. Section 4 describes Ether’s design and implementation, including an in-depth explanation of how hardware virtualization extensions are leveraged. Section 5 details the experiment selection process and how experimentation was performed, and provides an analysis of the results. Finally, Section 6 briefly describes future work and provides some concluding remarks."	https://doi.org/10.1145/1455770.1455779	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Dinaburg, et al. [NO] proposes a transparent and external approach to malware analysis, which is motivated by the intuition that for a malware analyzer to be transparent, it must not induce any side-effects that are unconditionally detectable by malware. 
A survey on automated dynamic malware-analysis techniques and tools	['Since the early days of computing, malware has evolved from the simple exploits into the complex ones in the forms of — virus, worm, trojan, adware, spyware, backdoor, flooder, botnet, rootkit and bootkits <NO>.', 'Traditionally, the two major approaches for malware detection can be roughly split based on the approach that is used to analyze the malware, either static and dynamic analysis (see review <NO>).', 'Machine learning has been applied to malware detection at least since <NO>, with numerous approaches since (see reviews <NO>).']	Manuel Egele, Theodoor Scholte, Engin Kirda, and Christopher Kruegel. 2012. A survey on automated dynamic malware-analysis techniques and tools. ACM Computing Surveys (CSUR) 44, 2 (2012), 6.	Anti-virus vendors are confronted with a multitude of potentially malicious samples today. Receiving thousands of new samples every day is not uncommon. The signatures that detect confirmed malicious threats are mainly still created manually, so it is important to discriminate between samples that pose a new unknown threat and those that are mere variants of known malware. This survey article provides an overview of techniques based on dynamic analysis that are used to analyze potentially malicious samples. It also covers analysis programs that employ these techniques to assist human analysts in assessing, in a timely and appropriate manner, whether a given sample deserves closer manual inspection due to its unknown malicious behavior.	"The Internet has become an essential part of daily life as more and more people use services that are offered on the Internet. The Internet has evolved from a basic communication network to an interconnected set of information sources enabling, new forms of (social) interactions and marketplaces for the sale of products and services among other things. Online banking or advertising are examples of the commercial aspects of the Internet. Just as in the physical world, there are people on the Internet with malevolent intents, who strive to enrich themselves by taking advantage of legitimate users whenever money is involved. Malware (i.e., software of malicious intent) helps these people accomplish their goals.
To protect legitimate users from these threats, security vendors offer tools that aim to identify malicious software components. Typically, these tools apply some sort of signature matching process to identify known threats. This technique requires the
This work has been supported by the European Commission through project FP7-ICT-216026-WOMBAT, by FIT-IT through the SECoverer project, and by Secure Business Austria. Corresponding author’s address: M. Egele, Automation Systems Group (E183-1), Vienna University of Technology, Treitlstr. 1, 1040 Vienna, Austria; email: manuel@seclab.tuwien.ac.at. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org. c© 2012 ACM 0360-0300/2012/02-ART6 $10.00 DOI 10.1145/2089125.2089126 http://doi.acm.org/10.1145/2089125.2089126
ACM Computing Surveys, Vol. 44, No. 2, Article 6, Publication date: February 2012.
vendor to provide a database of signatures which are then compared against potential threats. Once the security vendor obtains a sample of a new potential threat to study, the first step is for a human analyst to determine whether this (so far unknown) sample poses a threat to users by analyzing the sample. If the sample poses a threat, the analyst attempts to find a pattern that allows her to identify this sample (i.e., the signature). This pattern should be generic enough to also match with variants of the same threat, but not falsely match on legitimate content. The analysis of malware and the successive construction of signatures by human analysts is time-consuming and error-prone. It is also trivial for malware authors to automatically generate a multitude of different malicious samples derived from a single malware instance. It is not extraordinary for an anti-virus vendor to receive thousands of unknown samples per day. Symantec <NO> (averaging 4,300 per day) as well as McAfee <NO> (averaging 12,300 per day) report receiving over 1.6M new samples in 2008. This substantial quantity requires an automated approach to quickly differentiating between samples that deserve closer (manual) analysis and those that are a variation of an already known threats. This automatic analysis can be performed in two ways. Dynamic analysis refers to techniques that execute a sample and verify the actions this sample performs in practice, while static analysis performs its task without actually executing the sample.
This article focuses on the techniques that can be applied to analyze potential threats and discriminate samples that are mere variations of already known threats. In addition, it presents the currently available tools and their underlying approaches to performing automated dynamic analysis on potentially malicious software."	https://doi.org/10.1145/2089125.2089126	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Egele, et al. [NO] article provides an overview of techniques based on dynamic analysis that are used to analyze potentially malicious samples. 
Synthesizing near-optimal malware specifications from suspicious behaviors	[]	Matt Fredrikson, Somesh Jha, Mihai Christodorescu, Reiner Sailer, and Xifeng Yan. 2010. Synthesizing near-optimal malware specifications from suspicious behaviors. Proceedings of IEEE Symposium on Security and Privacy.	Fueled by an emerging underground economy, malware authors are exploiting vulnerabilities at an alarming rate. To make matters worse, obfuscation tools are commonly available, and much of the malware is open source, leading to a huge number of variants. Behavior-based detection techniques are a promising solution to this growing problem. However, these detectors require precise specifications of malicious behavior that do not result in an excessive number of false alarms. In this paper, we present an automatic technique for extracting optimally discriminative specifications, which uniquely identify a class of programs. Such a discriminative specification can be used by a behavior-based malware detector. Our technique, based on graph mining and concept analysis, scales to large classes of programs due to probabilistic sampling of the specification space. Our implementation, called HOLMES, can synthesize discriminative specifications that accurately distinguish between programs, sustaining an 86% detection rate on new, unknown malware, with 0 false positives, in contrast with 55% for commercial signature-based antivirus (AV) and 62-64% for behavior-based AV (commercial or research).	"The behavior of a program can be thought of as its effect on the state and environment of the system on which it executes. Most malware relies on system calls to deliver a malicious payload, so reasoning about behavior in terms of the system calls made by a program allows us to succinctly and precisely capture the intent of the malware author, while ignoring many implementation-specific artifacts. Using this representation, we wish to derive a behavioral specification that is descriptive of a given set of programs (the positive set of programs) but does not describe any program in a second set (the negative set of programs). In the malware detection case, the positive set consists of malicious programs and the negative set consists of benign programs, and the goal is to construct a specification that is characteristic of the malicious programs but not of the benign programs.
For an arbitrarily chosen positive set of programs one is unlikely to find a single behavior common to all of them; if there is one such common behavior, it is likely also present in the programs from the negative set. Thus, we need to partition the positive set into subsets of similar programs, such that programs in the same subset share many behaviors. This leads us to the high-level workflow of our technique, which is presented in 1 and proceeds as follows:
I. The positive set of programs is divided into disjoint subsets of behaviorally similar programs. This can be performed manually, or using existing malware clustering techniques <NO>, <NO>.
II. Using existing techniques for dependence-graph construction <NO>, a graph is constructed for each malware and benign application to represent its behavior.
III. The significant behaviors specific to each positive subset are mined. (III)
A significant behavior is a sequence of operations that distinguishes the programs in a positive subset from
all of the programs in the negative subset. We use structural leap mining <NO> to identify multiple distinct graphs that are present in the dependence graphs of the positive subset and absent from the dependence graphs of the negative set.
IV. The significant behaviors mined from each positive subset are combined to obtain a discriminative specification for the whole positive set. (IV)
Two significant behaviors can be combined either by merging them into one significant behavior that is more general, or by taking the union of the two behaviors. We use concept analysis to identify the behaviors that can be combined with little or no increase in the coverage rate of the negative set, while maintaining the coverage rate of the positive set. As there are exponentially many ways of combining behaviors, we use probabilistic sampling to approximate the optimal solution in an efficient manner."	https://doi.org/10.1109/SP.2010.11	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Fredrikson, et al. [NO] presents an automatic technique for extracting optimally discriminative specifications, which uniquely identify a class of programs. 
The WEKA data mining software: An update	['The tests and experiments were conducted using Weka <NO> 3.', 'For classification, we use the Weka machine learning open-source package <NO>.', 'WEKA tool <NO> for the offline evaluation of machine learning classifier.', '5 decision tree (J48), naive bayes (NB), logistic regression (LR), support vector machine (SVM) using LibSVM, sequential minimal optimization (SMO), RIPPER rule learner (JRIP) and multilayer perceptron (MLP) <NO>.']	Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: An update. ACM SIGKDD Explorations Newsletter (2009).	More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on SourceForge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.	"The WEKA project aims to provide a comprehensive collection of machine learning algorithms and data preprocessing tools to researchers and practitioners alike. It allows users to quickly try out and compare different machine learning methods on new data sets. Its modular, extensible architecture allows sophisticated data mining processes to be built up from the wide collection of base learning algorithms and tools provided. Extending the toolkit is easy thanks to a simple API, plugin mechanisms and facilities that automate the integration of new learning algorithms with WEKA’s graphical user interfaces.
The workbench includes algorithms for regression, classification, clustering, association rule mining and attribute selection. Preliminary exploration of data is well catered for by data visualization facilities and many preprocessing tools. These, when combined with statistical evaluation of learning schemes and visualization of the results of learning, supports process models of data mining such as CRISP-DM <NO>."	https://doi.org/10.1145/1656274.1656278	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Hall, et al. [NO] provides an introduction to the weka workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (weka 3.4) released in 2003. 
A feature selection and evaluation scheme for computer virus detection	['<NO> used intra-family and inter-family support for n-grams for feature selection.', 'N-grams Static Hybrid <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO> Misuse <NO>']	Olivier Henchiri, and Nathalie Japkowicz. 2006. A feature selection and evaluation scheme for computer virus detection. Proceedings of the 6th International Conference on Data Mining.	Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are overfitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.	"Current research applying data mining to virus detection strives to automate the search for features used in classification. This process has been tackled from two different angles: extracting optimal signatures from a dataset of viruses, and discovering more general features for use in a complex classification scheme.
Extracting virus signatures is not a new problem. Kephart et al. <NO> developed a popular extraction method for virus signatures, by infecting a large number of files with a given virus and then harvesting for constant regions of 12 to 36 bytes. Then, from the considerable number of signatures collected, the ones with lowest predicted false positive rates were selected. While this method make it possible to extract signatures quickly and without the help of an expert, the authors concede that the algorithm fails for viruses that are moderately polymorphic.
Some detection methods utilize a variety of features, such as Win32 dll file calls, ASCII strings and byte sequences contained in the binary files. In an early heuristic approach <NO>, features such as duplicated UNIX system calls and files targeted by the program for writing purposes were used to detect malicious executables. In a machine learning method developed by Matthew Schultz et al. <NO>, ASCII strings and bytes sequences yielded good results. However, despite the byte sequences having a fixed length of 16, the feature space was very large, such that their dataset had to be split into partitions and different classifiers trained separately on each of them. Research in non signature-based heuristics has shown that sequences as short as 4 bytes can be used to detect unseen virus instances successfully <NO>. However, as was found in <NO>, the list of candidate features extracted from a small dataset can contain tens of thousands of sequences.
Finally, many viruses are considered to belong to common virus families, based on the similarities in structure, code or method of infection that they share <NO>. This classification is crucial to properly evaluating the effectiveness of a virus detection system. The first occurrence of a new kind of virus is typically the most devastating, as virus scanners are often incapable of detecting it. Then a host of variants typically emerge soon after the initial outbreak, albeit with less damaging consequences. Our method uses a priori knowledge of virus families, and evaluates the ability of our classifier to detect instances of a family without having been trained on any other instance from that same family."	https://doi.org/10.1109/ICDM.2006.4	1	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']	Henchiri, et al. [NO] presents a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. 
A feature selection and evaluation scheme for computer virus detection	['<NO> used intra-family and inter-family support for n-grams for feature selection.', 'N-grams Static Hybrid <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO> Misuse <NO>']	Olivier Henchiri, and Nathalie Japkowicz. 2006. A feature selection and evaluation scheme for computer virus detection. Proceedings of ICDM.	Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are overfitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.	"Current research applying data mining to virus detection strives to automate the search for features used in classification. This process has been tackled from two different angles: extracting optimal signatures from a dataset of viruses, and discovering more general features for use in a complex classification scheme.
Extracting virus signatures is not a new problem. Kephart et al. <NO> developed a popular extraction method for virus signatures, by infecting a large number of files with a given virus and then harvesting for constant regions of 12 to 36 bytes. Then, from the considerable number of signatures collected, the ones with lowest predicted false positive rates were selected. While this method make it possible to extract signatures quickly and without the help of an expert, the authors concede that the algorithm fails for viruses that are moderately polymorphic.
Some detection methods utilize a variety of features, such as Win32 dll file calls, ASCII strings and byte sequences contained in the binary files. In an early heuristic approach <NO>, features such as duplicated UNIX system calls and files targeted by the program for writing purposes were used to detect malicious executables. In a machine learning method developed by Matthew Schultz et al. <NO>, ASCII strings and bytes sequences yielded good results. However, despite the byte sequences having a fixed length of 16, the feature space was very large, such that their dataset had to be split into partitions and different classifiers trained separately on each of them. Research in non signature-based heuristics has shown that sequences as short as 4 bytes can be used to detect unseen virus instances successfully <NO>. However, as was found in <NO>, the list of candidate features extracted from a small dataset can contain tens of thousands of sequences.
Finally, many viruses are considered to belong to common virus families, based on the similarities in structure, code or method of infection that they share <NO>. This classification is crucial to properly evaluating the effectiveness of a virus detection system. The first occurrence of a new kind of virus is typically the most devastating, as virus scanners are often incapable of detecting it. Then a host of variants typically emerge soon after the initial outbreak, albeit with less damaging consequences. Our method uses a priori knowledge of virus families, and evaluates the ability of our classifier to detect instances of a family without having been trained on any other instance from that same family."	https://doi.org/10.1109/ICDM.2006.4	1	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']	Henchiri, et al. [NO] presents a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. 
A feature selection and evaluation scheme for computer virus detection	['<NO> used intra-family and inter-family support for n-grams for feature selection.', 'N-grams Static Hybrid <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO> Misuse <NO>']	Olivier Henchiri, and Nathalie Japkowicz. 2006. A feature selection and evaluation scheme for computer virus detection. Proceedings of the 6th International Conference on Data Mining.	Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are overfitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.	"Current research applying data mining to virus detection strives to automate the search for features used in classification. This process has been tackled from two different angles: extracting optimal signatures from a dataset of viruses, and discovering more general features for use in a complex classification scheme.
Extracting virus signatures is not a new problem. Kephart et al. <NO> developed a popular extraction method for virus signatures, by infecting a large number of files with a given virus and then harvesting for constant regions of 12 to 36 bytes. Then, from the considerable number of signatures collected, the ones with lowest predicted false positive rates were selected. While this method make it possible to extract signatures quickly and without the help of an expert, the authors concede that the algorithm fails for viruses that are moderately polymorphic.
Some detection methods utilize a variety of features, such as Win32 dll file calls, ASCII strings and byte sequences contained in the binary files. In an early heuristic approach <NO>, features such as duplicated UNIX system calls and files targeted by the program for writing purposes were used to detect malicious executables. In a machine learning method developed by Matthew Schultz et al. <NO>, ASCII strings and bytes sequences yielded good results. However, despite the byte sequences having a fixed length of 16, the feature space was very large, such that their dataset had to be split into partitions and different classifiers trained separately on each of them. Research in non signature-based heuristics has shown that sequences as short as 4 bytes can be used to detect unseen virus instances successfully <NO>. However, as was found in <NO>, the list of candidate features extracted from a small dataset can contain tens of thousands of sequences.
Finally, many viruses are considered to belong to common virus families, based on the similarities in structure, code or method of infection that they share <NO>. This classification is crucial to properly evaluating the effectiveness of a virus detection system. The first occurrence of a new kind of virus is typically the most devastating, as virus scanners are often incapable of detecting it. Then a host of variants typically emerge soon after the initial outbreak, albeit with less damaging consequences. Our method uses a priori knowledge of virus families, and evaluates the ability of our classifier to detect instances of a family without having been trained on any other instance from that same family."	https://doi.org/10.1109/ICDM.2006.4	1	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']	Henchiri, et al. [NO] presents a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. 
A feature selection and evaluation scheme for computer virus detection	['<NO> used intra-family and inter-family support for n-grams for feature selection.', 'N-grams Static Hybrid <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO> Misuse <NO>']	Olivier Henchiri, and Nathalie Japkowicz. 2006. A feature selection and evaluation scheme for computer virus detection. Proceedings of ICDM.	Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are overfitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.	"Current research applying data mining to virus detection strives to automate the search for features used in classification. This process has been tackled from two different angles: extracting optimal signatures from a dataset of viruses, and discovering more general features for use in a complex classification scheme.
Extracting virus signatures is not a new problem. Kephart et al. <NO> developed a popular extraction method for virus signatures, by infecting a large number of files with a given virus and then harvesting for constant regions of 12 to 36 bytes. Then, from the considerable number of signatures collected, the ones with lowest predicted false positive rates were selected. While this method make it possible to extract signatures quickly and without the help of an expert, the authors concede that the algorithm fails for viruses that are moderately polymorphic.
Some detection methods utilize a variety of features, such as Win32 dll file calls, ASCII strings and byte sequences contained in the binary files. In an early heuristic approach <NO>, features such as duplicated UNIX system calls and files targeted by the program for writing purposes were used to detect malicious executables. In a machine learning method developed by Matthew Schultz et al. <NO>, ASCII strings and bytes sequences yielded good results. However, despite the byte sequences having a fixed length of 16, the feature space was very large, such that their dataset had to be split into partitions and different classifiers trained separately on each of them. Research in non signature-based heuristics has shown that sequences as short as 4 bytes can be used to detect unseen virus instances successfully <NO>. However, as was found in <NO>, the list of candidate features extracted from a small dataset can contain tens of thousands of sequences.
Finally, many viruses are considered to belong to common virus families, based on the similarities in structure, code or method of infection that they share <NO>. This classification is crucial to properly evaluating the effectiveness of a virus detection system. The first occurrence of a new kind of virus is typically the most devastating, as virus scanners are often incapable of detecting it. Then a host of variants typically emerge soon after the initial outbreak, albeit with less damaging consequences. Our method uses a priori knowledge of virus families, and evaluates the ability of our classifier to detect instances of a family without having been trained on any other instance from that same family."	https://doi.org/10.1109/ICDM.2006.4	1	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']	Henchiri, et al. [NO] presents a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. 
Statistical pattern recognition: A review	['<NO>, <NO> and Bishop <NO>, feature selection', 'selection can be found in <NO>, <NO>, and <NO>.', 'Some more survey papers can also be found in <NO>, <NO>, <NO>, <NO>, and <NO>.', 'second-order relationships in the covariance matrix, Other linear transforms, like independent component analysis (ICA) and projection pursuit, which use higher order statistical information, are more suited for non-Gaussian distributions <NO>, <NO>.', 'Identifying the most representative features is critical to improve the performance and efficiency of the classifiers <NO>.', ', feature selection (or variable selection, among many other names) <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, is critical to minimize the classification error.', ', (see <NO>, <NO>, <NO> for a detailed comparison.', 'In other words, “them best features are not the bestm features” <NO>, <NO>, <NO>, <NO>.', ', <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>) and select features with the minimal redundancy (Min-Redundancy).', 'The data set HDR <NO>, <NO>, <NO>, <NO> contains 649 features for 2,000 handwritten digits.', 'This seems underconstrained, especially when rules of thumb suggest that one needs ten times more examples than features <NO>.']	Anil K. Jain, Robert P.W. Duin, and Jianchang Mao. 2000. Statistical pattern recognition: A review. IEEE Trans. Pattern Anal. Mach. Intell. 22, 1 (2000), 4–37.	ÐThe primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field. Index TermsÐStatistical pattern recognition, classification, clustering, feature extraction, feature selection, error estimation, classifier combination, neural networks.	"BY the time they are five years old, most children canrecognize digits and letters. Small characters, large characters, handwritten, machine printed, or rotatedÐall are easily recognized by the young. The characters may be written on a cluttered background, on crumpled paper or may even be partially occluded. We take this ability for granted until we face the task of teaching a machine how to do the same. Pattern recognition is the study of how machines can observe the environment, learn to distinguish patterns of interest from their background, and make sound and reasonable decisions about the categories of the patterns. In spite of almost 50 years of research, design of a general purpose machine pattern recognizer remains an elusive goal.
The best pattern recognizers in most instances are
humans, yet we do not understand how humans recognize
patterns. Ross <NO> emphasizes the work of Nobel Laureate
Herbert Simon whose central finding was that pattern
recognition is critical in most human decision making tasks:
ªThe more relevant patterns at your disposal, the better
your decisions will be. This is hopeful news to proponents
of artificial intelligence, since computers can surely be
taught to recognize patterns. Indeed, successful computer
programs that help banks score credit applicants, help
doctors diagnose disease and help pilots land airplanes
depend in some way on pattern recognition... We need to pay much more explicit attention to teaching pattern recognition.º Our goal here is to introduce pattern recognition as the best possible way of utilizing available sensors, processors, and domain knowledge to make decisions automatically."	https://doi.org/10.1109/34.824819	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Index TermsÐStatistical pattern recognition, classification, clustering, feature extraction, feature selection, error estimation, classifier combination, neural networks [NO].
Renovo: A hidden code extractor for packed executables	['Automated unpackers–common applications for fine-grained analysis–include PolyUnpack <NO> and Renovo <NO>.']	Min Gyung Kang, Pongsin Poosankam, and Heng Yin. 2007. Renovo: A hidden code extractor for packed executables. Proceedings of the 5th ACM Workshop on Recurring Malcode (WORM).	As reverse engineering becomes a prevalent technique to analyze malware, malware writers leverage various anti-reverse engineering techniques to hide their code. One technique commonly used is code packing as packed executables hinder code analysis. While this problem has been previously researched, the existing solutions are either unable to handle novel samples, or vulnerable to various evasion techniques. In this paper, we propose a fully dynamic approach that captures an intrinsic nature of hidden code execution that the original code should be present in memory and executed at some point at run-time. Thus, this approach monitors program execution and memory writes at run-time, determines if the code under execution is newly generated, and then extracts the hidden code of the executable. To demonstrate its effectiveness, we implement a system, Renovo, and evaluate it with a large number of real-world malware samples. The experiments show that Renovo is accurate compared to previous work, yet practical in terms of performance.	"Reverse engineering is one of the main techniques used for malware analysis. To make the analysis more difficult, malware writers usually have their programs heavy-armored with various anti-reverse engineering techniques. Such techniques include binary and source code obfuscation <NO>, control-flow obfuscation <NO>, instruction virtualization <NO>, and binary code packing <NO>. This paper focuses on identifying and extracting the hidden code generated using binary code packing, one of the most common anti-reverse engineering methods. Code packing transforms a program into a packed program by compressing or encrypting the original code and data into packed data and associating it with a restoration routine. A restoration routine is a piece of code for recovering the original code and data as well as setting an execution context to the original code when the packed program is executed. This technique is available as commercial products <NO> and open-source tools. According to the anti-virus (AV) program test results of AVTest GmbH <NO>, the detection rates of 8 major AV programs varied from 10% to 80% when known malware binaries have been packed.
Various tools have been developed to identify and extract the hidden code in packed executables. Commonly known tools such as PEiD <NO> employ a simple pattern matching approach. These tools check an executable with a signature database to determine what kind of packing tool is used to create the executable. Then, using a priori knowledge about the packing tool, it is possible to extract the hidden binary from the executable <NO>. Although this approach is usually fast and accurate for known packing tools, it is unable to detect novel and modified packing techniques. For example, a variant of the Bagle worm employed its own compression engine which is not known to the public <NO>. In fact, by modifying the open source anti-reverse engineering tools like YodaProtector <NO>, it is easy for malware writers to implement new anti-reverse engineering algorithms and tricks.
Dynamic analysis is a promising solution to the problem of hidden code extraction because it does not depend on signatures. Regardless of what packing technique might be applied to the original program, the original code or its equivalent must eventually be present in memory and get executed at some point at run-time. By taking advantage of this intrinsic nature of packed executables, one could potentially extract the hidden binary code or its equivalent as a raw memory dump. However, it is not clear which regions in the memory contain the hidden binary and when is the right time to dump such regions, i.e., when the execution context
jumps to the hidden original code. In addition to the hidden code, other information such as the original entry point (OEP) is also crucial for further analyses of the malware. The original entry point is the first hidden instruction being executed when the program control flow is transferred from the restoration routine to the hidden code. Several approaches, such as Universal PE Unpacker <NO> and PolyUnpack <NO>, have shown that extracting packed binaries and finding the OEP using dynamic analysis is feasible. These approaches either rely on some heuristics or require disassembling the packed program. However, heuristics about packed code may not be reliable in all cases and can be easily evaded. In addition, correctly disassembling a binary program itself is challenging and error-prone, as demonstrated in <NO>. To overcome the disassembly challenge required for packed code extraction, a tool like PolyUnpack needs to perform a series of static and dynamic analysis which leads to performance overhead.
In this paper, we present a fully dynamic approach for extracting the original hidden code and additional information useful for further analysis of the extracted malware binary. We capture an intrinsic nature of packed programs that is independent of the packing techniques applied on the programs. That is, the original code will be dynamically generated and then executed.
The contributions of this paper are as follows:
Propose a fully dynamic approach for extracting the original hidden code of packed executables: A considerable effort has been made to come up with practical solutions for identifying compressed executables and restoring their original hidden code and data. Previous work relies on either heuristics of known packing tools or the accuracy of the disassembler. However, as we see in the Bagle case, malware writers can apply modified binary compression techniques to evade heuristic-based tools <NO>. In addition, disassembling binary executables as being done in <NO> and <NO> is an arduous task. In this paper, we present a binary extraction technique which is fully dynamic and thus does not depend on the program disassembly or the known signatures of packing techniques. We also show that our proposed technique can extract the original hidden code and data, and find the entry point of the original program that enables efficient code analysis.
Provide additional information for the next-step analysis: In addition to extracting the hidden code, our proposed method can provide additional information on the packed binaries:
• Identify the exact regions of memory where the hidden code and data reside: by tracking the newly-written memory areas of the program, we can distinguish newlygenerated code and data at run-time from the packed binary, and thus obtain the exact regions of them.
• Extract information on multiple hidden layers : even in the case that the original program is hidden through multiple rounds of compression and encryption, we can keep track of intermediate code and data for each round. This provides valuable information on what kind of packing methods are in use and what kind of data is generated at each round.
Implement and evaluate Renovo, an automated framework for extracting hidden code: Applying our pro-
posed technique, we build a framework for automatically examining executable binaries and extracting their original hidden code. Since this is a fully automated process, it could be used by anti-virus programs and on-line malware binary analysis services <NO>. We also present the evaluation results of Renovo, demonstrating that it is both highly effective and efficient compared to previous approaches."	https://doi.org/10.1145/1314389.1314399	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Gyung et al. [NO] proposes a fully dynamic approach that captures an intrinsic nature of hidden code execution that the original code should be present in memory and executed at some point at run-time. 
Learning to detect malicious executables in the wild	['A similar approach was used by <NO>, where they trained Instance-Based Learner, TFIDF, Naive-Bayes, support vector machines, decision tree, boosted Naive-Bayes, boosted SVMs and boosted decision tree on n-grams.', 'N-grams Static Hybrid <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO> Misuse <NO>', 'Hence, malware detection is one of the internet security topics that are of great interest <NO>.', 'Recently, many research efforts have been conducted on developing intelligent malware detection systems <NO>.', 'In the first step, various features such as Application Programming Interface (API) calls <NO> and program strings <NO> are extracted to capture the characteristics of the file samples.', 'In the second step, intelligent classification techniques such as decision trees <NO>, Naive Bayes, and associative classifiers <NO> are used to automatically classify the file samples into different classes based on computational analysis of the feature representations.', 'Classification: For classification, over the last couple of years, many data mining and machine learning approaches have been adopted for malware detection <NO>.', 'Naive Bayes method, Support Vector Machine(SVM), decision tree and associative classification methods are applied to detect new malicious executables in previous studies <NO>.', 'So far, several data mining and machine-learning approaches have been used in malware detection <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'the previous studies <NO>, <NO>, <NO> and the results show that our IMDS applying associative classification method outperforms other classification approaches in both detection rate', 'tion <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'Naive Bayes method, SVM, and decision tree classifiers are used to detect new malicious executables in previous studies <NO>, <NO>, <NO>.', 'The collected data in our work is significantly larger than those used in previous studies on data mining for malware detection <NO>.', '<NO> gathered 1971 benign executables and 1651 malicious executables in Windows PE format, and examined the performance of different classifiers such as Naive Bayes, support vector machine (SVM) and Decision Tree using 10-fold cross validation and plotting ROC curves <NO>.', 'Over the last few years, many research efforts have been conducted on developing intelligent malware detection systems <NO>.', 'Both classifiers have been successfully used in malware detection <NO> and have distinct properties.', 'In order to overcome the disadvantages of the widely-used signature-based malware detection method, data mining and machine learning approaches are proposed for malware detection <NO>.', 'Naive Bayes, Support Vector Machine(SVM) and Decision Tree classifiers are used to detect new malicious executables based on small data collection in the previous studies <NO>.', '2) Both associative classification and SVM have been successfully applied in malware detection <NO>.', 'The problem of detecting malware using data mining <NO> involves classifying each executable as either benign or malicious.']	Jeremy Z. Kolter, and Marcus A. Maloof. 2004. Learning to detect malicious executables in the wild. Proceedings of the International Conference on Knowledge Discovery and Data Mining (SIGKDD).	In this paper, we describe the development of a fielded application for detecting malicious executables in the wild. We gathered 1971 benign and 1651 malicious executables and encoded each as a training example using n-grams of byte codes as features. Such processing resulted in more than 255 million distinct n-grams. After selecting the most relevant n-grams for prediction, we evaluated a variety of inductive methods, including naive Bayes, decision trees, support vector machines, and boosting. Ultimately, boosted decision trees outperformed other methods with an area under the roc curve of 0.996. Results also suggest that our methodology will scale to larger collections of executables. To the best of our knowledge, ours is the only fielded application for this task developed using techniques from machine learning and data mining.	"Malicious code is “any code added, changed, or removed from a software system to intentionally cause harm or subvert the system’s intended function” <NO>. Such software has been used to compromise computer systems, to destroy their information, and to render them useless. It has also been used to gather information, such as passwords and credit card numbers, and to distribute information, such as pornography, all without the knowledge of the system’s users. As more novice users obtain sophisticated computers
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. KDD’04, August 22–25, 2004, Seattle, Washington, USA. Copyright 2004 ACM 1-58113-888-1/04/0008 ...$5.00.
with high-speed connections to the Internet, the potential for further abuse is great.
Malicious executables generally fall into three categories based on their transport mechanism: viruses, worms, and Trojan horses. Viruses inject malicious code into existing programs, which become “infected” and, in turn, propagate the virus to other programs when executed. Viruses come in two forms, either as an infected executable or as a virus loader, a small program that only inserts viral code. Worms, in contrast, are self-contained programs that spread over a network, usually by exploiting vulnerabilities in the software running on the networked computers. Finally, Trojan horses masquerade as benign programs, but perform malicious functions. Malicious executables do not always fit neatly into these categories and can exhibit combinations of behaviors.
Excellent technology exists for detecting known malicious executables. Software for virus detection has been quite successful, and programs such as McAfee Virus Scan and Norton AntiVirus are ubiquitous. Indeed, Dell recommends Norton AntiVirus for all of its new systems. Although these products use the word virus in their names, they also detect worms and Trojan horses.
These programs search executable code for known patterns, and this method is problematic. One shortcoming is that we must obtain a copy of a malicious program before extracting the pattern necessary for its detection. Obtaining copies of new or unknown malicious programs usually entails them infecting or attacking a computer system.
To complicate matters, writing malicious programs has become easier: There are virus kits freely available on the Internet. Individuals who write viruses have become more sophisticated, often using mechanisms to change or obfuscate their code to produce so-called polymorphic viruses <NO>. Indeed, researchers have recently discovered that simple obfuscation techniques foil commercial programs for virus detection <NO>. These challenges have prompted some researchers to investigate learning methods for detecting new or unknown viruses, and more generally, malicious code.
Our efforts to address this problem have resulted in a fielded application, built using techniques from machine learning <NO> and data mining <NO>. The Malicious Executable Classification System (mecs) currently detects unknown malicious executables “in the wild”, that is, without removing any obfuscation. To date, we have gathered 1971 system and non-system executables, which we will refer to as “benign” executables, and 1651 malicious executables with a variety of transport mechanisms and payloads (e.g., key-
loggers and backdoors). Although all were for the Windows operating system, it is important to note that our approach is not restricted to this operating system.
We extracted byte sequences from the executables, converted these into n-grams, and constructed several classifiers: ibk, tfidf, naive Bayes, support vector machines (svms), decision trees, boosted naive Bayes, boosted svms, and boosted decision trees. In this domain, there is an issue of unequal but unknown costs of misclassification error, so we evaluated the methods using receiver operating characteristic (roc) analysis <NO>, using area under the roc curve as the performance metric. Ultimately, boosted decision trees outperformed all other methods with an area under the curve of 0.996.
We delivered mecs to the mitre Corporation, the sponsors of this project, as a research prototype. Users interact with mecs through a command line. They can add new executables to the collection, update learned models, display roc curves, and produce a single classifier at a specific operating point on a selected roc curve.
With this paper, we make three main contributions. We show how established methods for text classification apply to executables. We present empirical results from an extensive study of inductive methods for detecting malicious executables in the wild. We report on a fielded application developed using machine learning and data mining.
In the three sections that follow, we describe related work, our data collection, and the methods we applied. Then, in Section 6, we present empirical results, and in Section 7, we discuss these results and other approaches."	https://doi.org/10.1145/1014052.1014105	1	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']	Z. et al. [NO] describes the development of a fielded application for detecting malicious executables in the wild. 
Input feature selection by mutual information based on parzen window	[', feature selection (or variable selection, among many other names) <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, is critical to minimize the classification error.', ', Parzen windows)toapproximateIðx; yÞ,assuggestedbyearlierwork in medical image registration <NO> and feature selection <NO>.', 'In earlier work, Kwak and Choi <NO> used the density estimation approach to calculate the mutual information between an individual feature xi and the target class c.']	Nojun Kwak, and Chong-Ho Choi. 2002. Input feature selection by mutual information based on parzen window. IEEE Trans. Pattern Anal. Mach. Intell. 24, 12 (2002), 1667–1671.	Mutual information is a good indicator of relevance between variables, and have been used as a measure in several feature selection algorithms. However, calculating the mutual information is difficult, and the performance of a feature selection algorithm depends on the accuracy of the mutual information. In this paper, we propose a new method of calculating mutual information between input and class variables based on the Parzen window, and we apply this to a feature selection algorithm for classification problems.	"MUTUAL information is considered as a good indicator of relevance between two random variables <NO>. Recently, efforts to adopt mutual information in feature selection problems resulted in a series of researches <NO>, <NO>, <NO>. Because the computation of mutual information between continuous variables is a very difficult job requiring probability density functions (pdf) and involving integration of those functions, mutual information feature selector (MIFS) <NO>, and its variants <NO>, <NO> used histograms in approximating the pdfs to avoid these complexities. Thus, the performance can be degraded as a result of large errors in estimating the mutual information. In addition, MIFS methods have another limitation in that these methods do not provide a direct measure to judge whether to add additional features or not. More direct calculation of mutual information is attempted using the quadratic mutual information in the feature transformation field <NO>, <NO>, <NO>, but the relationship between Shannon’s mutual information and the quadratic mutual information is not clear so far.
In this paper, a new feature selection method with the mutual information maximization scheme is proposed for classification problems. In calculating the mutual information between the input features and the output class, instead of dividing the input space into several partitions, we use the Parzen window method to estimate the input distribution. With this method, more accurate mutual information is calculated giving better performance than other methods.
In the following section, the basics of information theory and the Parzen window method are briefly presented. In Section 3, we propose a new feature selection method and in Section 4, the proposed algorithms are applied to several classification problems to show their effectiveness. And finally, conclusions follow in Section 5."	https://doi.org/10.1109/TPAMI.2002.1114861	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Kwak, et al. [NO] proposes a new method of calculating mutual information between input and class variables based on the parzen window, and Kwak, et al. [NO] apply this to a feature selection algorithm for classification problems. 
Random KNN	[]	Shengqiao Li, E. James Harner, and Donald A. Adjeroh. 2014. Random KNN. Proceedings of the 2014 IEEE International Conference on Data Mining Workshops. 629–636.	We present Random KNN, a novel generalization of traditional nearest-neighbor modeling. Random KNN consists of an ensemble of base k-nearest neighbor classifiers, each constructed from a random subset of the input variables. We study the properties of the proposed Random KNN. Using various datasets, we perform an empirical analysis of Random KNN performance and compare it with recently proposed methods for high-dimensional datasets. It is shown that Random KNN provides significant advantages in both the computational requirement and classification performance.	"The proposed Random KNN has a connection with classifier fusion and ensemble algorithms, such as those studied by Kitler et al. <NO>, Freud and Schapire <NO>, <NO>, Ji and Ma <NO>, Breiman <NO>, or Sewell <NO>. However, the method is most closely related to, and motivated by, the technique of Random Forests (RF) developed by Breiman <NO>.
One problem with the RF algorithm is that the prediction relies on all the input variables. Variable selection methods have been developed for RF <NO>, <NO>. Various authors have studied Random Forests from different perspectives. For instance, Lin and Jeon studied the connections between Random Forests and adaptive nearest neighbor methods, which use adaptive local distance metrics <NO>. Even with these extensions, which stabilize the hierarchical tree structures, RF may need to keep a relative large number of variables to generate many dissimilar trees.
Random KNN uses KNN as base classifiers that are simple to implement and are stable <NO>, compared with decision trees. Each KNN classifier classifies a test point by its majority, or weighted majority class, of its k neighbors. The final classification in each case is determined by majority voting of r KNN classifications. This can be viewed as a sort of voting by Majority of a Majority.
More formally, let F = {f1, f2, . . . , fp} be the p input features, and X be the n original input data vectors of length p, i.e., an n × p matrix. For a given integer m < p, denote F
(m) = {fj1 , fj2 , . . . , fjm |fjl ∈ F, 1 ≤ l ≤ m} a random subset drawn from F with equiprobability. Similarly, let X(m) be the data vectors in the subspace defined by F(m), i.e., an n × m matrix. Then a KNN(m) classifier is constructed by applying the basic KNN algorithm to the random collection of features in X(m). A collection of r such base classifiers is then combined to build the final Random KNN classifier."	https://doi.org/10.1023/A:1010933404324	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Li, et al. [NO] present random knn, a novel generalization of traditional nearest-neighbor modeling. 
Cloud-based malware detection for evolving data streams	[]	Mohammad M. Masud, Tahseen Al-Khateeb, Kevin W. Hamlen, Jing Gao, Latifur Khan, Jiawei Han, and Bhavani M. Thuraisingham. 2011. Cloud-based malware detection for evolving data streams. ACM Trans. Management Inf. Syst. 2, 3 (2011), 16.	Data stream classification for intrusion detection poses at least three major challenges. First, these data streams are typically infinite-length, making traditional multipass learning algorithms inapplicable. Second, they exhibit significant concept-drift as attackers react and adapt to defenses. Third, for data streams that do not have any fixed feature set, such as text streams, an additional feature extraction and selection task must be performed. If the number of candidate features is too large, then traditional feature extraction techniques fail. In order to address the first two challenges, this article proposes a multipartition, multichunk ensemble classifier in which a collection of v classifiers is trained from r consecutive data chunks using v-fold partitioning of the data, yielding an ensemble of such classifiers. This multipartition, multichunk ensemble technique significantly reduces classification error compared to existing single-partition, single-chunk ensemble approaches, wherein a single data chunk is used to train each classifier. To address the third challenge, a feature extraction and selection technique is proposed for data streams that do not have any fixed feature set. The technique’s scalability is demonstrated through an implementation for the Hadoop MapReduce cloud computing architecture. Both theoretical and empirical evidence demonstrate its effectiveness over other state-of-the-art stream classification techniques on synthetic data, real botnet traffic, and malicious executables.	"Malware is a potent vehicle for many successful cyber attacks every year, including data and identity theft, system and data corruption, and denial of service; it therefore constitutes a significant security threat to many individuals and organizations. The average direct malware cost damages worldwide per year from 1999 to 2006 have been estimated at $14 billion USD <NO>. This includes labor costs for analyzing, repairing, and disinfecting systems, productivity losses, revenue losses due to system loss or degraded performance, and other costs directly incurred as the result of the attack. However, the direct cost does not include the prevention cost, such as antivirus software, hardware, and IT security staff salary, etc. Aside from these monetary losses, individuals and organizations also suffer identity theft, data theft, and other intangible losses due to successful attacks.
Malware includes viruses, worms, Trojan horses, time and logic bombs, botnets, and spyware. A number of techniques have been devised by researchers to counter these attacks; however, the more successful the researchers become in detecting and preventing the attacks, the more sophisticated malicious code appears in the wild. Thus, the arms race between malware authors and malware defenders continues to escalate. One popular technique applied by the antivirus community to detect malicious code is signature detection. This technique matches untrusted executables against a unique telltale string or byte pattern known as a signature, which is used as an identifier for a particular malicious code. Although signature detection techniques are widely used, they are not effective against zero-day attacks (new malicious code), polymorphic attacks (different encryptions of the same binary), or metamorphic attacks (different code for the same functionality) <NO>. There has therefore been a growing need for fast, automated, and efficient detection techniques that are robust to these attacks. This article describes a data mining technique that is dedicated to automated generation of signatures to defend against these kinds of attacks."	https://doi.org/10.1145/2019618.2019622	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	To address the third challenge, a feature extraction and selection technique is proposed for data streams that do not have any fixed feature set [NO].
Limits of static analysis for malware detection	[', encryption) that remove, or limit, access to the code <NO>.', 'These transformations have long been the downfall of static analysis frameworks for traditional analyses <NO> and mobile malware analysis [Rastogi et al.', 'In our work, we also incorporate learning with dynamic trace data, which has been shown to be very important for classifying classes of malware which are packed or obfuscated in other ways <NO>.', 'perform quite well, it has been shown that these methods can be evaded by using advanced obfuscation transformations <NO>.', 'Traditional static analysis techniques have been shown to be insufficient given the rise of newer malware obfuscation techniques <NO>.', 'In principle, dynamic detection can provide direct observation of malware action, is less vulnerable to obfuscation <NO>, and makes it harder to recycle existing malware.']	Andreas Moser, Christopher Kruegel, and Engin Kirda. 2007. Limits of static analysis for malware detection. Proceedings of the 23rd Annual Computer Security Applications Conference (ACSAC).	Malicious code is an increasingly important problem that threatens the security of computer systems. The traditional line of defense against malware is composed of malware detectors such as virus and spyware scanners. Unfortunately, both researchers and malware authors have demonstrated that these scanners, which use pattern matching to identify malware, can be easily evaded by simple code transformations. To address this shortcoming, more powerful malware detectors have been proposed. These tools rely on semantic signatures and employ static analysis techniques such as model checking and theorem proving to perform detection. While it has been shown that these systems are highly effective in identifying current malware, it is less clear how successful they would be against adversaries that take into account the novel detection mechanisms. The goal of this paper is to explore the limits of static analysis for the detection of malicious code. To this end, we present a binary obfuscation scheme that relies on the idea of opaque constants, which are primitives that allow us to load a constant into a register such that an analysis tool cannot determine its value. Based on opaque constants, we build obfuscation transformations that obscure program control flow, disguise access to local and global variables, and interrupt tracking of values held in processor registers. Using our proposed obfuscation approach, we were able to show that advanced semantics-based malware detectors can be evaded. Moreover, our opaque constant primitive can be applied in a way such that is provably hard to analyze for any static code analyzer. This demonstrates that static analysis techniques alone might no longer be sufficient to identify malware.	"Malicious code (or malware) is defined as software that fulfills the harmful intent of an attacker. The damage caused by malware has dramatically increased in the past few
years <NO>. One reason is the rising popularity of the Internet and the resulting increase in the number of available vulnerable machines because of security-unaware users. Another reason is the elevated sophistication of the malicious code itself.
Current systems to detect malicious code (most prominently, virus scanners) are largely based on syntactic signatures. That is, these systems are equipped with a database of regular expressions that specify byte or instruction sequences that are considered malicious. A program is declared malware when one of the signatures is identified in the program’s code.
Recent work <NO> has demonstrated that techniques such as polymorphism and metamorphism are successful in evading commercial virus scanners. The reason is that syntactic signatures are ignorant of the semantics of instructions. To address this problem, a novel class of semantics-aware malware detectors was proposed. These detectors <NO> operate with abstract models, or templates, that describe the behavior of malicious code. Because the syntactic properties of code are (largely) ignored, these techniques are (mostly) resilient against the evasion attempts discussed above. The premise of semantics-aware malware detectors is that semantic properties are more difficult to morph in an automated fashion than syntactic properties. While this is most likely true, the extent to which this is more difficult is less obvious. On one hand, semantics-aware detection faces the challenge that the problem of deciding whether a certain piece of code exhibits a certain behavior is undecidable in the general case. On the other hand, it is also not trivial for an attacker to automatically generate semantically equivalent code.
The question that we address in this paper is the following: How difficult is it for an attacker to evade semanticsbased malware detectors that use powerful static analysis to identify malicious code? We try to answer this question by introducing a binary code obfuscation technique that makes it difficult for an advanced, semantics-based malware detector to properly determine the effect of a piece of code. For this obfuscation process, we use a primitive known as
1063-9527/07 $25.00 © 2007 IEEE DOI 10.1109/ACSAC.2007.21
421
opaque constant, which denotes a code sequence to load a constant into a processor register whose value cannot be determined statically. Based on opaque constants, we build a number of obfuscation transformations that are difficult to analyze statically.
Given our obfuscation scheme, the next question that needs to be addressed is how these transformations should be applied to a program. The easiest way, and the approach chosen by most previous obfuscation approaches <NO>, is to work on the program’s source code. Applying obfuscation at the source code level is the normal choice when the distributor of a binary controls the source (e.g., to protect intellectual property). For malware that is spreading in the wild, source code is typically not available. Also, malware authors are often reluctant to revealing their source code to make analysis more difficult. Thus, to guard against objections that our presented threats are unrealistic, we present a solution that operates directly on binaries.
The core contributions of our paper are as follows:
• We present a binary obfuscation scheme based on the idea of opaque constants. This scheme allows us to demonstrate that static analysis of advanced malware detectors can be thwarted by scrambling control flow and hiding data locations and usage.
• We introduce a binary rewriting tool that allows us to obfuscate Windows and Linux binary programs for which no source code or debug information is available.
• We present experimental results that demonstrate that semantics-aware malware detectors can be evaded successfully. In addition, we show that our binary transformations are robust, allowing us to run real-world obfuscated binaries under both Linux and Windows.
The code obfuscation scheme introduced in this paper provides a strong indication that static analysis alone might not be sufficient to detect malicious code. In particular, we introduce an obfuscation scheme that is provably hard to analyze statically. Because of the many ways in which code can be obfuscated and the fundamental limits in what can be decided statically, we firmly believe that dynamic analysis is a necessary complement to static detection techniques. The reason is that dynamic techniques can monitor the instructions that are actually executed by a program and thus, are immune to many code obfuscating transformations.
2 Code Obfuscation
In this section, we present the concepts of the transformations that we apply to make the code of a binary difficult to analyze statically. As with most obfuscation approaches,
the basic idea behind our transformations is that either some instructions of the original code are replaced by program fragments that are semantically equivalent but more difficult to analyze, or that additional instructions are added to the program that do not change its behavior.
2.1 Opaque Constants
Simple Opaque Constant Calculation Figure 1 shows one approach to create a code sequence that makes use of random input and different intermediate variable values on different branches. In this code sequence, the value unknown is a random value loaded during runtime. To prepare the opaque constant calculation, the bits of the constant that we aim to create have to be randomly partitioned into two groups. The values of the arrays zero and one are crafted such that after the for loop, all bits of the first group have the correct, final value, while those of the second group depend on the random input (and thus, are unknown). Then, using the appropriate values for set ones and set zeros, all bits of the second group are forced to
their correct values (while those of the first group are left unchanged). The result is that all bits of constant hold the desired value at the end of the execution of the code.
An important question is how the arrays zero and one can be prepared such that all bits of the first group are guaranteed to hold their correct value. This can be accomplished by ensuring that, for each i, all bits that belong to the first group have the same value for the two array elements zero<NO> and one<NO>. Thus, independent of whether zero<NO> or one<NO> is used in the xor operation with constant, the values of all bits in the first group are known after each loop iteration. Of course, the bits that belong to the second group can be randomly chosen for all elements zero<NO> and one<NO>. Thus, the value of constant itself is different after each loop iteration. Because a static analyzer cannot determine the exact path that will be chosen during execution, the number of possible constant values doubles after each loop iteration. In such a case, the static analyzer would likely have to resort to approximation, in which case the exact knowledge of the constant is lost.
This problem could be addressed for example by introducing a more complex encoding for the constant. If we use for instance the relationship between two bits to represent one bit of actual information, we avoid the problem that single bits have the same value on every path. In this case, off-the-shelf static analyzers can no longer track the precise value of any variable.
Of course, given the knowledge of our scheme, the defender has always the option to adapt the analysis such that the used encoding is taken into account. Similar to before, it would be possible to keep the exact values for those variables that encode the same value after each loop iteration. However, this would require special treatment of the particular encoding scheme in use. Our experimental re-
sults demonstrate that the simple opaque constant calculation is already sufficient to thwart current malware detectors. However, we also explored the design space of opaque constants to identify primitives for which stronger guarantees with regard to robustness against static analysis can be provided. In the following paragraphs, we discuss a primitive that relies on the NP-hardness of the 3-satisfiability problem.
NP-Hard Opaque Constant Calculation The idea of the following opaque constant is that we encode the instance of an NP-hard problem into a code sequence that calculates our desired constant. That is, we create an opaque constant such that the generation of an algorithm to precisely determine the result of the code sequence would be equivalent to finding an algorithm to solve an NP-hard problem. For our primitive, we have chosen the 3-satisfiability problem (typically abbreviated as 3SAT) as a problem that is known to be hard to solve. The 3SAT problem is a decision problem where a formula in Boolean logic is given in the following form: ∧n
i=1(Vi1 ∨ Vi2 ∨ Vi3)
where Vij ∈ {v1, ..., vm} and v1, ..., vm are Boolean variables whose value can be either true or false. The task is now to determine if there exists an assignment for the variables vk such that the given formula is satisfied (i.e., the formula evaluates to true). 3SAT has been proven to be NPcomplete in <NO>.
Consider the code sequence in Figure 2. In this primitive, we define m boolean variables v1 . . . vm, which correspond directly to the variables in the given 3SAT formula. By v1 . . . vm, we denote their negations. The pointers V11 to Vn3 refer to the variables used in the various clauses of the formula. In other words, the pointers V11 to Vn3 encode a 3SAT problem based on the variables v1 . . . vm. The loop simply evaluates the encoded 3SAT formula on the input. If the assignment of variables v1 . . . vm does not satisfy the formula, there will always be at least one clause i that evaluates to false. When the check in the loop is evaluated for that specific clause, the result will always be true (as the check is performed against the negate of the clause). Therefore, the opaque constant will be set to 0. On the other hand, if the assignment satisfies the encoded formula, the check performed in the loop will never be true. Therefore, the value of the opaque constant is not overwritten and remains 1.
In the opaque constant presented in Figure 2, the 3SAT problem (that is, the pointers V11 to Vn3) is prepared by the obfuscator. However, the actual assignment of boolean values to the variables v1 . . . vm is randomly performed during runtime. Therefore, the analyzer cannot immediately evaluate the formula. The trick of our opaque constant is that the
3SAT problem is prepared such that the formula is not satisfiable. Thus, independent of the actual input, the constant will always evaluate to 0. Of course, when a constant value of 1 should be generated, we can simply invert the result of the satisfiability test. Note that it is possible to efficiently generate 3SAT instances that are not satisfiable with a high probability <NO>. A static analyzer that aims to exactly determine the possible values of our opaque constant has to solve the instance of the 3SAT problem. Thus, 3SAT is reducible in polynomial time to the problem of exact static analysis of the value of the given opaque constant.
Note that the method presented above only generates one bit of opaque information but can be easily extended to create arbitrarily long constants.
Basic Block Chaining One practical drawback of the 3SAT primitive presented above is that its output has to be the same for all executions, regardless of the actual input. As a result, one can conceive an analysis technique that evaluates the opaque constant function for a few concrete inputs. When all output values are equal, one can assume that this output is the opaque value encoded. To counter this analysis, we introduce a method that we denote basic block chaining.
With basic block chaining, the input for the 3SAT problems is not always selected randomly during runtime. Moreover, we do not always generate unsatisfiable 3SAT instances, but occasionally insert also satisfiable instances. In addition, we ensure that the input that solves a satisfiable formula is provided during runtime. To this end, the input variables v1 . . . vm to the various 3SAT formulas are realized as global variables. At the end of every basic block, these global variables are set in one of the three following ways: (1) to static random values, (2) to random values generated at runtime, or (3), to values specially crafted such that they satisfy a solvable formula used to calculate the opaque constant in the next basic block in the control flow graph.
To analyze a program that is obfuscated with basic block chaining, the analyzer cannot rely on the fact that the encoded formula is always unsatisfiable. Also, when randomly executing a few sample inputs, it is unlikely that the analyzer chooses values that solve a satisfiable formula. The only way to dissect an opaque constant would be to first identify the basic block(s) that precede a certain formula and then determine whether the input values stored in this block satisfy the 3SAT problem. However, finding these blocks is not trivial, as the control flow of the program is obfuscated to make this task difficult (see the following Section 2.2 for more details). Thus, the analysis would have to start at the program entry point and either execute the program dynamically or resort to an approach similar to whole program simulation in which different branches are followed from the start, resolving opaque constants as the
analysis progresses. Obviously, our obfuscation techniques fail against such methods, and indeed, this is consistent with an important point that we intend to make in this paper: dynamic analysis techniques are a promising and powerful approach to deal with obfuscated binaries."	http://scholar.google.com/scholar?hl=en&q=Andreas+Moser%2C+Christopher+Kruegel%2C+and+Engin+Kirda.+2007.+Limits+of+static+analysis+for+malware+detection.+In+Proceedings+of+the+23rd+Annual+Computer+Security+Applications+Conference+%28ACSAC%29.+10.1109%2FACSAC.2007.21	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Moser, et al. [NO] is to explore the limits of static analysis for the detection of malicious code. 
Valgrind: A framework for heavyweight dynamic binary instrumentation	[]	Nicholas Nethercote, and Julian Seward. 2007. Valgrind: A framework for heavyweight dynamic binary instrumentation. Proceedings of ACM SIGPLAN 2007 Conference on Programming Language Design and Implementation.	Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited. In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values—a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO.	"Many programmers use program analysis tools, such as error checkers and profilers, to improve the quality of their software. Dynamic binary analysis (DBA) tools are one such class of tools; they analyse programs at run-time at the level of machine code.
DBA tools are often implemented using dynamic binary instrumentation (DBI), whereby the analysis code is added to the original code of the client program at run-time. This is convenient for users,
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
PLDI’07 June 11–13, 2007, San Diego, California, USA. Copyright c© 2007 ACM 978-1-59593-633-2/07/0006. . . $5.00
as no preparation (such as recompiling or relinking) is needed. Also, it gives 100% instrumentation coverage of user-mode code, without requiring source code. Several generic DBI frameworks exist, such as Pin <NO>, DynamoRIO <NO>, and Valgrind <NO>. They provide a base system that can instrument and run code, plus an environment for writing tools that plug into the base system.
The performance of DBI frameworks has been studied closely <NO>. Less attention has been paid to their instrumentation capabilities, and the tools built with them. This is a shame, as it is the tools that make DBI frameworks useful, and complex tools are more interesting than simple tools. As a result, we believe the potential of DBI has not been fully exploited."	https://doi.org/10.1145/1250734.1250746	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Nethercote, et al. [NO] believes the potential of dbi has not been fully exploited. 
Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy	['First, we rank each API using Max-Relevance algorithm <NO>, Industrial and Government Track Short Paper', 'API Calls: As not all of the API calls are contributing to malware detection, we rank each API call using MaxRelevance algorithm <NO> and select a set of API calls with the highest relevance to the target class, i.', 'We then also apply Max-Relevance algorithm <NO> to select a set of the most representative strings for later classification.', 'As not all of the features contributing to malware detection, we rank each API call and interpretable string using Max-Relevance algorithm <NO> and select top k API calls and interpretable strings as the features for later classification.']	Hanchuan Peng, Fuhui Long, and Chris Ding. 2005. Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy. IEEE Transactions on Pattern Analysis and Machine Intelligence 27, 8 (2005), 1226–1238.	Feature selection is an important problem for pattern classification systems.We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e.g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.	"IN many pattern recognition applications, identifying themost characterizing features (or attributes) of the observed data, i.e., feature selection (or variable selection, among many other names) <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, is critical to minimize the classification error. Given the input data D tabled as N samples and M features X ¼ fxi; i ¼ 1; . . . ;Mg, and the target classification variable c, the feature selection problem is to find from the M-dimensional observation space, RM , a subspace of m features, Rm, that “optimally” characterizes c.
Given a condition defining the “optimal characterization,” a search algorithm is needed to find the best subspace. Because the total number of subspaces is 2M , and the number of subspaces with dimensions no larger than m is mi¼1 M i , it is hard to search the feature subspace exhaustively. Alternatively, many sequential-search-based approximation schemes have been proposed, including best individual features, sequential forward search, sequential forward floating search, etc., (see <NO>, <NO>, <NO> for a detailed comparison.).
The optimal characterization condition often means the minimal classification error. Inanunsupervisedsituationwhere theclassifiersarenotspecified,minimalerrorusuallyrequires themaximal statistical dependency of the target class c on the data distribution in the subspace Rm (and vice versa). This scheme ismaximal dependency (Max-Dependency).
One of the most popular approaches to realize MaxDependency is maximal relevance (Max-Relevance) feature selection: selecting the features with the highest relevance to the target class c. Relevance is usually characterized in terms of correlation ormutual information, ofwhich the latter is one of the widely used measures to define dependency of variables. In this paper, we focus on the discussion of mutual-information-based feature selection.
Given two random variables x and y, their mutual information is defined in terms of their probabilistic density functions pðxÞ, pðyÞ, and pðx; yÞ:
Iðx; yÞ ¼ ZZ
pðx; yÞ log pðx; yÞ pðxÞpðyÞ dxdy: ð1Þ
In Max-Relevance, the selected features xi are required, individually, to have the largest mutual information Iðxi; cÞ with the target class c, reflecting the largest dependency on the target class. In terms of sequential search, the m best individual features, i.e., the top m features in the descent ordering of Iðxi; cÞ, are often selected as the m features.
In feature selection, it has been recognized that the combinations of individually good features do not necessarily lead to good classification performance. In other words, “them best features are not the bestm features” <NO>, <NO>, <NO>, <NO>. Some researchers have studied indirect or direct means to reduce the redundancy among features1 (e.g., <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>) and select features with the minimal redundancy (Min-Redundancy). For example, in the sequential forward floating search <NO>, the joint dependency of features on the target class ismaximized; as a by-product, the redundancy among featuresmight be reduced. In <NO>, Jaeger et al. presentedaprefilteringmethod togroupvariables, thus, redundant variables within each group can be removed. In
. H. Peng and F. Long are with the Lawrence Berkeley National Laboratory, University of California at Berkeley, 1 Cyclotron Road, MS. 84-171, Berkeley, CA 94720. E-mail: {hpeng, flong}@lbl.gov. . C. Ding is with the Computational Research Division, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, CA 94720. E-mail: CHQDing@lbl.gov.
Manuscript received 6 Aug. 2003; revised 1 May 2004; accepted 3 Dec. 2004; published online 13 June 2005. Recommended for acceptance by A. Del Bimbo. For information on obtaining reprints of this article, please send e-mail to: tpami@computer.org, and reference IEEECS Log Number TPAMI-0215-0803. 1. Minimal redundancy has also been studied in feature extraction, which aims to find good features in a transformed domain. For instance, it has been well addressed in various techniques such as principal component analysis and independent component analysis <NO>, neural network feature extractors (e.g., <NO>), etc.
0162-8828/05/$20.00 2005 IEEE Published by the IEEE Computer Society
<NO>, we proposed a heuristic minimal-redundancy-maximalrelevance (mRMR) framework to minimize redundancy, and used a series of intuitive measures of relevance and redundancy to select promising features for both continuous and discrete data sets.
Our work in this paper focuses on three issues that have not been touched in earlier work. First, although both MaxRelevance and Min-Redundancy have been intuitively used for feature selection, no theoretical analysis is given on why they can benefit selecting optimal features for classification. Thus, the first goal of this paper is to present a theoretical analysis showing that mRMR is equivalent to Max-Dependency for first-order feature selection, but is more efficient.
Second, we investigate how to combine mRMR with other feature selection methods (such as wrappers <NO>, <NO>) into a two-stage selection algorithm. By doing this, we show that the space of candidate features selected by mRMR is more characterizing. This property of mRMR facilitates the integration of other feature selection schemes to find a compact subset of superior features at very low cost.
Third, through comprehensive experiments we compare mRMR, Max-Relevance, Max-Dependency, and the twostage feature selection algorithm, using three different classifiers and four data sets. The results show that mRMR and our two-stage algorithm are very effective in a wide range of feature selection applications.
This paper is organized as follows: Section 2 presents the theoretical analysis of the relationships of Max-Dependency, Max-Relevance, andMin-Redundancy. Section 3presents the two-stage feature selection algorithm, including schemes to integrate wrappers to select a squeezed subset of features. Section 4 discusses implementation issues of density estimation for mutual information and several different classifiers. Section 5 gives experimental results on four data sets, including handwritten characters, arrhythmia, NCI cancer cell lines, and lymphoma tissues. Sections 6 and 7 are discussions and conclusions, respectively."	https://doi.org/10.1109/TPAMI.2005.159	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Peng, et al. [NO] studies how to select good features according to the maximal statistical dependency criterion based on mutual information. 
PolyUnpack: Automating the hidden-code extraction of unpack-executing malware	['Automated unpackers–common applications for fine-grained analysis–include PolyUnpack <NO> and Renovo <NO>.', 'In <NO>, the authors first disassemble the code, and then run the code looking for sequences of instructions in the dynamic trace that are not found in the disassembled data.', 'Several approaches, such as Universal PE Unpacker <NO> and PolyUnpack <NO>, have shown that extracting packed binaries and finding the OEP using dynamic analysis is feasible.', 'In addition, disassembling binary executables as being done in <NO> and <NO> is an arduous task.', 'However, as shown in <NO> and in our results, some malware can evade this heuristicbased approach.', 'PolyUnpack <NO> is a general approach for extracting the original hidden code without any heuristic assumptions.', 'The details of how these mechanisms work are not present in <NO>, but some malware in the wild are still shown to be able to evade these commercial virus scanners <NO>.', 'Unlike previous approaches <NO> which employ disassembly techniques, our approach depends solely on the origin of the instructions being executed.', 'Note that determining whether a program has hidden code or not is an undecidable problem <NO>.', 'Since determining whether an executable contains hidden code or not is an undecidable problem as shown in <NO>, we employ a time-out mechanism.', 'To verify that Renovo generates accurate results, we have tested Renovo and two other extraction techniques, Universal PE Unpacker <NO> and PolyUnpack <NO>, against the synthetic sample programs generated by using 14 different pack-', 'PolyUnpack: We obtained the analysis results of PolyUnpack <NO> by submitting samples to the Malfease website <NO> of which PolyUnpack operates as its sub-module.']	Paul Royal, Mitch Halpin, David Dagon, Robert Edmonds, and Wenke Lee. 2006. PolyUnpack: Automating the hidden-code extraction of unpack-executing malware. Proceedings of the 22nd Annual Computer Security Applications Conference.	Modern malware often hide the malicious portion of their program code by making it appear as data at compiletime and transforming it back into executable code at runtime. This obfuscation technique poses obstacles to researchers who want to understand the malicious behavior of new or unknown malware and to practitioners who want to create models of detection and methods of recovery. In this paper we propose a technique for automating the process of extracting the hidden-code bodies of this class of malware. Our approach is based on the observation that sequences of packed or hidden code in a malware instance can be made self-identifying when its runtime execution is checked against its static code model. In deriving our technique, we formally define the unpack-executing behavior that such malware exhibits and devise an algorithm for identifying and extracting its hidden-code. We also provide details of the implementation and evaluation of our extraction technique; the results from our experiments on several thousand malware binaries show our approach can be used to significantly reduce the time required to analyze such malware, and to improve the performance of malware detection tools.	"In <NO>, Christodorescu et. al. further the detection of malware to include models based on semantic behavior. Called templates, these models leverage the power of context-free grammars (CFGs) to automatically identify classes (rather than instances) of malware. In such a framework, a template could be created for detecting malware instances that contain unpack-execute behavior based on the semantic class of their unpacking mechanism; indeed, one of the templates presented serves to capture the decryption loop of a polymorphic worm. In the context of our focus, if a malware instance is matched to a template describing a particular unpacking mechanism, the code segment matched could be used to unpack and extract the instance’s hidden-code. Unfortunately, however, even the power of CFGs do not provide a comprehensive mechanism for extracting the hidden-code of all unpack-executing malware. All the malware writer needs to do to successfully evade
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06) 0-7695-2716-7/06 $20.00 © 2006
detection is find a different semantic mechanism of unpacking for which a template has not yet been written, such as pulling malicious code from a network.
Among pattern-matching based extraction approaches, the program Portable Executable (PE) Identifier (PEiD) <NO> stands out as a widely used tool for detecting binaries that exhibit unpack-execute behavior. PEiD uses a signature database to determine if a binary contains packed-code. If a signature match is found, knowledge of the identified packing mechanism can be used to unpack and extract the hidden-code contained in the binary. The key limitations of PEiD are identical to that of a pattern-matching anti-virus tool: its signature database must be updated for it to detect new unpack-executing binary instances and can fail to detect even minor variations of an otherwise known packing method in the same semantic class.
The closest industry work to ours is the Universal PE Unpacker plugin <NO>, available for IDA Pro 4.9. The plugin uses the behavioral heuristic that a program will return to its original entry point once it starts unpacking. Although a good approach for handling compression-based packing techniques, there exists a straightforward possibility of evasion. That is, any program that begins execution in its entry point area, transforms a small portion of data in one of its data sections, then directs execution to the data section it transformed would evade the plugin’s detection heuristic. Using the results of testing our approach as described in Section 6, we discovered several hundred malware instances sampled in the wild that evade the IDA Pro plugin’s heuristic. Our approach does not make the same assumption, and represents a more general solution to the problem of unpacking. As an additional confirmation, we corresponded with Ilfak Guilfanov, the author of IDA Pro; he agrees that our technique provides a new approach not addressed by the Universal PE Unpacker plugin <NO>.
Finally, anti-virus companies have made reference to the notion of malware-instance-independent code extraction, occasionally referring to its implementation as a generic decryption engine <NO>. Just like the authors in <NO>, we found it impossible to obtain further details about the workings of commercial AV tools. In 2004, however, Christodorescu and Jha demonstrated in <NO> that encapsulation techniques used in modern polymorphic viruses prevented commercial anti-virus products from detecting otherwise functionally identical variants of known malware. Given the closed nature of commercial AV products, investigation of the efforts employed by these companies is difficult, and the degree of success in their implementations remains an open question."	https://doi.org/10.1109/ACSAC.2006.38	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Royal, et al. [NO] proposes a technique for automating the process of extracting the hidden-code bodies of this class of malware. 
Deep neural network based malware detection using two dimensional binary program features	[]	Joshua Saxe, and Konstantin Berlin. 2015. Deep neural network based malware detection using two dimensional binary program features. Proceedings of the 10th International Conference on Malicious and Unwanted Software (MALWARE).	In this paper we introduce a deep neural network based malware detection system that Invincea has developed, which achieves a usable detection rate at an extremely low false positive rate and scales to real world training example volumes on commodity hardware. We show that our system achieves a 95% detection rate at 0.1% false positive rate (FPR), based on more than 400,000 software binaries sourced directly from our customers and internal malware databases. In addition, we describe a non-parametric method for adjusting the classifier’s scores to better represent expected precision in the deployment environment. Our results demonstrate that it is now feasible to quickly train and deploy a low resource, highly accurate machine learning classification model, with false positive rates that approach traditional labor intensive expert rule based malware detection, while also detecting previously unseen malware missed by these traditional approaches. Since machine learning models tend to improve with larger datasizes, we foresee deep neural network classification models gaining in importance as part of a layered network defense strategy in coming years.	"Malware continues to facilitate cyber attacks, as attackers use malware as a key tool their campaigns. One problem in computer security is therefore to detect malware, so that it can be stopped before it can achieve its objectives, or at least so that it can be expunged once it has been discovered.
Various detection approaches have been proposed, including rule or signature based approaches, which require analysts to hand craft rules that reason over relevant data to make detections, and machine learning approaches, which automatically reason about malicious and benign data to fit detection model parameters. A middle path between these
∗Authors contributed equally to the work.
approach is the automatic generation of signatures. To date, the computer security industry has favored manual and automatically created rules and signatures over machine learning and statistical methods, because of the low false positive rates achievable by rule and signature-based methods.
In recent years, however, a confluence of three developments have increased the possibility for success in machinelearning based approaches, holding the promise that these methods might achieve high detection rates at low false positive rates without the burden of human signature generation required by manual methods.
The first of these trends is the rise of commercial threat intelligence feeds that provide large volumes of new malware, meaning that for the first time, timely, labeled malware data are available to the security community. The second trend is that computing power has become cheaper, meaning that researchers can more rapidly iterate on malware detection machine learning models and fit larger and more complex models to data. Third, machine learning as a discipline has evolved, meaning that researchers have more tools to craft detection models that achieve breakthrough performance in terms of both accuracy and scalability.
In this paper we introduce an approach that takes advantage of all three of these trends: a deployable deep neural network based malware detector using static features that gives what we believe to be the best reported accuracy results of any previously published detection engine that uses exclusively static features.
The structure of the rest of this paper is as follows. In Section 2 we describe our approach, giving a description of our feature extraction methods, our deep neural network, and our Bayesian calibration model. In Section 3 we provide multiple validations of our approach. Section 4 treats related work, surveying relevant malware detection research and comparing our results to other proposed methods. Finally, Section 5 concludes the paper, reiterating our findings and discussing plans for future work."	https://doi.org/10.1109/MALWARE.2015.7413680	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Saxe, et al. [NO] introduces a deep neural network based malware detection system that invincea has developed, which achieves a usable detection rate at an extremely low false positive rate and scales to real world training example volumes on commodity hardware. 
A survey of data mining techniques for malware detection using file features	[]	Muazzam Siddiqui, Morgan C. Wang, and Joohan Lee. 2008. A survey of data mining techniques for malware detection using file features. Proceedings of ACM-SE.	This paper presents a survey of data mining techniques for malware detection using file features. The techniques are categorized based upon a three tier hierarchy that includes file features, analysis type and detection type. File features are the features extracted from binary programs, analysis type is either static or dynamic, and the detection type is borrowed from intrusion detection as either misuse or anomaly detection. It provides the reader with the major advancement in the malware research using data mining on file features and categorizes the surveyed work based upon the above stated hierarchy. This served as the major contribution of this paper.	K.6.5 <NO>: Security and Protection— Invasive software; H.2.8 <NO>: Database Applications—Data mining ; I.2.6 <NO>: Learning—Concept learning, Connectionism and neural nets	https://doi.org/10.1145/1593105.1593239	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Siddiqui, et al. [NO] presents a survey of data mining techniques for malware detection using file features. 
Static analyzer of vicious executables (SAVE)	['Hence, malware detection is one of the internet security topics that are of great interest <NO>.', 'niques, chief among them being automated obfuscation <NO>.', 'Nowdays malware samples increasingly employ techniques such as polymorphism <NO>, metamorphism <NO>, packing, instruction virtualization, and emulation to bypass signatures and defeat attempts to analyze their inner mechanisms <NO>.', 'Recently, many research efforts have been conducted on developing intelligent malware detection systems <NO>.', 'Classification: For classification, over the last couple of years, many data mining and machine learning approaches have been adopted for malware detection <NO>.', 'However, this classic signature-based method always fails to detect variants of known malware or previously unknown malware, because the malware writers always adopt techniques like obfuscation to bypass these signatures <NO>.', 'So far, several data mining and machine-learning approaches have been used in malware detection <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'tion <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'Besides the traditional signature-based malware detection methods, there is some work to improve the signature-based detection <NO> and also a few attempts to apply data mining and machine learning techniques to detect new malicious executables.', '<NO> developed a signature based malware detection system called SAVE (Static Analyzer of Vicious Executables) which emphasized on detecting polymorphic malware.', 'For each virus, we apply the obfuscation techniques described in <NO> to create a set of polymorphic versions.', 'First, we compare the efficiency of our system with different scanners including the scanner named “SAVE” <NO> described in related work and some widely-used anti-virus software.', 'The problem lies in the signature extraction and generation process, and in fact these signatures can be easily bypassed <NO>.']	Andrew H. Sung, Jianyun Xu, Patrick Chavez, and Srinivas Mukkamala. 2004. Static analyzer of vicious executables (SAVE). Proceedings of the 20th Annual Computer Security Applications Conference.	Software security assurance and malware (trojans, worms, and viruses, etc.) detection are important topics of information security. Software obfuscation, a general technique that is useful for protecting software from reverse engineering, can also be used by hackers to circumvent the malware detection tools. Current static malware detection techniques have serious limitations, and sandbox testing also fails to provide a complete solution due to time constraints. In this paper, we present a robust signature-based malware detection technique, with emphasis on detecting obfuscated (or polymorphic) malware and mutated (or metamorphic) malware. The hypothesis is that all versions of the same malware share a common core signature that is a combination of several features of the code. After a particular malware has been first identified, it can be analyzed to extract the signature, which provides a basis for detecting variants and mutants of the same malware in the future. Encouraging experimental results on a large set of recent malware are presented.	"Due to the increasing prevalence of malware (trojans, worms, and virues, etc.) of all sorts and the significant economic loss they incur to individuals and organizations, one of the current computer security topics of great interest is malware detection.
A classification of malware based on payload, enabling vulnerability, and propagation mechanism gives three generations <NO>."	https://doi.org/10.1109/CSAC.2004.37	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	H. et al. [NO] presents a robust signature-based malware detection technique, with emphasis on detecting obfuscated (or polymorphic) malware and mutated (or metamorphic) malware. 
The evolution of android malware and android analysis techniques	[]	Kimberly Tam, Ali Feizollah, Nor Badrul Anuar, Rosli Salleh, and Lorenzo Cavallaro. 2017. The evolution of android malware and android analysis techniques. ACM Computing Surveys (CSUR) 49, 4 (2017), 76.	With the integration of mobile devices into daily life, smartphones are privy to increasing amounts of sensitive information. Sophisticated mobile malware, particularly Android malware, acquire or utilize such data without user consent. It is therefore essential to devise effective techniques to analyze and detect these threats. This article presents a comprehensive survey on leading Android malware analysis and detection techniques, and their effectiveness against evolving malware. This article categorizes systems by methodology and date to evaluate progression and weaknesses. This article also discusses evaluations of industry solutions, malware statistics, and malware evasion techniques and concludes by supporting future research paths.	"Smartphones, tablets, and other mobile platforms have quickly become ubiquitous due to their highly personal and powerful attributes. As the current dominating personal computing device, with mobile shipments surpassing PCs in 2010 <NO>, smartphones have spurred an increase of sophisticated mobile malware. Over six million mobile malware samples have been accumulated by McAfee as of Q4 2014, up 14% over Q3, and roughly 98% of them target primarily Android devices <NO>. Given Android’s all-pervasive nature and the threats against this particular mobile platform, there is a pressing need for effective analysis techniques to support the development of reliable detection and classification tools. In an attempt to evaluate the progress of research within this specific area of work, this article provides the following contributions.
(1) This work first presents background information on mobile devices and their characteristics. This leads to a detailed description of the Android operating system, as well as notable Android malware and general mobile malware traits (see Section 2). Unlike previous mobile malware surveys, this article primarily focuses on the malware traits that hinder accurate studies and presents them in conjunction with a comprehensive snapshot of today’s Android research techniques. (2) This work presents a comprehensive study on an extensive and diverse set of Android malware analysis frameworks, including methods (e.g., static, dynamic, hybrid), year, and outcome. Similar studies are then reviewed to identify evolving state-of-the-art techniques in an attempt to identify their strengths, weaknesses, performance, and uses. For example, this article discusses how robust some techniques are to major changes within Android, such as replacing the Dalvik runtime. Studies were primarily selected from well-established and top-ranked research venues. However, this work does include, wherever appropriate, a number of additional studies in an attempt to demonstrate the entire breadth of this research area (see Sections 3 and 4). (3) Section 5 addresses several Android malware tactics used to obstruct or evade analysis. This article classifies and describes transformation attacks and examines several advanced malware evasion techniques, such as encryption, native exploits, and Virtual machine (VM)-awareness. With that knowledge, this article performs a comparison of malware strengths to common analysis weaknesses, creating a more comprehensive view than surveys focused on individual aspects. We then confirm trends in evasive malware, found in similar studies, with our own experiments. (4) This work further supports several directions of future research and highlights issues that may not be apparent when looking at individual studies, including malware trends and plausible research paths. While some have recently been receiving more attention, others have yet to be explored sufficiently. Section 6 gives an overview of the state-of-the-art and future research discussion.
Unlike previous works, this article is not a general study on mobile attack vectors or defense <NO> but instead focuses on Android-related analysis techniques systematically and in detail. As can be seen in Table I, this differs from a number of previous works. In similar surveys (e.g, on Android malware families, evolution, characteristics), although analysis techniques are often mentioned, the information is scattered throughout the article to support other material. Furthermore, when combined, those pieces often formed an incomplete picture of all available methods. This study fills that gap by presenting a method-focused view. Furthermore, unlike similar surveys, for example, Vidas et al. <NO>, this article primarily concentrates on the malware aspects that hinder or deter analysis, detection, and classification, allowing us to explore the symbiotic relationship between malware and defense. These findings on how the newest malware and analysis techniques influence each other sets this survey apart from those focused on purely on malware threats or Android defense. However, while it is not the main focus, this article does discuss aspects of malware like market infections.
By narrowing the scope, this article provides in-depth studies on both sides of the arms race with respect to Android malware. A more general study on Android ecosystem weaknesses, for example, the level of app developer skills, and protection schemes can be found in Sufatrio et al. <NO>. This is unlike the focused details on analysis-related techniques, and anti-analysis methods, for Android malware in this article. The last section containing discussions and future research possibilities also differs from the most recent, and most relevant, articles. This may be useful to a wide range of readers."	https://doi.org/10.1145/3017427	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	This article presents a comprehensive survey on leading Android malware analysis and detection techniques, and their effectiveness against evolving malware [NO].
Guilt by association: Large scale malware detection by mining file-relation graphs	[]	Acar Tamersoy, Kevin Roundy, and Duen Horng Chau. 2014. Guilt by association: Large scale malware detection by mining file-relation graphs. Proccedings of ACM International Conference on Knowledge Discovery and Data Mining (ACM SIGKDD).	The increasing sophistication of malicious software calls for new defensive techniques that are harder to evade, and are capable of protecting users against novel threats. We present Aesop, a scalable algorithm that identifies malicious executable files by applying Aesop’s moral that“a man is known by the company he keeps.” We use a large dataset voluntarily contributed by the members of Norton Community Watch, consisting of partial lists of the files that exist on their machines, to identify close relationships between files that often appear together on machines. Aesop leverages locality-sensitive hashing to measure the strength of these inter-file relationships to construct a graph, on which it performs large scale inference by propagating information from the labeled files (as benign or malicious) to the preponderance of unlabeled files. Aesop attained early labeling of 99% of benign files and 79% of malicious files, over a week before they are labeled by the state-of-the-art techniques, with a 0.9961 true positive rate at flagging malware, at 0.0001 false positive rate.	"Protection against novel malware attacks, also known as 0-day malware, is becoming increasingly important as the cost of these attacks increases. For individuals, the dollars and cents cost is rising due to the increasing prevalence of financial fraud and the increasing viciousness of malware, such as the CryptoLocker ransomware program that encrypts personal data files and holds them for a ransom of 300 dollars <NO>. Emotional and professional costs can be much higher, as when attacks result in the loss of privacy. The situation is arguably worse for governments and businesses, which find themselves under siege by well-funded attackers that routinely create devastating financial losses, and perhaps even more impactful losses of intellectual property and operational secrets <NO>.
Computer security providers recognize the need to respond with better protection against novel threats. The goal of these 0-day threat protections is to limit the malware’s window of effectiveness, so that malicious files are detected as soon as possible after their first appearance. Another critical measure of success is a vanishingly small false positive rate, as labeling a benign file as malicious can have devastating consequences, particularly if it is a popular file or one that is essential to the stability of the system, as in the case of operating system and driver files.
We present Aesop (Figure 2), a novel approach to detecting malicious executable files by applying the well-known aphorism that “a man is known by the company he keeps,” and in our case, a file’s goodness may be judged by the other files that often appear with it on users’ machines. More precisely, we infer unlabeled files’ reputation (or goodness) by analyzing their relations with labeled peers.
Aesop is not the first attempt to detect malware by establishing file reputation scores. A representative work in this space is Polonium <NO>, which leverages the insight that some computer users have poor internet hygiene in that they attract many more malicious files than users that follow se-
curity best practices. Polonium constructs a bipartite graph between files and machines, in which a file-machine edge represents the existence of a particular file on a particular machine. This approach proved to be successful, Symantec has deployed Polonium; it has detected millions of malicious files. However, Polonium misses many malicious files as it can only observe malware’s file-to-file relationships indirectly through the lens of low-hygiene machines. By contrast, Aesop directly captures file-to-file affinity and can therefore identify malicious files that co-occur with one another, even when they do not appear on heavily infected machines. As we shall demonstrate, Aesop is able to detect many malicious files over a week before they are labeled by Symantec’s existing Polonium-based technology, with a 0.0001 false positive rate (see Figure 1).
Like Polonium, in this work we leverage Symantec’s Norton Community Watch data, the most important elements of which are unique file and machine identifiers. File identifiers are SHA-256 or MD5 cryptographic hash values that are computed over the file’s raw bytes. Symantec’s proxy for a true machine identifier is based on the serial number of Norton security products, which is an adequate but imperfect fit because product re-installation on a single machine may result in a serial number change, and a single serial number can be carried from one machine to another. The scale of this dataset is impressive, comprising 119 million machines and 10.1 billion files.
This paper makes the following contributions:
• We formulate the malware detection problem as a largescale graph mining and inference problem, where our goal is to identify an unknown file’s relations with other files so that we can establish guilt or innocence by its association with files that are known to be benign or malicious. • We present theAesop algorithm that leverages locality-
sensitive hashing to efficiently compute file similarity values to construct a file-relation graph for inferring file goodness based on belief propagation.
• Aesop achieved early detection of 99% of benign files and 79% of malicious files that remained unlabeled by Symantec for over a week before they were eventually labeled, with exceptionally low error rates (see Figure 1).
The remainder of this paper proceeds as follows. We begin by describing our dataset and the notation we will use throughout this paper. We then proceed to a description of Aesop and its various components, followed by the experiments we conducted to demonstrate its effectiveness. Finally, we discuss our plans to deploy Aesop in support of Symantec’s malware detection capabilities, and end by presenting our conclusions."	https://doi.org/10.1145/2623330.2623342	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Tamersoy, et al. [NO] present aesop, a scalable algorithm that identifies malicious executable files by applying aesop ’ s moral that “ a man is known by the company he keeps. ” Tamersoy, et al. [NO] use a large dataset voluntarily contributed by the members of norton community watch, consisting of partial lists of the files that exist on their machines, to identify close relationships between files that often appear together on machines. 
Stealth breakpoints	['Though current debuggers to some extent, support self-modifying code and code obfuscations, they are not tailored specifically towards malware analysis and fall prey to several anti-debugging tricks employed by them <NO>.', 'An overlay point under Cobra is defined by employing SPiKE <NO> (a stealth coarse-grained malware analysis framework) and/or VAMPiRE <NO> (a stealth breakpoint framework).', 'The analysis tool also initializes support frameworks used by Cobra such as VAMPiRE <NO> and/or SPiKE <NO> at this stage and establishes the first overlay point using their API (in our example in Figure 6, SPiKE is used to setup an overlay point on KiSwitchContext, a Windows internal kernel function).', 'It makes use of Cobra (apart from other frameworks such as SPiKE <NO> and VAMPiRE <NO>) for real-time malware analysis in both a coarse- and fine-grained fashion.', 'In the obfuscation/deobfuscation game played between attackers and defenders, numerous anti-evasion techniques have been applied in the creation of robust in-guest API call tracers and automated deobfuscation tools <NO>.', 'include VAMPiRE <NO>, BitBlaze <NO> and Cobra <NO>.']	Amit Vasudevan, and Ramesh Yerraballi. 2005. Stealth breakpoints. Proceedings of the 21st Annual Computer Security Applications Conference.	Microscopic analysis of malicious code (malware) requires the aid of a variety of powerful tools. Chief among them is a debugger that enables runtime binary analysis at an instruction level. One of the important services provided by a debugger is the ability to stop execution of code at an arbitrary point during runtime, using breakpoints. Software breakpoints support an unlimited number of breakpoint locations by changing the code being debugged so that it can be interrupted during runtime. Most, if not all, malware are very sensitive to code modification with self-modifying and/or self-checking (SM-SC) capabilities, rendering the use of software breakpoints limited in their scope. Hardware breakpoints supported by the underlying processor, on the other hand, use a subset of the processor register set and exception mechanisms to provide breakpoints that do not entail code modification. This makes hardware breakpoints the most powerful breakpoint mechanism for malware analysis. However, current processors provide a very limited number of hardware breakpoints (typically 2–4 locations). Thus, a serious restriction is imposed on the debugger to set a desired number of breakpoints without resorting to the limited alternative of software breakpoints. Also, with the ever evolving nature of malware, there are techniques being employed that prevent the use of hardware breakpoints. This calls for a new breakpoint mechanism that retains the features of hardware breakpoints while providing an unlimited number of breakpoints, which cannot be detected or countered. In this paper, we present the concept of stealth breakpoints and discuss the design and implementation of VAMPiRE 1, a realization of this concept. VAMPiRE cannot be detected or countered and provides unlimited number of breakpoints to be set on code, data, and I/O with the same precision as that of hardware breakpoints. It does so by employing a subtle combination of simple stealth techniques using virtual memory and hardware single-stepping mechanisms that are available on all processors, old and new. This technique makes VAMPiRE portable to any architecture, providing powerful breakpoint ability similar to hardware breakpoints for microscopic malware analysis. 1 VAMPiRE is a beast (in folklore) that attacks in a stealth fashion.	"Microscopic malware analysis — a fine-grained analysis process that provides insight into malware structure and inner functioning — helps in gleaning important information regarding a malware to facilitate the development of an antidote. Fine-grained analysis requires the aid of various powerful tools, chief among them being a debugger that enables runtime binary analysis at an instruction level. One of the important services provided by a debugger is the ability to stop execution of code being debugged at an arbitrary point during runtime. This is achieved using breakpoints, which can be of two types: Hardware and Software. Hardware breakpoints, as the name suggests, are provided by the underlying processor and support precise breakpoints on code, data and I/O. They are deployed by programming specific processor registers to specify the breakpoint locations and type. Software breakpoints on the other hand are implemented by changing the code being debugged to trigger certain exceptions upon execution (usually a breakpoint exception).
Software breakpoints support unlimited number of breakpoint locations but suffer from the fact that they modify the target code at runtime. This is clearly unsuitable in the context of malware since most if not all malware possess SMSC capabilities and are very sensitive to changes made to their code. For example, viruses such as W32.HIV <NO>, W9x.CIH <NO>, W32.MyDoom <NO> etc. use polymorphic/metamorphic code envelopes and employ a host of integrity checks to detect any changes made to their internal code fragments, to prevent their analysis. Hardware breakpoints on the other hand do not involve any form of code modification and, hence, are the most powerful tool in the repertoire of any debugger tailored for malware. Current processors , however, provide a very limited number of hardware breakpoints (typically 2–4 locations). Thus, a serious restriction is imposed on a debugger to set desired number of breakpoints without resorting to the limited alternative of software breakpoints. Also, with the ever evolving nature of malware, there are techniques being employed that prevent the use of hardware breakpoints to analyze them. For example, the W32.HIV virus uses the processor debug registers and the breakpoint exception for its internal computations, thereby effectively thwarting hardware breakpoints. This situation calls for a new breakpoint mechanism that retains the features of hardware breakpoints while providing unlimited
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 1063-9527/05 $20.00 © 2005 IEEE
number of breakpoints that cannot be detected or countered. This paper discusses the concept of stealth breakpoints and presents VAMPiRE, a realization of this concept that offers the best of both worlds in the sense of unlimited number of precise breakpoints on code, data and I/O which cannot be detected or countered. This is achieved by employing simple stealth techniques that involve virtual memory, singlestepping and task state segments 2 (for processors supporting legacy I/O) — features found in most new and old processor architectures.
While various ideas using virtual memory for breakpoint purposes have been explored in many debuggers <NO>, most if not all, allow only data read and/or write breakpoints. Also none of them are specifically tailored for malware analysis and their breakpoint implementation can be easily detected and defeated. To the best of our knowledge, VAMPiRE is the first to combine virtual memory, single-stepping, task state segments (TSS) and stealth techniques to provide a stealth and portable breakpoint framework highly conducive for malware analysis. By stealth we mean that the breakpoints inserted using VAMPiRE is completely invisible to the code being debugged. VAMPiRE currently runs under the Windows (9x, NT, 2K and XP) and Linux operating systems (OS) on IA-32 (and compatible) processors and is portable on any platform (OS and processor architecture) that supports virtual memory and single-stepping. The framework performance is well within the limits to suit interactive debugging and having a simple and easy-to-use API allows it to be incorporated into existing debuggers with ease.
This paper is organized as follows: In Section 2 we consider related work on breakpoints and compare them with VAMPiRE. In Section 3 we discuss the design and implementation of VAMPiRE. In Section 4 we demonstrate the use of VAMPiRE and present some performance numbers for the framework. We conclude the paper in Section 5 summarizing our contributions with suggestions for future work."	https://doi.org/10.1109/CSAC.2005.52	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Vasudevan, et al. [NO] presents the concept of stealth breakpoints and discuss the design and implementation of vampire 1, a realization of this concept. 
Graph-based malware distributors detection	[]	Andrei Venzhega, Polina Zhinalieva, and Nikolay Suboch. 2013. Graph-based malware distributors detection. Proceedings of the 22nd International Conference on World Wide Web Companion (WWW).	Search engines are currently facing a problem of websites that distribute malware. In this paper we present a novel efficient algorithm that learns to detect such kind of spam. We have used a bipartite graph with two types of nodes, each representing a layer in the graph: web-sites and file hostings (FH), connected with edges representing the fact that a file can be downloaded from the hosting via a link on the web-site. The performance of this spam detection method was verified using two set of ground truth labels: manual assessments of antivirus analysts and automatically generated assessments obtained from antivirus companies. We demonstrate that the proposed method is able to detect new types of malware even before the best known antivirus solutions are able to detect them.	"Due to Internet propagation malware has been rapidly spreading and infecting computers around the world at an unprecedented rate <NO> and malware detection became one of the top internet security topics <NO>. Security software developers reported that the release rate of malicious code and other unwanted programs may be exceeding that of legitimate software applications <NO>.
Search engines (SE) have become one of the principal boosters of malware distribution. Users are looking for software with SE, but sometimes instead of sites of software developers or legal distributors, they get fake websites or malware distributors (MD).
Recently, SEs began to realize their unintentional contribution in malware distribution. To protect users from malware search results they made agreements on cooperation between SE and antivirus companies. Web services enable the identification of malware with a huge partners data about viruses collected, e.g. virustotal.com1. But even a huge malware database does not guarantee detection of new ones. Most of anti-malware software products, such as Kaspersky, Symantec, MacAfee typically use the signaturebased method to recognize threats2. But malware writers successfully invent counter-measures against proposed malware analysis techniques. Today’s malware samples are created at a rate of thousands per day. According to Symantec’s annual report <NO>: 5,5 billion malware attacks were blocked in 2011, 81% more than in 2010. More than 403 million new types of malicious software were detected in 2011, 41% more than in 2011. Symantec reports huge amount of blocked malware, but they estimate that new malware techniques are able to generate an almost unique version of their malware for each potential victim. This suggests traditional signature-based malware detection solutions will likely be outpaced by the number of innovative threats being created by malware authors. A new radically different approach to the problem is currently needed.
SE companies are the first who face a threat from newmalwares. That is why early detection of new malware and in particular their distributors is the principle objective of ensuring safe and high-quality web search. Some websites even if they are not MDs, but closely related to the distributors, for example, linked with hyperlinks, can also be dangerous. We can even suspect them of intentional cooperation with distributors of viral software. Therefore to find suspicious websites, we propose an approach that consists in spreading information about MD via connections between neighbours, which is similar to the idea of homophily. We used a bipartite graph with two types of nodes: website and FH. An edge represents the fact that a file hosted on FH and can be downloaded from the website."	https://doi.org/10.1145/2487788.2488136	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Venzhega, et al. [NO] presents a novel efficient algorithm that learns to detect such kind of spam. 
Comparison of stability for different families of filter-based and wrapper-based feature selection	[]	Randall Wald, Taghi M. Khoshgoftaar, and Amri Napolitano. 2013. Comparison of stability for different families of filter-based and wrapper-based feature selection. ICMLA.	Due to the prevalence of high dimensionality (having a large number of independent attributes), feature selection techniques (which reduce the feature subset to a more manageable size) have become quite popular. These reduced feature subsets can help improve the performance of classification models and can also inform researchers about which features are most relevant for the problem at hand. For this latter problem, it is often most important that the features chosen are consistent even in the face of changes (perturbations) to the dataset. While previous studies have considered the problem of finding so-called “stable” feature selection techniques, none has examined stability across all three major categories of feature selection technique: filterbased feature rankers (which use statistical measures to assign scores to each feature), filter-based subset evaluators (which also employ statistical approaches, but consider whole feature subsets at a time), and wrapper-based subset evaluation (which also considers whole subsets, but which builds classification models to evaluate these subsets). In the present study, we use two datasets from the domain of Twitter profile mining to compare the stability of five filter-based rankers, two filter-based subset evaluators, and five wrapper-based subset evaluators. We find that the rankers are most stable, followed by the filter-based subset evaluators, with the wrappers being the least stable. We also show that the relative performance among the techniques within each group is consistent across dataset and perturbation level. However, the relative stability of the two datasets does vary between the groups, showing that the effects are more complex than simply “one group is always more stable than another group.” Keywords-Stability, filter-based feature selection, wrapperbased feature selection	"Feature selection is an extremely important problem across a wide range of application domains: any time a dataset has too many features, or practitioners would like to know which features are most important, feature selection can provide a reduced list with just those that matter most. A broad survey of this field is presented by Guyon and Elisseeff <NO>, who divide feature selection techniques into two broad categories: filters and wrappers. Filters are defined as any technique which uses statistical methods to find the best features from the dataset; these can score each feature individually and then rank features based on their scores, or calculate a metric from a whole feature subset to describe the goodness of that subset. Wrappers, on the other hand, incorporate learners to determine which feature subsets are actually best for building models. Embedded techniques are noted as a special case of wrapper selection, where instead of using the learner to select features and then using it again
to build a model, the feature selection is embedded directly in the model-building process.
Feature selection has been heavily studied for many years <NO>, but although feature ranking techniques have been widely examined, the increased complexity of filterbased subset evaluation and wrapper-based subset selection techniques has resulted in these being less well-studied <NO>. Even fewer works directly compare three different categories of feature selection (filter-based ranking, filter-based subset evaluation, and wrapper-based subset selection), and those that do are relatively unsophisticated: for example, Molina et al. <NO> use rankers which later research has shown to be ineffective <NO>, and the chosen subset search techniques are also fairly simple. In contrast, Gheyas and Smith <NO> propose a hybrid technique incorporating both filter and wrapperbased ideas, and compare this with other filter-wrapper hybrids, but do not consider either filters or wrappers alone. No previous works consider the previous decade of advancement in the area of feature selection to determine how feature ranking, filter-based subset evaluation, and wrapper-based subset selection compare with one another when using the best-known examples of each family.
While feature subset selection has received relatively little attention, evaluating the stability of these techniques has received even less focus. He and Yu <NO> reviewed causes of instability and stability metrics, including metrics which may be applied towards feature subset selection. Somol and Novovičová <NO> also evaluated stability metrics, using both simulated and real data to observe how different metrics can give different results as well as how three wrapper-based techniques (using a Bayesian classifier, 3-Nearest Neighbor, and Support Vector Machines) compare to one another. Yu et al. <NO> proposed both a new filter-based feature subset evaluation technique and a new stability metric for evaluating such techniques, both based on the idea of feature groups (selecting a collection of feature subsets, where the features within each subset are expected to be redundant with one another, rather than simply selecting individual features). Lustgarten et al. <NO> propose a new stability metric for feature subset evaluation (based on Kuncheva’s consistency index), and compare this metric with the Jaccard index using three wrapper-based subset selection techniques (Logistic Regression, Naı̈ve Bayes, and SVM). Dunne et al. <NO> consider wrappers using a 3-nearest neighbor learner and three choices of search technique, evaluating stability by resampling the original dataset and finding the Hamming distance between the various feature subset masks. Haury et al. <NO> evaluate a number of different feature selection techniques (primarily rankers, but including one wrapper-based subset evaluation technique using least squares regression) and consider stability in terms of how many features are in common between two subsets generated from independent subsamples of the original data. Overall, no work has considered both filter-based subset evaluation and wrapper-
based subset selection at the same time, or has examined a wide range of both learners and performance metrics within the context of wrapper-based feature selection.
The large number of users on Twitter makes it a major target for agencies seeking to create buzz for a product or service. In particular, automatically-generated advertising messages have become a significant problem for Twitter users <NO>. This has led to research focused on detecting spam on Twitter, using techniques including traditional classifiers <NO>, considering the network relationships between the sender and receiver <NO>, and evaluation of the URLs being promoted by the spammers <NO>.
In 2011, the Web Ecology Project began their Socialbot Challenge <NO> to promote the study of Twitter social bots. Three teams created bot clusters in order to elicit real users to follow and reply to their bots, accruing points based on how many users interacted with the “lead” bot on each team. Over the course of the two-week challenge, the top team was able to accumulate approximately 8 followers per day and 14 replies per day, with the latter metric far outweighing the other two competitors. An unaffiliated set of researchers, Wagner et al. <NO>, realized that the data from this challenge could help understand users who choose to follow bots. Three categories of features were extracted from each user to predict their susceptibility to bots: 70 linguistic features (which used the Linguistics Inquiry and Word Count (LIWC) <NO> package to extract word-use dimensions from users’ tweets), nine network-based features using three different forms of graph generation (a followerbased directed graph, an undirected retweet-based graph, and a raw interaction graph), and 13 behavioral features based on the scope and range of tweet contents. Using this dataset and six classification learners, Wagner et al. were able to achieve an overall accuracy of 0.71, and a closer analysis of the features shed light onto the psychological traits leading to bot susceptibility."	https://doi.org/10.1109/ICMLA.2013.162	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Wald, et al. [NO] uses two datasets from the domain of twitter profile mining to compare the stability of five filter-based rankers, two filter-based subset evaluators, and five wrapper-based subset evaluators. 
Toward automated dynamic malware analysis using cwsandbox	['In the obfuscation/deobfuscation game played between attackers and defenders, numerous anti-evasion techniques have been applied in the creation of robust in-guest API call tracers and automated deobfuscation tools <NO>.', 'Approaches that employ these ideas to obtain scalability include malware analysis services such as Norman Sandbox <NO>, CWSandbox <NO> and Anubis <NO>.']	Carsten Willems, Thorsten Holz, and Felix Freiling. 2007. Toward automated dynamic malware analysis using cwsandbox. IEEE Security and Privacy.	Malware is notoriously difficult to combat because it appears and spreads so quickly. Most security products such as virus scanners look for signatures—characteristic byte sequences—to identify malicious code. Malware, however, has adapted to that approach. Polyor metamorphic worms avoid detection by changing their appearance, for example, whereas flash worms stealthily perform reconnaissance without infecting vulnerable machines, waiting to pursue strategic spreading plans that can infect thousands of machines within seconds. In the face of such automated threats, security researchers can’t combat malicious software using manual methods of disassembly or reverse engineering. Therefore, analysis tools must analyze malware automatically, effectively, and correctly. Automating this process means that the analysis tool should create detailed reports of malware samples quickly and without user intervention. Analysts could then use the machinereadable reports to initiate automated responses—automatically updating an intrusion detection system’s signatures, for example, and protecting networks from new malware on the fly. An effective analysis tool must log the malware’s relevant behaviors—the tool shouldn’t overlook any of the executed functionality because analysts will use the information to realistically assess the threat. Finally, the tool should correctly analyze the malware—the sample should initiate every logged action to avoid false positives. In this article, we describe the design and implementation of CWSandbox, a malware analysis tool that fulfills our three design criteria of automation, effectiveness, and correctness for the Win32 family of operating systems. We show how to use API hooking and dynamic linked library (DLL) injection techniques to implement the necessary rootkit functionality to avoid detection by the malware. We acknowledge that these techniques aren’t new; however, we’ve assembled the techniques in a unique combination that provides a fully functional, elegantly simple, and arguably powerful automated malware analysis tool.	"Combining dynamic malware analysis, API hooking, and DLL injection within the CWSandbox lets analysts trace and monitor all relevant system calls and generates an automated, machine-readable report that describes
• the files the malware sample created or modified; • the changes the malware sample performed on the
Windows registry; • which DLLs the malware loaded before execution; • which virtual memory areas it accessed; • the processes that it created; • the network connections it opened and the informa-
tion it sent; and • other information, such as the malware’s access to pro-
tected storage areas, installed services, or kernel drivers.
CWSandbox’s reporting features aren’t perfect—that is, it reports only the malware’s visible behavior and not how it’s programmed, and using the CWSandbox might cause some harm to other machines connected to the network. Yet, the information derived from the CWSandbox for even the shortest of time periods is sur-
Toward Automated Dynamic Malware Analysis Using CWSandbox
32 PUBLISHED BY THE IEEE COMPUTER SOCIETY ■ 1540-7993/07/$25.00 © 2007 IEEE ■ IEEE SECURITY & PRIVACY
The authors present CWSandbox, which executes malware
samples in a simulated environment, monitors all system
calls, and automatically generates a detailed report to
simplify and automate the malware analyst’s task.
CARSTEN WILLEMS, THORSTEN HOLZ , AND FELIX FREILING University of Mannheim, Germany
prisingly rich; in most cases, it’s more than sufficient to assess the danger originating from malware.
In the following paragraphs, we introduce the individual building blocks and techniques behind CWSandbox."	https://doi.org/10.1109/MSP.2007.45	0	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']	Willems, et al. [NO] describes the design and implementation of cwsandbox, a malware analysis tool that fulfills our three design criteria of automation, effectiveness, and correctness for the win32 family of operating systems. 
Survey of clustering algorithms	['partitioning clustering are two common type of clustering methods and each of them has its own traits <NO>.']	Rui Xu, and Donald Wunsch. 2005. Survey of clustering algorithms. IEEE Transactions on Neural Networks 16, 3 (2005), 645–678.	Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.	"Different starting points and criteria usually lead to different taxonomies of clustering algorithms <NO>, <NO>, <NO>, <NO>, <NO>, <NO>. A rough but widely agreed frame is to classify clustering techniques as hierarchical clustering and partitional clustering, based on the properties of clusters generated <NO>, <NO>. Hierarchical clustering groups data objects with a sequence of partitions, either from singleton clusters to a cluster including all individuals or vice versa, while partitional clustering directly divides data objects into some prespecified number of clusters without the hierarchical structure. We follow this frame in surveying the clustering algorithms in the literature. Beginning with the discussion on proximity measure, which is the basis for most clustering algorithms, we focus on hierarchical clustering and classical partitional clustering algorithms in Section II-B–D. Starting from part E, we introduce and analyze clustering algorithms based on a wide variety of theories and techniques, including graph theory, combinatorial search techniques, fuzzy set theory, neural networks, and kernels techniques. Compared with graph theory and fuzzy set
theory, which had already been widely used in cluster analysis before the 1980s, the other techniques have been finding their applications in clustering just in the recent decades. In spite of the short history, much progress has been achieved. Note that these techniques can be used for both hierarchical and partitional clustering. Considering the more frequent requirement of tackling sequential data sets, large-scale, and high-dimensional data sets in many current applications, we review clustering algorithms for them in the following three parts. We focus particular attention on clustering algorithms applied in bioinformatics. We offer more detailed discussion on how to identify appropriate number of clusters, which is particularly important in cluster validity, in the last part of the section."	https://doi.org/10.1109/TNN.2005.845141	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Xu, et al. [NO] survey clusters algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. 
Automatic malware categorization using cluster ensemble	[]	Yanfang Ye, Tao Li, Yong Chen, and Qingshan Jiang. 2010. Automatic malware categorization using cluster ensemble. Proccedings of ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD).	Malware categorization is an important problem in malware analysis and has attracted a lot of attention of computer security researchers and anti-malware industry recently. Today’s malware samples are created at a rate of millions per day with the development of malware writing techniques. There is thus an urgent need of effective methods for automatic malware categorization. Over the last few years, many clustering techniques have been employed for automatic malware categorization. However, such techniques have isolated successes with limited effectiveness and efficiency, and few have been applied in real anti-malware industry. In this paper, resting on the analysis of instruction frequency and function-based instruction sequences, we develop an Automatic Malware Categorization System (AMCS) for automatically grouping malware samples into families that share some common characteristics using a cluster ensemble by aggregating the clustering solutions generated by different base clustering algorithms. We propose a principled cluster ensemble framework for combining individual clustering solutions based on the consensus partition. The domain knowledge in the form of sample-level constraints can be naturally incorporated in the ensemble framework. In addition, to account for the characteristics of feature representations, we propose a hybrid hierarchical clustering algorithm which combines the merits of hierarchical clustering and k-medoids algorithms and a weighted subspace K-medoids algorithm to generate base clusterings. The categorization results of our AMCS system can be used to generate signatures for malware families that are useful for malware detection. The case studies on large and real daily malware collection from Kingsoft Anti-Virus Lab demonstrate the effectiveness and efficiency of our AMCS system.	"Due to its damage to computer security, malware (such as virus, worms, Trojan Horses, spyware, backdoors, and rootkits) has caught the attention of computer security researchers for decades. Currently, the most significant line of defense against malware is AntiVirus (AV) software products which mainly use signature-based method to recognize threats. Given a collection of malware samples, these AV venders first categorize the samples into families so that samples in the same family share some common traits, and generate the common string(s) to detect variants of a family of malware samples.
For many years, malware categorization have been primarily done by human analysts, where memorization, looking up description libraries, and searching sample collections are typically required. The manual process is time-consuming and labor-intensive. Today’s malware samples are created at a rate of millions per day with the development of malware writing techniques. For example, the number of new malware samples collected by the Anti-virus Lab of Kingsoft is usually larger than 10, 000 per day. There is thus an urgent need of effective methods for automatic malware categorization.
Over the last few years, many research efforts have been conducted on developing automatic malware categorization systems <NO>. In these systems, the detection process is generally divided into two steps: feature extraction and categorization. In the first step, various features such as Application Programming Interface (API) calls and instruction sequences are extracted to capture the characteristics of the file samples. These features can be extracted via static analysis and/or dynamic analysis. In the second step, intelligent techniques are used to automatically categorize the file samples into different classes based on computational analysis of the feature representations. These intelligent malware detection systems are varied in their use of feature representations and categorization methods. They have isolated successes in clustering and/or classifying particular sets of malware samples, but they have limitations on the effectiveness and efficiency and few have
been applied in real anti-malware industry. For example, clustering techniques can be naturally used to automatically discover malware relationships <NO>. However, clustering is an inherently difficult problem due to the lack of supervision information. Different clustering algorithms and even multiple trials of the same algorithm may produce different results due to random initializations and stochastic learning methods <NO>. In this paper, resting on the analysis of instruction frequency and function-based instruction sequences of the Windows Portable Executable (PE) files, we develop AMCS for automatically grouping malware samples into families that share some common characteristics using a cluster ensemble by aggregating the clustering solutions generated by different base clustering algorithms.
To overcome the instability of clustering results and improve clustering performance, our AMCS system use a cluster ensemble to aggregate the clustering solutions generated by different algorithms. We develop new base clustering algorithms to account for the different characteristics of feature representations and propose a novel cluster ensemble framework for combining individual clustering solutions. We show that the domain knowledge in the form of sample-level constraints can be naturally incorporated in the ensemble framework. To the best of our knowledge, this is the first work of applying such cluster ensemble methods for malware categorization. In short, our AMCS system has the following major traits:
• Well-Chosen Feature Representations: Instruction frequency and function-based instruction sequences are used as malware feature representations. These instruction-level features well represent variants of malware families and can be efficiently extracted. In addition, these features can be naturally used to generate signatures for malware detection.
• Carefully-Designed Base Clusterings: The choice of base clustering algorithms is largely dependent on the underlying feature distributions. To deal with the irregular and skewed distributions of instruction frequency features, we propose a hybrid hierarchical clustering algorithm which combines the the merits of hierarchical clustering and k-medoids algorithms. To identify the hidden structures in the subspace of function-based instruction sequences, we use a weighted subspace K-medoids algorithm to generate base clusterings.
• A Principled Cluster Ensemble Scheme: Our AMCS system uses a cluster ensemble scheme to combine the clustering solutions of different algorithms. Our cluster ensemble scheme is a principled approach based on the consensus partition and is able to utilize the domain knowledge in the form of sample-level constraints.
• Human-in-the-Loop: In many cases, the domain knowledge and expertise of virus analysts can greatly help improve the categorization results. Our AMCS system offers a mechanism to incorporate the domain knowledge in the form of sample-level constraints (such as, some file samples are variants of a single malware; or some file samples belong to different malware types).
• Natural Application for Signature Generation: The categorization results generated by our AMCS system can be naturally used to generate signatures for each malware family. These signatures are very useful for malware detection.
All these traits make our AMCS system a practical solution for automatic malware categorization. The case studies on large and real daily malware collection from Kingsoft Anti-Virus Lab demonstrate the effectiveness and efficiency of our AMCS system. As a result, our AMCS has already been incorporated into Kingsoft’s Anti-Virus software products. The rest of this paper is organized as follows. Section 2 presents the overview of our AMCS system and Section 3 discusses the related work. Section 4 describes the feature extraction and representation; Section 5 introduces the base clustering methods we proposed to account for different characteristics of feature representations; Section 6 presents the cluster ensemble framework used in our AMCS system. In Section 7, using the daily data collection obtained from Kingsoft Anti-virus Lab, we systematically evaluate the effects and efficiency of our AMCS system in comparison with other proposed classification/clustering methods, as well as some of the popular Anti-Virus software such as Kaspersky and NOD32. Section 8 presents the details of system development and operation. Finally, Section 9 concludes our discussion."	https://doi.org/10.1145/1835804.1835820	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Ye, et al. [NO] develops an automatic malware categorization system (amcs) for automatically grouping malware samples into families that share some common characteristics using a cluster ensemble by aggregating the clustering solutions generated by different base clustering algorithms. 
Combining file content and file relations for cloud based malware detection	['<NO> presents a malware detection approach that combines file-to-file relationship data with features extracted at the individual file level.', 'There has been a rising interest in performing virus classification in the cloud <NO> due to the constraints of users’ resources.', 'Due to Internet propagation malware has been rapidly spreading and infecting computers around the world at an unprecedented rate <NO> and malware detection became one of the top internet security topics <NO>.', 'Valkyrie Technology by Comodo <NO> is based on a semiparametric classifier model to combine file content and file relations for malware detection.']	Yanfang Ye, Tao Li, Shenghuo Zhu, Weiwei Zhuang, Egemen Tas, Umesh Gupta, and Melih Abdulhayoglu. 2011. Combining file content and file relations for cloud based malware detection. Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD).	Due to their damages to Internet security, malware (such as virus, worms, trojans, spyware, backdoors, and rootkits) detection has caught the attention not only of anti-malware industry but also of researchers for decades. Resting on the analysis of file contents extracted from the file samples, like Application Programming Interface (API) calls, instruction sequences, and binary strings, data mining methods such as Naive Bayes and Support Vector Machines have been used for malware detection. However, besides file contents, relations among file samples, such as a “Downloader” is always associated with many Trojans, can provide invaluable information about the properties of file samples. In this paper, we study how file relations can be used to improve malware detection results and develop a file verdict system (named “Valkyrie”) building on a semi-parametric classifier model to combine file content and file relations together for malware detection. To the best of our knowledge, this is the first work of using both file content and file relations for malware detection. A comprehensive experimental study on a large collection of PE files obtained from the clients of anti-malware products of Comodo Security Solutions Incorporation is performed to compare various malware detection approaches. Promising experimental results demonstrate that the accuracy and efficiency of our Valkyrie system outperform other popular anti-malware software tools such as Kaspersky AntiVirus and McAfee VirusScan, as well as other alternative data mining based detection systems. Our system has already been incorporated into the scanning tool of Comodo’s Anti-Malware software.	"Malware is software designed to infiltrate or damage a computer system without the owner’s informed consent (e.g., virus, worms, trojans, spyware, backdoors, and rootkits) <NO>. Numerous attacks made by the malware pose a major security threat to Internet users <NO>. Hence, malware detection is one of the internet security topics that are of great interest <NO>. Currently, the most significant line of defense against malware is antimalware software products, such as Kaspersky, MacAfee and Comodo’s Anti-Malware software. Typically, these widely used malware detection software tools use the signature-based method to recognize threats. Signature is a short string of bytes, which is unique for each known malware so that its future examples can be correctly classified with a small error rate.
However, driven by the economic benefits, malware writers quickly invent counter-measures against proposed malware analysis tech-
niques, chief among them being automated obfuscation <NO>. Because of automated obfuscation, today’s malware samples are created at a rate of thousands per day. Figure 1 shows the increasing trend of malware samples in P.R.China from Year 2003 to Year 2010 (this data is provided by Comodo China Anti-Malware Lab). It can be observed that the number of malware samples has increased sharply since 2008. In fact the number of malware samples in 2008 alone is much larger than the total sum of previous five years.
Nowdays malware samples increasingly employ techniques such as polymorphism <NO>, metamorphism <NO>, packing, instruction virtualization, and emulation to bypass signatures and defeat attempts to analyze their inner mechanisms <NO>. In order to remain effective, many Anti-Malware venders have turned their classic signaturebased method to cloud (server) based detection. The work flow of the cloud based detection method adopted by Comodo Security Solutions Incorporation is shown in Figure 2.
The work flow of this cloud based malware detection scheme can be described as follows:
1. On the client side, users may receive new files from emails, media or IM(Instant Message) tools when they are using the Internet.
2. Anti-malware products will first use the signature set on the clients for scanning. If these new files are not detected by existing signatures, then they will be marked as “unknown”.
3. In order to detect malware from the unknown file collection, file features (like file content as well as the file relations) are extracted and sent to Comodo Cloud Security Center.
4. Based on these collected features, the classifier(s) on the cloud server will predict and generate the verdicts for the unknown file samples, either benign or malicious.
5. Then the cloud server will send the verdict results to the clients and notify the clients immediately.
6. According to the response from the cloud server, the scanning process can detect new malware samples and remove the threats.
7. Due to the fast response from the cloud server, the client users can have most up-to-date security solutions.
To sum-up, using the cloud-based architecture, malware detection is now conducted in a client-server manner: authenticating valid software programs from a whitelist and blocking invalid software programs from a blacklist using the signature-based method at the client (user) side, and predicting any unknown software (i.e., the gray list) at the cloud (server) side and quickly generating the verdict results to the clients within seconds. The gray list, containing unknown software programs which could be either benign or malicious, was usually authenticated or rejected manually by malware analysts before. With the development of the malware writing techniques, the number of file samples in the gray list that need to be analyzed by malware analysts on a daily basis is constantly increasing. For example, the gray list collected by the Anti-Malware Lab of Comodo Security Solutions Incorporation usually contains about 500,000 file samples per day. Therefore, there is an urgent need for anti-malware industry to develop intelligent methods for efficient and effective malware detection at the cloud (server) side.
Recently, many research efforts have been conducted on developing intelligent malware detection systems <NO>. In these systems, the detection process is generally divided into two steps: feature extraction and classification. In the first step, various features such as Application Programming Interface (API) calls <NO> and program strings <NO> are extracted to capture the characteristics of the file samples. In the second step, intelligent classification techniques such as decision trees <NO>, Naive Bayes, and associative classifiers <NO> are used to automatically classify the file samples into different classes based on computational analysis of the feature representations. These intelligent malware detection systems are varied in their use of feature representations and classification methods. For example, IMDS <NO> performs association classification on Windows API calls extracted from executable files, while Naive Bayes methods on the extracted strings and byte sequences are applied in <NO>.
These intelligent techniques have isolated successes in classifying particular sets of malware samples, but they have limitations that leave a large room for improvement. In particular, none of these techniques have taken the relationships among file samples into consideration for malware detection. Simply treating file programs as independent samples allows many off-the-shelf classification tools to be directly adapted for malware classification. However, the relationships among file samples may imply the interdependence among them and thus the usual i.i.d (independent and identical distributed) assumption may not hold for malware sam-
ples. As a result, ignoring the relations among file samples is a significant limitation of current malware classification methods. For malware detection, the relations among file samples provide invaluable information about their properties. Here we use some examples for illustration. Based on the collected file lists from clients, we construct a co-occurrence graph to describe the relations among file samples. Generally, two files are related if they are shared by many clients (or equivalently, file lists). As shown in Figure 3, we can observe that the file “yy(1).exe” is associated with many trojans which are marked as purple color. Actually, this “yy(1).exe” file is a kind of Trojan-Downloader malware. Trojan-Downloader refers to any malicious software that downloads and installs multiple unwanted applications of adware and malware from remote servers. Malware samples of this type are spread from malicious websites or by emails as attachments or links, and are installed secretly without the user’s consent. Therefore, from the relations shown in Figure 3, we can infer that if an unknown file always co-occurs with many kinds of trojans in users’ computers, then most likely, it is a malicious Trojan-Downloader file.
Another example showing the relations among benign files is illustrated in Figure 4. From Figure 4, we can observe that an unknown file “everest.exe” can be possibly recognized as benign since it is always associated with known benign files marked in green color. Actually, this “everest.exe” is a benign system diagnostic application which always co-occurs with its related Dynamic Link Library files, such as, “everest_start.dll”, “everest_mondiag.dll”, “everest_rcs.dll” and so on.
Sometime it is not easy to determine whether a file is malicious or not solely based on file content information itself. According to the experience and knowledge of our anti-malware experts, file relations among samples can be a novel and practical feature representation for malware detection. Some malware samples may have stronger connections with benign files than malicious ones. In such cases, those file samples might be infected files. Actually, these unexpected relations can be filtered and removed, because the infected samples can be detected independently using the infected file detector which is developed by our anti-malware experts. To improve the performance of file sample classification for malware detection, in this paper, we utilize both file content and file relation information. However, relation information and file content have different properties. Relation information provides a graph
structure in the data and induces pairwise similarity between objects while the file content provides inherent characteristic information about the file samples. Although both the relation information and file content can be used independently to classify file samples, classification algorithms that make use of them simultaneously should be able to achieve a better performance.
The problem of combining content information and relation information (i.e., link information) have been widely studied for web document categorization in data mining and information retrieval community <NO>. The approaches for combining content and link information generally fall into two categories: (1) feature integration which treats the relation information as additional features and enlarges the feature representation <NO>; and (2) Kernel Integration which integrates the data at the similarity computation or the Kernel level <NO>. However, both types of approaches have limitations: feature integration may degrade the quality of information as file relations and file content typically have different properties, while kernel integration fails to explore the correlation and the inherent consistency between the content information and the relation information <NO>. In this paper, we propose a semi-parametric classification model for combining file content and file relations. The semi-parametric model consists of two components: a parametric component reflecting file content information and a non-parametric component reflecting file relation information. The model seamlessly integrates these two components and formulates the classification problem using the graph regularization framework. Our model can be viewed as an extension of recently developed joint-embedding approaches which aims to seek a common low-dimensional embedding via joint factorization of both the content and relation information <NO>. However, different from the joint-embedding approaches, our model does not explicitly infer the embedding and is directly optimized for classification. We develop a file verdict system (named ""Valkyrie"") using the proposed model to integrate file content and file relations for malware detection. To the best of our knowledge, this is the first work of using both file content and file relations for malware detection. In short, our developed Valkyrie system has the following major traits:
• Novel Usage of File Relation: Different from previous studies for malware detection, we not only make use of file content, but also use the file relations for malware detection.
• A Principled Model for Combining File Content and File Relations: We propose a semi-parametric classification model
to seamlessly combine file content and file relation, and formulate the classification problem using the graph regularization framework.
• A Practical Developed System for Real Industry Application: Based on 37,930 clients, we obtain 30,950 malware samples, 225,830 benign files and 434,870 unknown files from Comodo Cloud Security Center. We build a practical system for malware detection and provide a comprehensive experimental study.
All these traits make our Valkyrie system a practical solution for automatic malware detection. The case studies on large and real daily malware collection from Comodo Cloud Security Center demonstrate the effectiveness and efficiency of our Valkyrie system. As a result, our Valkyrie system has already been incorporated into the scanning tool of Comodo’s Anti-Malware software. The rest of this paper is organized as follows. Section 2 presents the overview of our Valkyrie system. Section 3 describes the feature extraction and representation; Section 4 introduces the proposed semi-parametric model combining file content and file relations together for malware detection; In Section 5, using the daily data collection obtained from Comodo Cloud Security Center, we systematically evaluate the effectiveness and efficiency of our Valkyrie system in comparison with other proposed classification methods, as well as some of the popular Anti-Malware software such as Kaspersky and NOD32. Section 6 presents the details of system development and operation. Section 7 discusses the related work. Finally, Section 8 concludes the paper."	https://doi.org/10.5555/1025118.1025582	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Ye, et al. [NO] studies how file relations can be used to improve malware detection results and develop a file verdict system (named “ valkyrie ”) building on a semi-parametric classifier model to combine file content and file relations together for malware detection. 
IMDS: Intelligent malware detection system	"['<NO> developed Intelligent Malware Detection System (IMDS) that used Objective-Oriented Association (OOA) mining based classification.', 'API/System Calls Static Hybrid <NO>, <NO> Dynamic Anomaly <NO>', '<NO> proposed Intelligent Malware Detection System (IMDS) using Object Oriented Association (OOA) mining based classification.', 'API <NO> Detects polymorphic and unknown malware.', 'Hence, malware detection is one of the internet security topics that are of great interest <NO>.', 'Recently, many research efforts have been conducted on developing intelligent malware detection systems <NO>.', 'In the first step, various features such as Application Programming Interface (API) calls <NO> and program strings <NO> are extracted to capture the characteristics of the file samples.', 'In the second step, intelligent classification techniques such as decision trees <NO>, Naive Bayes, and associative classifiers <NO> are used to automatically classify the file samples into different classes based on computational analysis of the feature representations.', 'For example, IMDS <NO> performs association classification on Windows API calls extracted from executable files, while Naive Bayes methods on the extracted strings and byte sequences are applied in <NO>.', 'PE is designed as a common file format for all flavor of Windows operating system, and PE malware are in the majority of the malware rising in recent years <NO>.', 'We extract the Application Programming Interface (API) calls from the Import Tables <NO> of collected malicious and benign PE files, convert them to a group of 32-bit global IDs (for example, the API ""MAPI32.', 'Compared with dynamic feature extraction methods, static feature extraction methods are easier and less expensive <NO>.', 'Classification: For classification, over the last couple of years, many data mining and machine learning approaches have been adopted for malware detection <NO>.', 'Naive Bayes method, Support Vector Machine(SVM), decision tree and associative classification methods are applied to detect new malicious executables in previous studies <NO>.', 'So far, several data mining and machine-learning approaches have been used in malware detection <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'In our previous paper <NO>, <NO>, since', 'tion <NO>, <NO>, <NO>, <NO>, <NO>, <NO>, <NO>.', 'Due to the fact that frequent itemsets (sets of API calls) discovered by association mining can well represent the underlying semantics (profiles) of malware and benign file datasets, associative classification has been successfully used in the IMDS system developed in <NO>', 'It can be effectively used in malware detection <NO>, <NO>, since frequent itemsets are typically of statistical significance and classifiers based on frequent pattern analysis are', 'Based on the system architecture of our previous malware detection system IMDS <NO>, we extract the API calls as the features of the file samples and store them in the signature database.', 'For rule generation, we use the OOA_Fast_FP-Growth algorithm proposed in <NO> to derive the complete set of the rules with certain support and confidence thresholds, since it is much faster than Apriori for mining frequent itemsets.', 'In our paper, based on the complete set of the rules generated by the malware detection rule generator, IMDS applied the technique of CBACB <NO> to build a classifier as the malware detection module to predict new file samples <NO>.', 'By using the OOA_Fast_FP-Growth algorithm <NO>, <NO>, we generate 31', 'Over the last few years, many research efforts have been conducted on developing intelligent malware detection systems <NO>.', 'For example, IMDS <NO> performs association classification on Windows API calls extracted from executable files while Naive Bayes methods on the extracted strings and byte sequences are applied in <NO>.', 'Both classifiers have been successfully used in malware detection <NO> and have distinct properties.', 'Recently, associative classification <NO>, with its ability to utilize relationships among attributes, has been also applied in <NO>.', '2) Both associative classification and SVM have been successfully applied in malware detection <NO>.', 'Various classification approaches including association classifiers, support vector machines, and Naive Bayes have been applied in malware detection <NO>.']"	Yanfang Ye, Dingding Wang, Tao Li, and Dongyi Ye. 2007. IMDS: Intelligent malware detection system. Proccedings of ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD).	The proliferation of malware has presented a serious threat to the security of computer systems. Traditional signature-based antivirus systems fail to detect polymorphic and new, previously unseen malicious executables. In this paper, resting on the analysis of Windows API execution sequences called by PE files, we develop the Intelligent Malware Detection System (IMDS) using ObjectiveOriented Association (OOA) mining based classification. IMDS is an integrated system consisting of three major modules: PE parser, OOA rule generator, and rule based classifier. An OOA Fast FPGrowth algorithm is adapted to efficiently generate OOA rules for classification. A comprehensive experimental study on a large collection of PE files obtained from the anti-virus laboratory of KingSoft Corporation is performed to compare various malware detection approaches. Promising experimental results demonstrate that the accuracy and efficiency of our IMDS system outperform popular anti-virus software such as Norton AntiVirus and McAfee VirusScan, as well as previous data mining based detection systems which employed Naive Bayes, Support Vector Machine (SVM) and Decision Tree techniques.	"Besides the traditional signature-based malware detection methods, there is some work to improve the signature-based detection <NO> and also a few attempts to apply data mining and machine learning techniques to detect new malicious executables.
Sung et al. <NO> developed a signature based malware detection system called SAVE (Static Analyzer of Vicious Executables) which emphasized on detecting polymorphic malware. The basic idea of this approach is to extract the signatures from the original malware with the hypothesis that all versions of the same malware
share a common core signature. Schultz et al. <NO> applied Naive Bayes method to detect previously unknown malicious code. Decision Tree was studied in <NO>. Kolter et al. <NO> gathered 1971 benign executables and 1651 malicious executables in Windows PE format, and examined the performance of different classifiers such as Naive Bayes, support vector machine (SVM) and Decision Tree using 10-fold cross validation and plotting ROC curves <NO>. Their results also showed that the ROC curve of the Decision Tree method dominated all others.
Different from earlier studies, our work is based on a large collection of malicious executables collected at KingSoft Anti-Virus Laboratory. In addition, we apply OOA mining technique to extract the characterizing frequent patterns to achieve accurate malware detection since frequent patterns found by association mining carry the underlying semantics of the data."	https://doi.org/10.1145/1281192.1281308	3	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']	Ye, et al. [NO] develops the intelligent malware detection system (imds) using objectiveoriented association (ooa) mining based classification. 
Panorama: Capturing system-wide information flow for malware detection and analysis	[', Polyglot <NO> and Panorama <NO>), Siren <NO> and oth-', 'BitBlaze has been shown to provide reliable data that has been used to produce very accurate malware classification results <NO>.', 'The first phase is implemented by the execution monitor <NO>.', 'Capturing information flow in dependence graphs: Existing techniques for constructing dependence graphs from programs provide only data-flow (and sometimes controlflow) dependencies between operations <NO>, <NO>, <NO>.', 'Previous work has shown that using data flows to describe malicious behavior is a powerful approach <NO>, <NO>, <NO> and that the system-call interface is the right abstraction for characterizing user-space malware <NO>,', 'HOLMES builds on existing work for creating the behavior graph and will benefit from more powerful tools that use, for example, dynamic taint tracing <NO>, <NO> and multipath analysis <NO>.', 'describe a behavioral specification of browser-based spyware based on taint-tracking <NO>, and Panorama uses whole-system taint analysis in a similar vein to detect more general classes of spyware <NO>.']	Heng Yin, Dawn Song, Manuel Egele, Christopher Kruegel, and Engin Kirda. 2007. Panorama: Capturing system-wide information flow for malware detection and analysis. Proceedings of the 14th ACM Conference on Computer and Communications Security (CCS).	Malicious programs spy on users’ behavior and compromise their privacy. Even software from reputable vendors, such as Google Desktop and Sony DRM media player, may perform undesirable actions. Unfortunately, existing techniques for detecting malware and analyzing unknown code samples are insufficient and have significant shortcomings. We observe that malicious information access and processing behavior is the fundamental trait of numerous malware categories breaching users’ privacy (including keyloggers, password thieves, network sniffers, stealth backdoors, spyware and rootkits), which separates these malicious applications from benign software. We propose a system, Panorama, to detect and analyze malware by capturing this fundamental trait. In our extensive experiments, Panorama successfully detected all the malware samples and had very few false positives. Furthermore, by using Google Desktop as a case study, we show that our system can accurately capture its information access and processing behavior, and we can confirm that it does send back sensitive information to remote servers in certain settings. We believe that a system such as Panorama will offer indispensable assistance to code analysts and malware researchers by enabling them to quickly comprehend the behavior and inner-workings of an unknown sample.	D.4.6 <NO>: Security and Protection—Invasive software	https://doi.org/10.5555/1025118.1025582	2	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']	Yin, et al. [NO] observes that malicious information access and processing behavior is the fundamental trait of numerous malware categories breaching users ’ privacy (including keyloggers, password thieves, network sniffers, stealth backdoors, spyware and rootkits), which separates these malicious applications from benign software. 
