	ref_title	ref_context	ref_entry	abstract	intro	ref_link	label	topic_word	topic_bigram	topic_trigram	description
2	Understanding the impact of multi-core architecture in cluster computing: A case study with Intel dual-core system	[]	Lei Chai, Qi Gao, and Dhabaleswar K. Panda. 2007. Understanding the impact of multi-core architecture in cluster computing: A case study with Intel dual-core system. 7th IEEE International Symposium on Cluster Computing and the Grid (CCGRID’07). IEEE, 471–478. DOI:http://dx.doi.org/10.1109/ CCGRID.2007.119.	Multi-core processors are growing as a new industry trend as single core processors rapidly reach the physical limits of possible complexity and speed. In the new Top500 supercomputer list, more than 20% processors belong to the multi-core processor family. However, without an indepth study on application behaviors and trends on multicore clusters, we might not be able to understand the characteristics of multi-core cluster in a comprehensive manner and hence not be able to get optimal performance. In this paper, we take on these challenges and design a set of experiments to study the impact of multi-core architecture on cluster computing. We choose to use one of the most advanced multi-core servers, Intel Bensley system with Woodcrest processors, as our evaluation platform, and use benchmarks including HPL, NAMD, and NAS as the applications to study. From our message distribution experiments, we find that on an average about 50% messages are transferred through intra-node communication, which is much higher than intuition. This trend indicates that optimizing intranode communication is as important as optimizing internode communication in a multi-core cluster. We also observe that cache and memory contention may be a potential bottleneck in multi-core clusters, and communication middleware and applications should be multi-core aware to alleviate this problem. We demonstrate that multi-core aware algorithm, e.g. data tiling, improves benchmark execution time by up to 70%. We also compare the scalability of a multi-core cluster with that of a single-core cluster and find that the scalability of the multi-core cluster is promising. ∗This research is supported in part by DOE’s Grants#DE-FC0206ER25749 and #DE-FC02-06ER25755; NSF’s Grants #CNS-0403342 and #CNS-0509452; grants from Intel, Mellanox, Cisco systems, Linux Networx and Sun Microsystems; and equipment donations from Intel, Mellanox, AMD, Apple, Appro, Dell, Microway, PathScale, IBM, SilverStorm and Sun Microsystems.	"Multi-core means to integrate two or more complete computational cores within a single chip <NO>. The motivation is the fact that scaling up processor speed results in dramatic rise in power consumption and heat generation. In addition, it becomes more difficult to increase processor speed nowadays that even a little increase in performance will be costly. Realizing these factors, computer architects have proposed multi-core processors that speed up application performance by dividing the workload among multiple processing cores instead of using one “super fast” single processor. Multi-core processor is also referred to as Chip Multiprocessor (CMP). Since a processing core can
be viewed as an independent processor, in this paper we use processor and core interchangeably.
Most processor vendors have multi-core products, e.g. Intel Quad- and Dual-Core Xeon, AMD Quad- and DualCore Opteron, Sun Microsystems UltraSPARC T1 (8 cores), IBM Cell, etc. There are various alternatives in designing cache hierarchy organization and memory access model. Figure 1 illustrates two typical multi-core system designs. The left box shows a NUMA <NO> based dual-core system in which each core has its own L2 cache. Two cores on the same chip share the memory controller and local memory. Processors can also access remote memory, although local memory access is much faster. The right box shows a bus based dual-core system, in which two cores on the same chip share the same L2 cache and memory controller, and all the cores access the main memory through a shared bus.
Multi-core processors have been deployed in cluster computing. In a multi-core cluster, there are three levels of communication as shown in Figure 1. The communication between two processors on the same chip is referred to as intra-CMP communication in this paper. The communication across chips but within a node is referred to as inter-CMP communication. And the communication between two processors on different nodes is referred to as inter-node communication. Multi-core clusters impose new challenges in software design, both at the middleware level and application level."	https://doi.org/10.1109/CCGRID.2007.119	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Chai, et al. [NO] might not is able to understand the characteristics of multi-core cluster in a comprehensive manner and hence not be able to get optimal performance. 
8	Virtual machine scheduling for multicores considering effects of shared on-chip last level cache interference	[]	Shin-gyu Kim, Hyeonsang Eom, and Heon Y. Yeom. 2012. Virtual machine scheduling for multicores considering effects of shared on-chip last level cache interference. International Green Computing Conference (IGCC). IEEE, 1–6. DOI:http://dx.doi.org/ 10.1109/IGCC.2012.6322250	As the cloud markets grow, the cloud providers are faced with new challenges such as reduction of power consumption and guaranteeing service level agreements (SLAs). One reason for these problems is the use of server consolidation policy based on virtualization technologies for maximizing the efficiency of resource usage. Because current virtualization technologies do not ensure performance isolation among active virtual machines (VMs), it is required to consider resource usage pattern of VMs to improve total throughput and quality of service. In this paper, we propose a virtual machine scheduler for multicore processors, which exploits the lastlevel cache (LLC) reference ratio. Specifically, we focus on the performance impact of contention in a shared LLC. We have found that the ratio of the number of LLC references to that of instructions (LLC reference ratio) is highly associated with the amount of cache demand, and a Performance-Maximizing VM (PMV) scheduling algorithm can be devised by using the ratio. We show that our PMV scheduler is effective by evaluation for various workloads. Keywords-Virtual machine consolidation; Shared resource interference; Multicore processor	In this section, we describe a cache hierachy in modern multicore processors and how to characterize cache demand of a workload by LLC reference ratio.	https://doi.org/10.1109/IGCC.2012.6322250	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Kim, et al. [NO] proposes a virtual machine scheduler for multicore processors, which exploits the lastlevel cache (llc) reference ratio. 
15	The current state of understanding of the energy efficiency of cloud computing	[]	Francis Owusu, and Colin Pattinson. 2012. The current state of understanding of the energy efficiency of cloud computing. IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom’12). 1948–1953. DOI:http://dx.doi.org/10.1109/TrustCom.2012.270	Cloud computing has been hailed as the achievement of the longheld dream of computing as a utility and has the potential to transform a large part of the Information and Communication Technology (ICT) industry. Cloud computing is both a business and an economic model which has been gaining popularity since 2006 and it is currently the most talked about technology in the ICT industry. Because it views hardware and software as commodities, the cloud is an example of a disruptive technology. It offers enterprises the opportunity to reduce hardware and software cost and the potential reduction of maintenance and support staff. Data centers and cloud computing services providers hope that the widespread adoption of the cloud will bring them more profit and they are actively promoting the technology. The cloud has had its share of controversy; ranging from the definition of cloud computing to its energy efficiency. This paper discusses one area of controversy; the energy efficiency of cloud computing. We outline previous contributions to the discussion of energy efficiency of cloud computing, provide a working definition of cloud computing and discuss its importance, which will grow as the technology matures and becomes well known.	"Arif wrote that cloud computing has evolved through a number of phases including grid and utility computing, and application service provision (ASP) <NO>. Arif wrote Salesforce.com pioneered the concept of delivering enterprise applications via a website in 1999 followed by Amazon Web Services for storage and computation in 2002. Cloud computing started gaining general popularity in 2006 when Amazon launched its Elastic Compute Cloud (EC2) as a commercial web service, allowing small businesses and individuals to rent computing resources. After the introduction of Web 2.0, Google and others started to offer browser-based enterprise applications such as Google Apps in 2009. Other technologies enabling the evolution of cloud computing include virtualization and broadband. The many definitions of cloud computing has generated some controversy because the technology is new and not well understood resulting in confusion among IT professionals and vendors. This confusion was captured in “Twenty one experts define cloud computing” when these experts gave twenty one different definitions for cloud computing <NO>.
978-0-7695-4745-9/12 $26.00 © 2012 IEEE DOI 10.1109/TrustCom.2012.270
1948
Gartner lamented that the contrasting views on cloud computing are causing confusion then added their own definition by defining cloud computing as ""a style of computing where scalable and elastic IT-enabled capabilities are provided 'as a service' to external customers using Internet technologies” <NO>. IDC defines it as ""an emerging IT development, deployment and delivery model, enabling realtime delivery of products, services and solutions over the Internet"" <NO>. Accenture defines cloud computing as “the dynamic provisioning of IT capabilities, whether hardware, software, or services from a third party over the network” <NO>. Kenneth K. Chellappa gave the first academic definition of cloud computing as “a computing paradigm where the boundaries of computing will be determined by economic rationale rather than technical limits” <NO>. Ambrust et al writes that “Cloud computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the data centers that provide those services” <NO>. Although there are many different definitions for cloud computing, there is a broad consensus on the definition by the National Institute of Standards and Technology (NIST). They define cloud computing as: “A model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model promotes availability and is composed of five essential characteristics, three service models, and four deployment models”. This paper accepts the NIST definition but with the understanding that “network” comprises the telecommunication networks and the Internet. The hope of many is that a standard definition will be found and adopted as the technology matures.
III. COMPONENTS OF CLOUD COMPUTING AND THEIR ENERGY EFFICIENCY
Cloud computing can be considered as a system with three main components."	https://doi.org/10.1145/1735971.1736048	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Owusu, et al. [NO] discusses one area of controversy ; the energy efficiency of cloud computing. 
16	Variation-aware server placement and task assignment for data center power minimization	[]	Ali Pahlavan, Mahmoud Momtazpour, and Maziar Goudarzi. 2012. Variation-aware server placement and task assignment for data center power minimization. 2012 IEEE 10th International Symposium	Size and number of data centers are fast growing all over the world and their increasing total power consumption is a worldwide concern. Moreover, increase in the amount of process variation in nanometer technologies and its effect on total power consumption of servers has made it inevitable to move toward variation-aware power reduction strategies. This paper formulates a variation-aware joint server placement and task assignment method using Integer Linear Programming (ILP) to minimize total power consumption of data centers. We first determine the optimum placement of servers in the data center racks based on total power consumption of each server and the data center recirculation model obtained by Computational Fluid Dynamics (CFD) simulations. Then, we dynamically consolidate the ON servers in chassis and racks such that the use of powergreedy servers is minimized. Experimental results reveal up to 14.85% and an average of 8.92% power saving at different server utilization rates with respect to conventional methods. Keywords-Data center, Power reduction, Process variation, Server placement, Task assignment.	"The authors in <NO> proposed a method to minimize the total energy consumption of data center while considering thermal management for their reliable function. They have used CFDbased simulations in order to evaluate their task scheduling methods such as Minimal Computing Energy (MCE) which is the best one among others. The aforementioned algorithm tries to minimize the total number of running servers and turn off all other idle ones. The algorithm first assigns the tasks to the nodes having the lowest inlet temperature. In another CFDbased work <NO> an analysis of a data center with temperature variation has been presented. The authors have obtained static provisioning for an arbitrary distribution of cooling resources that will lead to a reference state. They try to minimize the inlet temperature by dividing the workload on other available systems.
CFD-based techniques are often time consuming and complex. This issue will not lead to tackling online scheduling problem efficiently <NO>. Therefore, fast thermal evaluation models are developed such as <NO>, <NO>. In <NO>, the goal is to reduce the peak inlet temperature in order to obtain the lowest power consumption of cooling system using heat recirculation model. As a result, 20% to 30% cooling power saving will occur in different data center utilization rates. In <NO> fast prediction of temperature distribution is done using distributed sensors to reduce energy consumption in high performance data centers considering recirculation properties. So, this method is suitable for real time and online management. The authors in <NO> demonstrated a thermal aware resource management method considering heat transfer properties and workloads having thermal features. Their scheduling algorithm will result in reduced power consumption without performance degradation.
Reference <NO> presented the chassis consolidation technique as a mathematical optimization problem and a heuristic algorithm. Optimization problem has been solved via ILP. Their experiments show that they gain 13% power saving for different utilization rates in comparison with the technique lacking consolidation.
None of the above works considers process variation effects on total power consumption of high performance servers. As will be explained below, variability effects in nanometer-scale technologies has caused dramatic variations in leakage and total power consumption of processor cores especially in high performance processors <NO>. Such variation effects are visible in today processors and are expected to further rise with technology scaling when further approaching atomic scales. Process variation effects are already studied in highperformance multiprocessor and embedded systems <NO>, <NO>, <NO>, but to the best of our knowledge such effects have not been previously considered at data center scales."	https://doi.org/10.1109/ISPA.2012.29	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Pahlavan, et al. [NO] formulates a variation-aware joint server placement and task assignment method using integer linear programming (ilp) to minimize total power consumption of data centers. 
