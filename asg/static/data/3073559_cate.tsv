top_n_words	label	title	abstract	topic_word	topic_bigram	topic_trigram
view avoid static kernel multiple source dynamic framework classification research avenue collected conjunction disguising extended facet hope incorporate integrate intent 	0	Improving malware classification: Bridging the static/dynamic gap	Malware classification systems have typically used some machine learning algorithm in conjunction with either static or dynamic features collected from the binary. Recently, more advanced malware has introduced mechanisms to avoid detection in these views by using obfuscation techniques to avoid static detection and execution-stalling techniques to avoid dynamic detection. In this paper we construct a classification framework that is able to incorporate both static and dynamic views into a unified framework in the hopes that, while a malicious executable can disguise itself in some views, disguising itself in every view while maintaining malicious intent will prove to be substantially more difficult. Our method uses kernels to place a similarity metric on each distinct view and then employs multiple kernel learning to find a weighted combination of the data sources which yields the best classification accuracy in a support vector machine classifier. Our approach opens up new avenues of malware research which will allow the research community to elegantly look at multiple facets of malware simultaneously, and which can easily be extended to integrate any new data sources that may become popular in the future.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
dbi valgrind dba framework build heavyweight shadow value tool focus difficult little built checker comparatively crucial describes dynamorio exploited impossible 	0	Valgrind: A framework for heavyweight dynamic binary instrumentation	Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited. In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values—a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
code renovo hidden run memory execution engineering reverse time determines handle hinder intrinsic monitor newly original packing prevalent researched term 	0	Renovo: A hidden code extractor for packed executables	As reverse engineering becomes a prevalent technique to analyze malware, malware writers leverage various anti-reverse engineering techniques to hide their code. One technique commonly used is code packing as packed executables hinder code analysis. While this problem has been previously researched, the existing solutions are either unable to handle novel samples, or vulnerable to various evasion techniques. In this paper, we propose a fully dynamic approach that captures an intrinsic nature of hidden code execution that the original code should be present in memory and executed at some point at run-time. Thus, this approach monitors program execution and memory writes at run-time, determines if the code under execution is newly generated, and then extracts the hidden code of the executable. To demonstrate its effectiveness, we implement a system, Renovo, and evaluate it with a large number of real-world malware samples. The experiments show that Renovo is accurate compared to previous work, yet practical in terms of performance.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
recognition pattern selection neural extraction statistical field attention research design 50 among careful challenging cursive definition estimation exciting following forefront 	0	Statistical pattern recognition: A review	ÐThe primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field. Index TermsÐStatistical pattern recognition, classification, clustering, feature extraction, feature selection, error estimation, classifier combination, neural networks.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
hidden code want identifying extracting runtime malware body checked compiletime define deriving detail executing formally instance modern observation obstacle portion 	0	PolyUnpack: Automating the hidden-code extraction of unpack-executing malware	Modern malware often hide the malicious portion of their program code by making it appear as data at compiletime and transforming it back into executable code at runtime. This obfuscation technique poses obstacles to researchers who want to understand the malicious behavior of new or unknown malware and to practitioners who want to create models of detection and methods of recovery. In this paper we propose a technique for automating the process of extracting the hidden-code bodies of this class of malware. Our approach is based on the observation that sequences of packed or hidden code in a malware instance can be made self-identifying when its runtime execution is checked against its static code model. In deriving our technique, we formally define the unpack-executing behavior that such malware exhibits and devise an algorithm for identifying and extracting its hidden-code. We also provide details of the implementation and evaluation of our extraction technique; the results from our experiments on several thousand malware binaries show our approach can be used to significantly reduce the time required to analyze such malware, and to improve the performance of malware detection tools.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
rate achieves deep neural low model positive network false traditional 400 95 adjusting better classifier’s coming commodity customer database datasizes 	0	Deep neural network based malware detection using two dimensional binary program features	In this paper we introduce a deep neural network based malware detection system that Invincea has developed, which achieves a usable detection rate at an extremely low false positive rate and scales to real world training example volumes on commodity hardware. We show that our system achieves a 95% detection rate at 0.1% false positive rate (FPR), based on more than 400,000 software binaries sourced directly from our customers and internal malware databases. In addition, we describe a non-parametric method for adjusting the classifier’s scores to better represent expected precision in the deployment environment. Our results demonstrate that it is now feasible to quickly train and deploy a low resource, highly accurate machine learning classification model, with false positive rates that approach traditional labor intensive expert rule based malware detection, while also detecting previously unseen malware missed by these traditional approaches. Since machine learning models tend to improve with larger datasizes, we foresee deep neural network classification models gaining in importance as part of a layered network defense strategy in coming years.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
constant opaque static detector evaded transformation scanner value code obfuscation primitive register malware proposed identify clear demonstrates determine explore global 	0	Limits of static analysis for malware detection	Malicious code is an increasingly important problem that threatens the security of computer systems. The traditional line of defense against malware is composed of malware detectors such as virus and spyware scanners. Unfortunately, both researchers and malware authors have demonstrated that these scanners, which use pattern matching to identify malware, can be easily evaded by simple code transformations. To address this shortcoming, more powerful malware detectors have been proposed. These tools rely on semantic signatures and employ static analysis techniques such as model checking and theorem proving to perform detection. While it has been shown that these systems are highly effective in identifying current malware, it is less clear how successful they would be against adversaries that take into account the novel detection mechanisms. The goal of this paper is to explore the limits of static analysis for the detection of malicious code. To this end, we present a binary obfuscation scheme that relies on the idea of opaque constants, which are primitives that allow us to load a constant into a register such that an analysis tool cannot determine its value. Based on opaque constants, we build obfuscation transformations that obscure program control flow, disguise access to local and global variables, and interrupt tracking of values held in processor registers. Using our proposed obfuscation approach, we were able to show that advanced semantics-based malware detectors can be evaded. Moreover, our opaque constant primitive can be applied in a way such that is provably hard to analyze for any static code analyzer. This demonstrates that static analysis techniques alone might no longer be sufficient to identify malware.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
transparent analyzer ether guest evade malware hardware runtime obfuscation 25 arise battle centerpiece cleanup component detectable emulate emulation extension external 	0	Ether: Malware analysis via hardware virtualization extensions	Malware has become the centerpiece of most security threats on the Internet. Malware analysis is an essential technology that extracts the runtime behavior of malware, and supplies signatures to detection systems and provides evidence for recovery and cleanup. The focal point in the malware analysis battle is how to detect versus how to hide a malware analyzer from malware during runtime. State-of-the-art analyzers reside in or emulate part of the guest operating system and its underlying hardware, making them easy to detect and evade. In this paper, we propose a transparent and external approach to malware analysis, which is motivated by the intuition that for a malware analyzer to be transparent, it must not induce any side-effects that are unconditionally detectable by malware. Our analyzer, Ether, is based on a novel application of hardware virtualization extensions such as Intel VT, and resides completely outside of the target OS environment. Thus, there are no in-guest software components vulnerable to detection, and there are no shortcomings that arise from incomplete or inaccurate system emulation. Our experiments are based on our study of obfuscation techniques used to create 25,000 recent malware samples. The results show that Ether remains transparent and defeats the obfuscation tools that evade existing approaches.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
breakpoints hardware breakpoint vampire debugger unlimited mechanism processor stealth code number limited ability countered microscopic modification providing runtime powerful make 	0	Stealth breakpoints	Microscopic analysis of malicious code (malware) requires the aid of a variety of powerful tools. Chief among them is a debugger that enables runtime binary analysis at an instruction level. One of the important services provided by a debugger is the ability to stop execution of code at an arbitrary point during runtime, using breakpoints. Software breakpoints support an unlimited number of breakpoint locations by changing the code being debugged so that it can be interrupted during runtime. Most, if not all, malware are very sensitive to code modification with self-modifying and/or self-checking (SM-SC) capabilities, rendering the use of software breakpoints limited in their scope. Hardware breakpoints supported by the underlying processor, on the other hand, use a subset of the processor register set and exception mechanisms to provide breakpoints that do not entail code modification. This makes hardware breakpoints the most powerful breakpoint mechanism for malware analysis. However, current processors provide a very limited number of hardware breakpoints (typically 2–4 locations). Thus, a serious restriction is imposed on the debugger to set a desired number of breakpoints without resorting to the limited alternative of software breakpoints. Also, with the ever evolving nature of malware, there are techniques being employed that prevent the use of hardware breakpoints. This calls for a new breakpoint mechanism that retains the features of hardware breakpoints while providing an unlimited number of breakpoints, which cannot be detected or countered. In this paper, we present the concept of stealth breakpoints and discuss the design and implementation of VAMPiRE 1, a realization of this concept. VAMPiRE cannot be detected or countered and provides unlimited number of breakpoints to be set on code, data, and I/O with the same precision as that of hardware breakpoints. It does so by employing a subtle combination of simple stealth techniques using virtual memory and hardware single-stepping mechanisms that are available on all processors, old and new. This technique makes VAMPiRE portable to any architecture, providing powerful breakpoint ability similar to hardware breakpoints for microscopic malware analysis. 1 VAMPiRE is a beast (in folklore) that attacks in a stealth fashion.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
automated avoid tool combat correctly initiate report functionality example quickly use worm malware analyst design acknowledge appearance appears aren’t arguably 	0	Toward automated dynamic malware analysis using cwsandbox	Malware is notoriously difficult to combat because it appears and spreads so quickly. Most security products such as virus scanners look for signatures—characteristic byte sequences—to identify malicious code. Malware, however, has adapted to that approach. Polyor metamorphic worms avoid detection by changing their appearance, for example, whereas flash worms stealthily perform reconnaissance without infecting vulnerable machines, waiting to pursue strategic spreading plans that can infect thousands of machines within seconds. In the face of such automated threats, security researchers can’t combat malicious software using manual methods of disassembly or reverse engineering. Therefore, analysis tools must analyze malware automatically, effectively, and correctly. Automating this process means that the analysis tool should create detailed reports of malware samples quickly and without user intervention. Analysts could then use the machinereadable reports to initiate automated responses—automatically updating an intrusion detection system’s signatures, for example, and protecting networks from new malware on the fly. An effective analysis tool must log the malware’s relevant behaviors—the tool shouldn’t overlook any of the executed functionality because analysts will use the information to realistically assess the threat. Finally, the tool should correctly analyze the malware—the sample should initiate every logged action to avoid false positives. In this article, we describe the design and implementation of CWSandbox, a malware analysis tool that fulfills our three design criteria of automation, effectiveness, and correctness for the Win32 family of operating systems. We show how to use API hooking and dynamic linked library (DLL) injection techniques to implement the necessary rootkit functionality to avoid detection by the malware. We acknowledge that these techniques aren’t new; however, we’ve assembled the techniques in a unique combination that provides a fully functional, elegantly simple, and arguably powerful automated malware analysis tool.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
protocol implementation different difference format message trace application network way engineering reverse process 17 benefit crafted dns extensively fingerprint fuzzing 	0	Polyglot: Automatic extraction of protocol message format using dynamic binary analysis	Protocol reverse engineering, the process of extracting the application-level protocol used by an implementation, without access to the protocol specification, is important for many network security applications. Recent work [17] has proposed protocol reverse engineering by using clustering on network traces. That kind of approach is limited by the lack of semantic information on network traces. In this paper we propose a new approach using program binaries. Our approach, shadowing, uses dynamic analysis and is based on a unique intuition—the way that an implementation of the protocol processes the received application data reveals a wealth of information about the protocol message format. We have implemented our approach in a system called Polyglot and evaluated it extensively using real-world implementations of five different protocols: DNS, HTTP, IRC, Samba and ICQ. We compare our results with the manually crafted message format, included in Wireshark, one of the state-ofthe-art protocol analyzers. The differences we find are small and usually due to different implementations handling fields in different ways. Finding such differences between implementations is an added benefit, as they are important for problems such as fingerprint generation, fuzzing, and error detection.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
web http tap server outbound tap’s transaction tunneling traffic network attempt inbound request program filter help period send detected significant 	0	Web tap: Detecting covert web traffic	As network security is a growing concern, system administrators lock down their networks by closing inbound ports and only allowing outbound communication over selected protocols such as HTTP. Hackers, in turn, are forced to find ways to communicate with compromised workstations by tunneling through web requests. While several tools attempt to analyze inbound traffic for denial-of-service and other attacks on web servers, Web Tap’s focus is on detecting attempts to send significant amounts of information out via HTTP tunnels to rogue Web servers from within an otherwise firewalled network. A related goal of Web Tap is to help detect spyware programs, which often send out personal data to servers using HTTP transactions and may open up security holes in the network. Based on the analysis of HTTP traffic over a training period, we designed filters to help detect anomalies in outbound HTTP traffic using metrics such as request regularity, bandwidth usage, interrequest delay time, and transaction size. Subsequently, Web Tap was evaluated on several available HTTP covert tunneling programs as well as a test backdoor program, which creates a remote shell from outside the network to a protected machine using only outbound HTTP transactions. Web Tap’s filters detected all the tunneling programs tested after modest use. Web Tap also analyzed the activity of approximately thirty faculty and students who agreed to use it as a proxy server over a 40 day period. It successfully detected a significant number of spyware and aware programs. This paper presents the design of Web Tap, results from its evaluation, as well as potential limits to Web Tap’s capabilities.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
subset filter evaluator group stability ranker feature selection stable wrapper consistent perturbation relative datasets dataset based statistical assign attribute change 	0	Comparison of stability for different families of filter-based and wrapper-based feature selection	Due to the prevalence of high dimensionality (having a large number of independent attributes), feature selection techniques (which reduce the feature subset to a more manageable size) have become quite popular. These reduced feature subsets can help improve the performance of classification models and can also inform researchers about which features are most relevant for the problem at hand. For this latter problem, it is often most important that the features chosen are consistent even in the face of changes (perturbations) to the dataset. While previous studies have considered the problem of finding so-called “stable” feature selection techniques, none has examined stability across all three major categories of feature selection technique: filterbased feature rankers (which use statistical measures to assign scores to each feature), filter-based subset evaluators (which also employ statistical approaches, but consider whole feature subsets at a time), and wrapper-based subset evaluation (which also considers whole subsets, but which builds classification models to evaluate these subsets). In the present study, we use two datasets from the domain of Twitter profile mining to compare the stability of five filter-based rankers, two filter-based subset evaluators, and five wrapper-based subset evaluators. We find that the rankers are most stable, followed by the filter-based subset evaluators, with the wrappers being the least stable. We also show that the relative performance among the techniques within each group is consistent across dataset and perturbation level. However, the relative stability of the two datasets does vary between the groups, showing that the effects are more complex than simply “one group is always more stable than another group.” Keywords-Stability, filter-based feature selection, wrapperbased feature selection	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
stream challenge chunk ensemble single extraction fixed multichunk multipartition v address data feature classifier selection traditional classification additional both botnet 	0	Cloud-based malware detection for evolving data streams	Data stream classification for intrusion detection poses at least three major challenges. First, these data streams are typically infinite-length, making traditional multipass learning algorithms inapplicable. Second, they exhibit significant concept-drift as attackers react and adapt to defenses. Third, for data streams that do not have any fixed feature set, such as text streams, an additional feature extraction and selection task must be performed. If the number of candidate features is too large, then traditional feature extraction techniques fail. In order to address the first two challenges, this article proposes a multipartition, multichunk ensemble classifier in which a collection of v classifiers is trained from r consecutive data chunks using v-fold partitioning of the data, yielding an ensemble of such classifiers. This multipartition, multichunk ensemble technique significantly reduces classification error compared to existing single-partition, single-chunk ensemble approaches, wherein a single data chunk is used to train each classifier. To address the third challenge, a feature extraction and selection technique is proposed for data streams that do not have any fixed feature set. The technique’s scalability is demonstrated through an implementation for the Hadoop MapReduce cloud computing architecture. Both theoretical and empirical evidence demonstrate its effectiveness over other state-of-the-art stream classification techniques on synthetic data, real botnet traffic, and malicious executables.	['malware', 'code', 'network']	['hardware_breakpoints', 'hide_code', 'based_subset', 'dbi_frameworks', 'filter_based']	['based_subset_evaluators', 'extracts_hidden_code', 'feature_extraction_selection', 'feature_selection_techniques', 'filter_based_subset']
virus use conduct degree dependence exhaustive fitting obviate other overfitted predictive seek strives taking feature yield heuristic power condition exist 	1	A feature selection and evaluation scheme for computer virus detection	Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are overfitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']
virus use conduct degree dependence exhaustive fitting obviate other overfitted predictive seek strives taking feature yield heuristic power condition exist 	1	A feature selection and evaluation scheme for computer virus detection	Anti-virus systems traditionally use signatures to detect malicious executables, but signatures are overfitted features that are of little use in machine learning. Other more heuristic methods seek to utilize more general features, with some degree of success. In this paper, we present a data mining approach that conducts an exhaustive feature search on a set of computer viruses and strives to obviate over-fitting. We also evaluate the predictive power of a classifier by taking into account dependence relationships that exist between viruses, and we show that our classifier yields high detection rates and can be expected to perform as well in real-world conditions.	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']
gram n fielded decision tree executables 1651 1971 255 996 area boosted boosting curve encoded gathered inductive outperformed resulted roc 	1	Learning to detect malicious executables in the wild	In this paper, we describe the development of a fielded application for detecting malicious executables in the wild. We gathered 1971 benign and 1651 malicious executables and encoded each as a training example using n-grams of byte codes as features. Such processing resulted in more than 255 million distinct n-grams. After selecting the most relevant n-grams for prediction, we evaluated a variety of inductive methods, including naive Bayes, decision trees, support vector machines, and boosting. Ultimately, boosted decision trees outperformed other methods with an area under the roc curve of 0.996. Results also suggest that our methodology will scale to larger collections of executables. To the best of our knowledge, ours is the only fielded application for this task developed using techniques from machine learning and data mining.	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']
heuristic behavioral computer method introduced api call discus antiviruses deficiency disadvantage documented growth harm invent malwares ngram opcode opcodes protect 	1	A survey on heuristic malware detection techniques	Malware is a malicious code which is developed to harm a computer or network. The number of malwares is growing so fast and this amount of growth makes the computer security researchers invent new methods to protect computers and networks. There are three main methods used to malware detection: Signature based, Behavioral based and Heuristic ones. Signature based malware detection is the most common method used by commercial antiviruses but it can be used in the cases which are completely known and documented. Behavioral malware detection was introduced to cover deficiencies of signature based method. However, because of some shortcomings, the heuristic methods have been introduced. In this paper, we discuss the state of the art heuristic malware detection methods and briefly overview various features used in these methods such as API Calls, OpCodes, N-Grams etc. and discuss their advantages and disadvantages. Keywords-Malware Detection, Computer Security, API Call, NGram, OpCode, Control Flow Graph.	['heuristic', 'virus', 'use']	['n_grams', 'heuristic_methods', 'account_dependence', 'approach_conducts', 'classifier_taking']	['detect_malicious_executables', 'account_dependence_relationships', 'anti_virus_systems', 'approach_conducts_exhaustive', 'classifier_taking_account']
categorization clustering amcs automatic ensemble characteristic hierarchical medoids malware base k family generate cluster industry instruction efficiency anti algorithm sample 	2	Automatic malware categorization using cluster ensemble	Malware categorization is an important problem in malware analysis and has attracted a lot of attention of computer security researchers and anti-malware industry recently. Today’s malware samples are created at a rate of millions per day with the development of malware writing techniques. There is thus an urgent need of effective methods for automatic malware categorization. Over the last few years, many clustering techniques have been employed for automatic malware categorization. However, such techniques have isolated successes with limited effectiveness and efficiency, and few have been applied in real anti-malware industry. In this paper, resting on the analysis of instruction frequency and function-based instruction sequences, we develop an Automatic Malware Categorization System (AMCS) for automatically grouping malware samples into families that share some common characteristics using a cluster ensemble by aggregating the clustering solutions generated by different base clustering algorithms. We propose a principled cluster ensemble framework for combining individual clustering solutions based on the consensus partition. The domain knowledge in the form of sample-level constraints can be naturally incorporated in the ensemble framework. In addition, to account for the characteristics of feature representations, we propose a hybrid hierarchical clustering algorithm which combines the merits of hierarchical clustering and k-medoids algorithms and a weighted subspace K-medoids algorithm to generate base clusterings. The categorization results of our AMCS system can be used to generate signatures for malware families that are useful for malware detection. The case studies on large and real daily malware collection from Kingsoft Anti-Virus Lab demonstrate the effectiveness and efficiency of our AMCS system.	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
file relation content anti trojan malware sample detection experimental associated client comodo comodo’s damage decade incorporation interface invaluable kaspersky like 	2	Combining file content and file relations for cloud based malware detection	Due to their damages to Internet security, malware (such as virus, worms, trojans, spyware, backdoors, and rootkits) detection has caught the attention not only of anti-malware industry but also of researchers for decades. Resting on the analysis of file contents extracted from the file samples, like Application Programming Interface (API) calls, instruction sequences, and binary strings, data mining methods such as Naive Bayes and Support Vector Machines have been used for malware detection. However, besides file contents, relations among file samples, such as a “Downloader” is always associated with many Trojans, can provide invaluable information about the properties of file samples. In this paper, we study how file relations can be used to improve malware detection results and develop a file verdict system (named “Valkyrie”) building on a semi-parametric classifier model to combine file content and file relations together for malware detection. To the best of our knowledge, this is the first work of using both file content and file relations for malware detection. A comprehensive experimental study on a large collection of PE files obtained from the clients of anti-malware products of Comodo Security Solutions Incorporation is performed to compare various malware detection approaches. Promising experimental results demonstrate that the accuracy and efficiency of our Valkyrie system outperform other popular anti-malware software tools such as Kaspersky AntiVirus and McAfee VirusScan, as well as other alternative data mining based detection systems. Our system has already been incorporated into the scanning tool of Comodo’s Anti-Malware software.	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
random knn nearest neighbor datasets proposed computational dimensional generalization modeling requirement constructed input base consists k property shown performance advantage 	2	Random KNN	We present Random KNN, a novel generalization of traditional nearest-neighbor modeling. Random KNN consists of an ensemble of base k-nearest neighbor classifiers, each constructed from a random subset of the input variables. We study the properties of the proposed Random KNN. Using various datasets, we perform an empirical analysis of Random KNN performance and compare it with recently proposed methods for high-dimensional datasets. It is shown that Random KNN provides significant advantages in both the computational requirement and classification performance.	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
mutual calculating selection information variable apply depends indicator parzen algorithm good input relevance window feature difficult class measure accuracy however 	2	Input feature selection by mutual information based on parzen window	Mutual information is a good indicator of relevance between variables, and have been used as a measure in several feature selection algorithms. However, calculating the mutual information is difficult, and the performance of a feature selection algorithm depends on the accuracy of the mutual information. In this paper, we propose a new method of calculating mutual information between input and class variables based on the Parzen window, and we apply this to a feature selection algorithm for classification problems.	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
behavior specification prototype malware detector known algorithm variant benign program comparing derives description indicate investigating laborious output overcome succinct word 	2	Mining specifications of malicious behavior	Malware detectors require a specification of malicious behavior. Typically, these specifications are manually constructed by investigating known malware. We present an automatic technique to overcome this laborious manual process. Our technique derives such a specification by comparing the execution behavior of a known malware against the execution behaviors of a set of benign programs. In other words, we mine the malicious behavior present in a known malware that is not present in a set of benign programs. The output of our algorithm can be used by malware detectors to detect malware variants. Since our algorithm provides a succinct description of malicious behavior present in a malware, it can also be used by security analysts for understanding the malware. We have implemented a prototype based on our algorithm and tested it on several malware programs. Experimental results obtained from our prototype indicate that our algorithm is effective in extracting malicious behaviors that can be used to detect malware variants.	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
specification discriminative av behavior commercial detector class based program rate 55 62 64 86 alarm alarming contrast economy excessive exploiting 	2	Synthesizing near-optimal malware specifications from suspicious behaviors	Fueled by an emerging underground economy, malware authors are exploiting vulnerabilities at an alarming rate. To make matters worse, obfuscation tools are commonly available, and much of the malware is open source, leading to a huge number of variants. Behavior-based detection techniques are a promising solution to this growing problem. However, these detectors require precise specifications of malicious behavior that do not result in an excessive number of false alarms. In this paper, we present an automatic technique for extracting optimally discriminative specifications, which uniquely identify a class of programs. Such a discriminative specification can be used by a behavior-based malware detector. Our technique, based on graph mining and concept analysis, scales to large classes of programs due to probabilistic sampling of the specification space. Our implementation, called HOLMES, can synthesize discriminative specifications that accurately distinguish between programs, sustaining an 86% detection rate on new, unknown malware, with 0 false positives, in contrast with 55% for commercial signature-based antivirus (AV) and 62-64% for behavior-based AV (commercial or research).	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
panorama desktop fundamental google privacy trait users’ behavior access processing sample information unknown analyzing assistance breaching capturing comprehend compromise drm 	2	Panorama: Capturing system-wide information flow for malware detection and analysis	Malicious programs spy on users’ behavior and compromise their privacy. Even software from reputable vendors, such as Google Desktop and Sony DRM media player, may perform undesirable actions. Unfortunately, existing techniques for detecting malware and analyzing unknown code samples are insufficient and have significant shortcomings. We observe that malicious information access and processing behavior is the fundamental trait of numerous malware categories breaching users’ privacy (including keyloggers, password thieves, network sniffers, stealth backdoors, spyware and rootkits), which separates these malicious applications from benign software. We propose a system, Panorama, to detect and analyze malware by capturing this fundamental trait. In our extensive experiments, Panorama successfully detected all the malware samples and had very few false positives. Furthermore, by using Google Desktop as a case study, we show that our system can accurately capture its information access and processing behavior, and we can confirm that it does send back sensitive information to remote servers in certain settings. We believe that a system such as Panorama will offer indispensable assistance to code analysts and malware researchers by enabling them to quickly comprehend the behavior and inner-workings of an unknown sample.	['behavior', 'malware', 'algorithm']	['anti_malware', 'malware_categorization', 'random_knn', 'file_contents', 'discriminative_specifications']	['anti_malware_industry', 'automatic_malware_categorization', 'access_processing_behavior', 'anti_malware_software', 'calculating_mutual_information']
type file hierarchy major feature advancement borrowed categorized contribution includes misuse reader served stated surveyed tier detection anomaly categorizes extracted 	3	A survey of data mining techniques for malware detection using file features	This paper presents a survey of data mining techniques for malware detection using file features. The techniques are categorized based upon a three tier hierarchy that includes file features, analysis type and detection type. File features are the features extracted from binary programs, analysis type is either static or dynamic, and the detection type is borrowed from intrusion detection as either misuse or anomaly detection. It provides the reader with the major advancement in the malware research using data mining on file features and categorizes the surveyed work based upon the above stated hierarchy. This served as the major contribution of this paper.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
malware detecting software assurance basis circumvent complete core emphasis encouraging fails hypothesis identified limitation mutant mutated obfuscated particular sandbox testing 	3	Static analyzer of vicious executables (SAVE)	Software security assurance and malware (trojans, worms, and viruses, etc.) detection are important topics of information security. Software obfuscation, a general technique that is useful for protecting software from reverse engineering, can also be used by hackers to circumvent the malware detection tools. Current static malware detection techniques have serious limitations, and sandbox testing also fails to provide a complete solution due to time constraints. In this paper, we present a robust signature-based malware detection technique, with emphasis on detecting obfuscated (or polymorphic) malware and mutated (or metamorphic) malware. The hypothesis is that all versions of the same malware share a common core signature that is a combination of several features of the code. After a particular malware has been first identified, it can be analyzed to extract the signature, which provides a basis for detecting variants and mutants of the same malware in the future. Encouraging experimental results on a large set of recent malware are presented.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
android mobile article this acquire concludes consent date device integration life particularly path privy progression smartphones supporting weakness with malware 	3	The evolution of android malware and android analysis techniques	With the integration of mobile devices into daily life, smartphones are privy to increasing amounts of sensitive information. Sophisticated mobile malware, particularly Android malware, acquire or utilize such data without user consent. It is therefore essential to devise effective techniques to analyze and detect these threats. This article presents a comprehensive survey on leading Android malware analysis and detection techniques, and their effectiveness against evolving malware. This article categorizes systems by methodology and date to evaluate progression and weaknesses. This article also discusses evaluations of industry solutions, malware statistics, and malware evasion techniques and concludes by supporting future research paths.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
file aesop labeled relationship 0 benign rate 0001 79 99 9961 aesop’s applying attained capable close contributed defensive flagging harder 	3	Guilt by association: Large scale malware detection by mining file-relation graphs	The increasing sophistication of malicious software calls for new defensive techniques that are harder to evade, and are capable of protecting users against novel threats. We present Aesop, a scalable algorithm that identifies malicious executable files by applying Aesop’s moral that“a man is known by the company he keeps.” We use a large dataset voluntarily contributed by the members of Norton Community Watch, consisting of partial lists of the files that exist on their machines, to identify close relationships between files that often appear together on machines. Aesop leverages locality-sensitive hashing to measure the strength of these inter-file relationships to construct a graph, on which it performs large scale inference by propagating information from the labeled files (as benign or malicious) to the preponderance of unlabeled files. Aesop attained early labeling of 99% of benign files and 79% of malicious files, over a week before they are labeled by the state-of-the-art techniques, with a 0.9961 true positive rate at flagging malware, at 0.0001 false positive rate.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
ooa imds rule pe system antivirus file experimental association corporation efficiently fpgrowth generator integrated intelligent laboratory module objectiveoriented parser proliferation 	3	IMDS: Intelligent malware detection system	The proliferation of malware has presented a serious threat to the security of computer systems. Traditional signature-based antivirus systems fail to detect polymorphic and new, previously unseen malicious executables. In this paper, resting on the analysis of Windows API execution sequences called by PE files, we develop the Intelligent Malware Detection System (IMDS) using ObjectiveOriented Association (OOA) mining based classification. IMDS is an integrated system consisting of three major modules: PE parser, OOA rule generator, and rule based classifier. An OOA Fast FPGrowth algorithm is adapted to efficiently generate OOA rules for classification. A comprehensive experimental study on a large collection of PE files obtained from the anti-virus laboratory of KingSoft Corporation is performed to compare various malware detection approaches. Promising experimental results demonstrate that the accuracy and efficiency of our IMDS system outperform popular anti-virus software such as Norton AntiVirus and McAfee VirusScan, as well as previous data mining based detection systems which employed Naive Bayes, Support Vector Machine (SVM) and Decision Tree techniques.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
assessment representing site antivirus spam type web able graph file detect bipartite connected distribute edge engine facing fact fh ground 	3	Graph-based malware distributors detection	Search engines are currently facing a problem of websites that distribute malware. In this paper we present a novel efficient algorithm that learns to detect such kind of spam. We have used a bipartite graph with two types of nodes, each representing a layer in the graph: web-sites and file hostings (FH), connected with edges representing the fact that a file can be downloaded from the hosting via a link on the web-site. The performance of this spam detection method was verified using two set of ground truth labels: manual assessments of antivirus analysts and automatically generated assessments obtained from antivirus companies. We demonstrate that the proposed method is able to detect new types of malware even before the best known antivirus solutions are able to detect them.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
fpga guardol early sample benign malware 100 30 46 97 achieve aim array at centric classify combined construction consumption conventional 	3	Semantics-based online malware detection: Towards efficient real-time protection against malware	Recently, malware has increasingly become a critical threat to embedded systems, while the conventional software solutions, such as antivirus and patches, have not been so successful in defending the ever-evolving and advanced malicious programs. In this paper, we propose a hardwareenhanced architecture, GuardOL, to perform online malware detection. GuardOL is a combined approach using processor and field-programmable gate array (FPGA). Our approach aims to capture the malicious behavior (i.e., highlevel semantics) of malware. To this end, we first propose the frequency-centric model for feature construction using system call patterns of known malware and benign samples. We then develop a machine learning approach (using multilayer perceptron) in FPGA to train classifier using these features. At runtime, the trained classifier is used to classify the unknown samples as malware or benign, with early prediction. The experimental results show that our solution can achieve high classification accuracy, fast detection, low power consumption, and flexibility for easy functionality upgrade to adapt to new malware samples. One of the main advantages of our design is the support of early prediction—detecting 46% of malware within first 30% of their execution, while 97% of the samples at 100% of their execution, with <3% false positives.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
adversary classifier domain adversary’s optimal produce spam actively ad assume counter datagenerating degrade deployed essentially far formal fraud game greatly 	3	Adversarial classification	Essentially all data mining algorithms assume that the datagenerating process is independent of the data miner’s activities. However, in many domains, including spam detection, intrusion detection, fraud detection, surveillance and counter-terrorism, this is far from the case: the data is actively manipulated by an adversary seeking to make the classifier produce false negatives. In these domains, the performance of a classifier can degrade rapidly after it is deployed, as the adversary learns to defeat it. Currently the only solution to this is repeated, manual, ad hoc reconstruction of the classifier. In this paper we develop a formal framework and algorithms for this problem. We view classification as a game between the classifier and the adversary, and produce a classifier that is optimal given the adversary’s optimal strategy. Experiments in a spam detection domain show that this approach can greatly outperform a classifier learned in the standard way, and (within the parameters of the problem) automatically adapt the classifier to the adversary’s evolving manipulations.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
cluster hand appearing attracting benchmark bioinformatics cause confusion discussed diversity effort equips exploration illustrate on option phenomenon play profusion proximity 	3	Survey of clustering algorithms	Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
vulnerability exploit observed worm dacoda discovered filtering month predicate attacker content string byte typically effective 14 2 actual conclude contiguous 	3	On deriving unknown vulnerabilities from zero-day polymorphic and metamorphic worm exploits	Vulnerabilities that allow worms to hijack the control flow of each host that they spread to are typically discovered months before the worm outbreak, but are also typically discovered by third party researchers. A determined attacker could discover vulnerabilities as easily and create zero-day worms for vulnerabilities unknown to network defenses. It is important for an analysis tool to be able to generalize from a new exploit observed and derive protection for the vulnerability. Many researchers have observed that certain predicates of the exploit vector must be present for the exploit to work and that therefore these predicates place a limit on the amount of polymorphism and metamorphism available to the attacker. We formalize this idea and subject it to quantitative analysis with a symbolic execution tool called DACODA. Using DACODA we provide an empirical analysis of 14 exploits (seven of them actual worms or attacks from the Internet, caught by Minos with no prior knowledge of the vulnerabilities and no false positives observed over a period of six months) for four operating systems. Evaluation of our results in the light of these two models leads us to conclude that 1) single contiguous byte string signatures are not effective for content filtering, and tokenbased byte string signatures composed of smaller substrings are only semantically rich enough to be effective for content filtering if the vulnerability lies in a part of a protocol that is not commonly used, and that 2) practical exploit analysis must account for multiple processes, multithreading, and kernel processing of network data necessitating a focus on primitives instead of vulnerabilities. 	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
maximal mrmr selection dependency select feature criterion different according allows arrhythmia cancer cell compact comparison cost difficulty digit equivalent g 	3	Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy	Feature selection is an important problem for pattern classification systems.We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e.g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
weka 4 release 3 stable time 2000 2003 35 6 academia acceptance accompanies active april business elapsed enjoys entirely evolved 	3	The WEKA data mining software: An update	More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on SourceForge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
potentially sample unknown appropriate assessing assist closer confirmed confronted deserves human inspection mainly manner mere multitude timely today uncommon threat 	3	A survey on automated dynamic malware-analysis techniques and tools	Anti-virus vendors are confronted with a multitude of potentially malicious samples today. Receiving thousands of new samples every day is not uncommon. The signatures that detect confirmed malicious threats are mainly still created manually, so it is important to discriminate between samples that pose a new unknown threat and those that are mere variants of known malware. This survey article provides an overview of techniques based on dynamic analysis that are used to analyze potentially malicious samples. It also covers analysis programs that employ these techniques to assist human analysts in assessing, in a timely and appropriate manner, whether a given sample deserves closer manual inspection due to its unknown malicious behavior.	['file', 'malware', 'spam']	['file_features', 'data_sets', 'spam_detection', 'this_article', 'able_detect']	['byte_string_signatures', 'effective_content_filtering', 'malware_detection_techniques', 'potentially_malicious_samples', 'bayes_support_vector']
