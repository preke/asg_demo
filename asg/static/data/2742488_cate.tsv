top_n_words	label	title	abstract	topic_word	topic_bigram	topic_trigram
core heterogeneity hardware changing computation multicore reliability management processor allowing architect argue arise assigning chip complicates configuration constantly content continues 	0	Dynamic heterogeneity and the need for multicore virtualization	As the computing industry enters the multicore era, exponential growth in the number of transistors on a chip continues to present challenges and opportunities for computer architects and system designers. We examine one emerging issue in particular: that of dynamic heterogeneity, which can arise, even among physically homogeneous cores, from changing reliability, power, or thermal conditions, different cache and TLB contents, or changing resource configurations. This heterogeneity results in a constantly varying pool of hardware resources, which greatly complicates software’s traditional task of assigning computation to cores. In part to address dynamic heterogeneity, we argue that hardware should take a more active role in the management of its computation resources. We propose hardware techniques to virtualize the cores of a multicore processor, allowing hardware to flexibly reassign the virtual processors that are exposed, even to a single operating system, to any subset of the physical cores. We show that multicore virtualization operates with minimal overhead, and that it enables several novel resource management applications for improving both performance and reliability.	['cloud', 'discus', 'vm']	['v_man', 'ict_industry', 'level_virtualization', 'algorithm_jointly', 'algorithm_vmp']	['cloud_computing_we', 'definition_cloud_computing', 'technology_ict_industry', '00or22725_techniques_address', '2006_currently_talked']
isolate laboratory solution hpc virtualization level implementation research support system operating technique environment 00or22725 70’s ac05 appear battelle brief by 	0	System-level virtualization for high performance computing	System-level virtualization has been a research topic since the 70’s but regained popularity during the past few years because of the availability of efficient solution such as Xen and the implementation of hardware support in commodity processors (e.g. Intel-VT, AMD-V). However, a majority of system-level virtualization projects is guided by the server consolidation market. As a result, current virtualization solutions appear to not be suitable for high performance computing (HPC) which is typically based on large-scale systems. On another hand there is significant interest in exploiting virtual machines (VMs) within HPC for a number of other reasons. By virtualizing the machine, one is able to run a variety of operating systems and environments as needed by the applications. Virtualization allows users to isolate workloads, improving security and reliability. It is also possible to support nonnative environments and/or legacy operating environments through virtualization. In addition, it is possible to balance work loads, use migration techniques to relocate applications from failing machines, and isolate fault systems for repair. This document presents the challenges for the implementation of a system-level virtualization solution for HPC. It also presents a brief survey of the different approaches and ∗ORNL’s research sponsored by the Laboratory Directed Research and Development Program of Oak Ridge National Laboratory (ORNL), managed by UT-Battelle, LLC for the U. S. Department of Energy under Contract No. DE-AC05-00OR22725. techniques to address these challenges.	['cloud', 'discus', 'vm']	['v_man', 'ict_industry', 'level_virtualization', 'algorithm_jointly', 'algorithm_vmp']	['cloud_computing_we', 'definition_cloud_computing', 'technology_ict_industry', '00or22725_techniques_address', '2006_currently_talked']
believe deserves highlight identify interoperability last many oriented pinpoint reshape revolution cloud issue substantial adoption discus entire perspective related relationship 	0	Cloud computing: Issues and challenges	Many believe that Cloud will reshape the entire ICT industry as a revolution. In this paper, we aim to pinpoint the challenges and issues of Cloud computing. We first discuss two related computing paradigms Service-Oriented Computing and Grid computing, and their relationships with Cloud computing We then identify several challenges from the Cloud computing adoption perspective. Last, we will highlight the Cloud interoperability issue that deserves substantial further research	['cloud', 'discus', 'vm']	['v_man', 'ict_industry', 'level_virtualization', 'algorithm_jointly', 'algorithm_vmp']	['cloud_computing_we', 'definition_cloud_computing', 'technology_ict_industry', '00or22725_techniques_address', '2006_currently_talked']
technology controversy definition software cloud discus potential ict hardware 2006 achievement bring business contribution currently discussion disruptive dream economic gaining 	0	The current state of understanding of the energy efficiency of cloud computing	Cloud computing has been hailed as the achievement of the longheld dream of computing as a utility and has the potential to transform a large part of the Information and Communication Technology (ICT) industry. Cloud computing is both a business and an economic model which has been gaining popularity since 2006 and it is currently the most talked about technology in the ICT industry. Because it views hardware and software as commodities, the cloud is an example of a disruptive technology. It offers enterprises the opportunity to reduce hardware and software cost and the potential reduction of maintenance and support staff. Data centers and cloud computing services providers hope that the widespread adoption of the cloud will bring them more profit and they are actively promoting the technology. The cloud has had its share of controversy; ranging from the definition of cloud computing to its energy efficiency. This paper discusses one area of controversy; the energy efficiency of cloud computing. We outline previous contributions to the discussion of energy efficiency of cloud computing, provide a working definition of cloud computing and discuss its importance, which will grow as the technology matures and becomes well known.	['cloud', 'discus', 'vm']	['v_man', 'ict_industry', 'level_virtualization', 'algorithm_jointly', 'algorithm_vmp']	['cloud_computing_we', 'definition_cloud_computing', 'technology_ict_industry', '00or22725_techniques_address', '2006_currently_talked']
man v allocation datacenters protocol conservation vm vms modern operate node technique cloud significant account achieving added allocate allow arbitrary 	0	Server consolidation in clouds through gossiping	The success of Cloud computing, where computing power is treated as a utility, has resulted in the creation of many large datacenters that are very expensive to build and operate. In particular, the energy bill accounts for a significant fraction of the total operation costs. For this reason a significant attention is being devoted to energy conservation techniques, for example by taking advantage of the built-in power saving features of modern hardware. Cloud computing offers novel opportunities for achieving energy savings: Cloud systems rely on virtualization techniques to allocate computing resources on demand, and modern Virtual Machine (VM) monitors allow live migration of running VMs. Thus, energy conservation can be achieved through server consolidation, moving VM instances away from lightly loaded computing nodes so that they become empty and can be switched to low-power mode. In this paper we present V-MAN, a fully decentralized algorithm for consolidating VMs in large Cloud datacenters. V-MAN can operate on any arbitrary initial allocation of VMs on the Cloud, iteratively producing new allocations that quickly converge towards the one maximizing the number of idle hosts. V-MAN uses a simple gossip protocol to achieve efficiency, scalability and robustness to failures. Simulation experiments indicate that, starting from a random allocation, V-MAN produces an almost-optimal VM placement in just a few rounds; the protocol is intrinsically robust and can cope with computing nodes being added to or removed from the Cloud.	['cloud', 'discus', 'vm']	['v_man', 'ict_industry', 'level_virtualization', 'algorithm_jointly', 'algorithm_vmp']	['cloud_computing_we', 'definition_cloud_computing', 'technology_ict_industry', '00or22725_techniques_address', '2006_currently_talked']
backup vlm vmp algorithm vms bandwidth framework mapping solves subproblem svi failure vm problem present affected baseline collected comparable correlated 	0	Survivable virtual infrastructure mapping in virtualized data centers	In a virtualized data center, survivability can be enhanced by creating redundant Virtual Machines (VMs) as backup for VMs such that after VM or server failures, affected services can be quickly switched over to backup VMs. To enable flexible and efficient resource management, we propose to use a service-aware approach in which multiple correlated VMs and their backups are grouped together to form a Survivable Virtual Infrastructure (SVI) for a service or a tenant. A fundamental problem in such a system is to determine how to map each SVI to a physical data center network such that operational costs are minimized subject to the constraints that each VM’s resource requirements are met and bandwidth demands between VMs can be guaranteed before and after failures. This problem can be naturally divided into two sub-problems: VM Placement (VMP) and Virtual Link Mapping (VLM). We present a general optimization framework for this mapping problem. Then we present an efficient algorithm for the VMP subproblem as well as a polynomial-time algorithm that optimally solves the VLM subproblem, which can be used as subroutines in the framework. We also present an effective heuristic algorithm that jointly solves the two subproblems. It has been shown by extensive simulation results based on the real VM data traces collected from the green data center at Syracuse University that compared with the First Fit Descending (FFD) and single shortest path based baseline algorithm, both our VMP+VLM algorithm and joint algorithm significantly reduce the reserved bandwidth, and yield comparable results in terms of the number of active servers.	['cloud', 'discus', 'vm']	['v_man', 'ict_industry', 'level_virtualization', 'algorithm_jointly', 'algorithm_vmp']	['cloud_computing_we', 'definition_cloud_computing', 'technology_ict_industry', '00or22725_techniques_address', '2006_currently_talked']
loading cooling response time proposal surgeguard power active 30 absorb fine granularity incur maximum powertrade scheme standby idle previous server 	1	Joint optimization of idle and cooling power in data centers while maintaining response time	Server power and cooling power amount to a significant fraction of modern data centers’ recurring costs. While data centers provision enough servers to guarantee response times under the maximum loading, data centers operate under much less loading most of the times (e.g., 30-70% of the maximum loading). Previous serverpower proposals exploit this under-utilization to reduce the server idle power by keeping active only as many servers as necessary and putting the rest into low-power standby modes. However, these proposals incur higher cooling power due to hot spots created by concentrating the data center loading on fewer active servers, or degrade response times due to standby-to-active transition delays, or both. Other proposals optimize the cooling power but incur considerable idle power. To address the first issue of power, we propose PowerTrade, which trades-off idle power and cooling power for each other, thereby reducing the total power. To address the second issue of response time, we propose SurgeGuard to overprovision the number of active servers beyond that needed by the current loading so as to absorb future increases in the loading. SurgeGuard is a two-tier scheme which uses well-known over-provisioning at coarse time granularities (e.g., one hour) to absorb the common, smooth increases in the loading, and a novel fine-grain replenishment of the over-provisioned reserves at fine time granularities (e.g., five minutes) to handle the uncommon, abrupt loading surges. Using real-world traces, we show that combining PowerTrade and SurgeGuard reduces total power by 30% compared to previous low-power schemes while maintaining response times within 1.7%.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
amdahl throughput blade constant intensive keeping state consumption architecture called combine comprising consequence disk double forcing hit i law magnitude 	1	Low-power Amdahl-balanced blades for data intensive computing	Enterprise and scientific data sets double every year, forcing similar growths in storage size and power consumption. As a consequence, current system architectures used to build data warehouses are about to hit a power consumption wall. In this paper we propose an alternative architecture comprising large number of so-called Amdahl blades that combine energy-efficient CPUs with solid state disks to increase sequential read I/O throughput by an order of magnitude while keeping power consumption constant. We also show that while keeping the total cost of ownership constant, Amdahl blades offer five times the throughput of a state-of-theart computing cluster for data-intensive applications. Finally, using the scaling laws originally postulated by Amdahl, we show that systems for data-intensive computing must maintain a balance between low power consumption and per-server throughput to optimize performance per Watt.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
security virtualization improve aggregation basic con explains flexibility greater integrated keywords— pro refers taxonomy threat unified vmm autonomous more purpose 	1	Virtualization: A survey on concepts, taxonomy and associated security issues	Virtualization is a term that refers to the abstraction of computer resources. The purpose of virtual computing environment is to improve resource utilization by providing a unified integrated operating platform for users and applications based on aggregation of heterogeneous and autonomous resources. More recently, virtualization at all levels (system, storage, and network) became important again as a way to improve system security, reliability and availability, reduce costs, and provide greater flexibility. This paper explains the basics of system virtualization and addresses pros and cons of virtualization along with taxonomy and challenges. Keywords— Virtualization; hypervisor; VMM; Security; Threats.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
cooling container floor raised center optimization data compared 41 42 80 block comparative employing estimate facility far introduced modular multitude 	1	A quantitative analysis of cooling power in container-based data centers	Cooling power is often represented as a single taxed cost on the total energy consumption of the data center. Some estimates go as far as 50% of the total energy demand. However, this view is rather simplistic in the presence of a multitude of cooling options and optimizations. In response to the rising cost of energy, the industry introduced modular design in the form of containers to serve as the new building block for data centers. However, it is still unclear how efficient they are compared to raised-floor data centers and under what conditions they are preferred. In this paper, we provide comparative and quantitative analysis of cooling power in both container-based and raised-floor data centers. Our results show that a container achieves 80% and 42% savings in cooling and facility powers respectively compared to a raised-floor data center and that savings of 41% in cooling power are possible when workloads are consolidated onto the least number of containers. We also show that cooling optimizations are not very effective at high utilizations; and that a raised-floor data center can approach the efficiency of a container at low utilizations when employing a simple cooling optimization.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
variation server assignment process rack total placement center power method task consumption data 14 8 85 92 cfd chassis fast 	1	Variation-aware server placement and task assignment for data center power minimization	Size and number of data centers are fast growing all over the world and their increasing total power consumption is a worldwide concern. Moreover, increase in the amount of process variation in nanometer technologies and its effect on total power consumption of servers has made it inevitable to move toward variation-aware power reduction strategies. This paper formulates a variation-aware joint server placement and task assignment method using Integer Linear Programming (ILP) to minimize total power consumption of data centers. We first determine the optimum placement of servers in the data center racks based on total power consumption of each server and the data center recirculation model obtained by Computational Fluid Dynamics (CFD) simulations. Then, we dynamically consolidate the ON servers in chassis and racks such that the use of powergreedy servers is minimized. Experimental results reveal up to 14.85% and an average of 8.92% power saving at different server utilization rates with respect to conventional methods. Keywords-Data center, Power reduction, Process variation, Server placement, Task assignment.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
research draw question paradigm task comparison computing model both calculation classic coordination decomposition examined identifying pervasive product qualitative selling series 	1	A tale of clouds: Paradigm comparisons and some thoughts on research issues	Cloud computing is an emerging computing paradigm. It aims to share data, calculations, and services transparently among users of a massive grid. Although the industry has started selling cloud-computing products, research challenges in various areas, such as UI design, task decomposition, task distribution, and task coordination, are still unclear. Therefore, we study the methods to reason and model cloud computing as a step toward identifying fundamental research questions in this paradigm. In this paper, we compare cloud computing with service computing and pervasive computing. Both the industry and research community have actively examined these three computing paradigms. We draw a qualitative comparison among them based on the classic model of computer architecture. We finally evaluate the comparison results and draw up a series of research questions in cloud computing for future exploration.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
technology hypervisors hypervisor virtualization analysis performance important accepted applicability choice commonly depending depth disadvantage emerges equal experience focusing futuregrid kvm 	1	Analysis of virtualization technologies for high performance computing environments	As Cloud computing emerges as a dominant paradigm in distributed systems, it is important to fully understand the underlying technologies that make Clouds possible. One technology, and perhaps the most important, is virtualization. Recently virtualization, through the use of hypervisors, has become widely used and well understood by many. However, there are a large spread of different hypervisors, each with their own advantages and disadvantages. This paper provides an in-depth analysis of some of today’s commonly accepted virtualization technologies from feature comparison to performance analysis, focusing on the applicability to High Performance Computing environments using FutureGrid resources. The results indicate virtualization sometimes introduces slight performance impacts depending on the hypervisor type, however the benefits of such technologies are profound and not all virtualization technologies are equal. From our experience, the KVM hypervisor is the optimal choice for supporting HPC applications within a Cloud infrastructure.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
dissipation network co2 point information communication energy emission limit layer theory link impractical layered minimizing minimum stem ict approach fundamental 	1	Fundamentals of green communications and computing: Modeling and simulation	"A bot tom-up approach to minimizing energy dissipation starts with establishing a fundamental energy dissipation limit, which shows the true gap between current and optimum energy savings and which can serve as a springboard for developing techniques to achieve that limit. Unfortunately, for point-to-point communications, such an approach applies only in certain scenarios; using information-theory approaches to derive energy dissipation limits is largely impractical for large-scale networks, and even some small networks, because incorporating the dynamics of practical networks from an informationtheory perspective is difficult.
As an alternative way to find the minimum energy consumption in larger networks, we propose combining an architecture that uses Internet layers with a physical layer operating at the fundamental limit of energy dissipation. We can then view energy consumption as the fundamental energy consumed per information bit. For large networks, this layered approach is more feasible than an analysis based on information theory.
Our exploration of this approach highlighted some novel implementation challenges, particularly how to address the effects of constraints on the upper layers— constraints that stem from requiring minimal energy consumption at the physical layer. It also revealed new directions and open issues for green network simulation and standardization.
A s society becomes more aware of how carbon diox-ide (CO2) emissions are affecting the environment, the information and communications technology (ICT) community is investigating how to ensure that communication systems consume less energy and thus collectively have a substantially smaller carbon footprint. To that end, researchers have been working on novel techniques to reduce the energy dissipation of point-to-point communication links and computer networks.
Although modifying existing ICT systems can lead to incremental energy savings, the primary purpose of lowering energy dissipation is to reduce the CO2 emission rate. The relationship between these two ideas is more complex than many organizations realize. The ICT community has long assumed that energy savings will reduce CO2 emissions,1 but the amounts of emitted CO2 and dissipated energy are not always linearly related. In some scenarios, optimum CO2 savings in fact do not stem from the lowest possible energy consumption. Minimizing the total energy consumption of links over all possible network
A layered architecture incorporates the concept of minimum energy consumption for communication links and computer networks with multiple terminals, where emission-reduction approaches based on information theory are impractical."	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
uptime scheduler cumulative machine center 60 administrator ass batch besides caused composition consuming customized default demonstrating difference exclusively factor iaa 	1	Energy-aware scheduling for infrastructure clouds	More and more data centers are built, consuming ever more kilo watts of energy. Over the years, energy has become a dominant cost factor for data center operators. Utilizing lowpower idle modes is an immediate remedy to reduce data center power consumption. We use simulation to quantify the difference in energy consumption caused exclusively by virtual machine schedulers. Besides demonstrating the inefficiency of wide-spread default schedulers, we present our own optimized scheduler. Using a range of realistic simulation scenarios, our customized scheduler OptSched reduces cumulative machine uptime by up to 60.1%. We evaluate the effect of data center composition, run time distribution, virtual machine sizes, and batch requests on cumulative machine uptime. IaaS administrators can use our results to quickly assess possible reductions in machine uptime and, hence, untapped energy saving potential.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
ratio llc reference pmv shared usage cache multicore scheduler maximizing performance processor consolidation consider devised faced guaranteeing instruction interference isolation 	1	Virtual machine scheduling for multicores considering effects of shared on-chip last level cache interference	As the cloud markets grow, the cloud providers are faced with new challenges such as reduction of power consumption and guaranteeing service level agreements (SLAs). One reason for these problems is the use of server consolidation policy based on virtualization technologies for maximizing the efficiency of resource usage. Because current virtualization technologies do not ensure performance isolation among active virtual machines (VMs), it is required to consider resource usage pattern of VMs to improve total throughput and quality of service. In this paper, we propose a virtual machine scheduler for multicore processors, which exploits the lastlevel cache (LLC) reference ratio. Specifically, we focus on the performance impact of contention in a shared LLC. We have found that the ratio of the number of LLC references to that of instructions (LLC reference ratio) is highly associated with the amount of cache demand, and a Performance-Maximizing VM (PMV) scheduling algorithm can be devised by using the ratio. We show that our PMV scheduler is effective by evaluation for various workloads. Keywords-Virtual machine consolidation; Shared resource interference; Multicore processor	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
scheduling priority task balancing ldss policy energy efficiency exploit heterogeneous processor awareness capacity controlling cool deadline designing dissipate efficacy excessive 	1	Priority-based scheduling for large-scale distribute systems with energy awareness	Large-scale distributed computing systems (LDSs), such as grids and clouds are primarily designed to provide massive computing capacity. These systems dissipate often excessive energy to both power and cool them. Concerns over greening these systems have prompted a call for scheduling policies with energy awareness (e.g., energy proportionality). The dynamic and heterogeneous nature of resources and tasks in LDSs is a major hurdle to be overcome for energy efficiency when designing scheduling policies. In this paper, we address the problem of scheduling tasks with different priorities (deadlines) for energy efficiency exploiting resource heterogeneity. Specifically, our investigation for energy efficiency focuses on two issues: (1) balancing the workload in the way utilization is maximized and (2) power management by controlling execution of tasks on processor for ensuring the energy is optimally consumed. We form a hierarchical scheduler that exploits the multi-core architecture for effective scheduling. Our scheduling approach exploits the diversity of task priority for proper load balancing across heterogeneous processors while observing energy consumption in the system. Simulation experiments prove the efficacy of our approach; and the comparison results indicate our scheduling policy helps improve energy efficiency of the system. Keywords– energy efficiency, dynamic scheduling, task priority.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
geo network attack center 2 appropriate diversity service providing data to accordingly agility breakdown capital completed distributing diverse dollar fragmentation 	1	The cost of a cloud: Research problems in data center networks	The data centers used to create cloud services represent a significant investment in capital outlay and ongoing costs. Accordingly, we first examine the costs of cloud service data centers today. The cost breakdown reveals the importance of optimizing work completed per dollar invested. Unfortunately, the resources inside the data centers often operate at low utilization due to resource stranding and fragmentation. To attack this first problem, we propose (1) increasing network agility, and (2) providing appropriate incentives to shape resource consumption. Second, we note that cloud service providers are building out geo-distributed networks of data centers. Geo-diversity lowers latency to users and increases reliability in the presence of an outage taking out an entire site. However, without appropriate design and management, these geo-diverse data center networks can raise the cost of providing service. Moreover, leveraging geo-diversity requires services be designed to benefit from it. To attack this problem, we propose (1) joint optimization of network and data center resources, and (2) new systems and mechanisms for geo-distributing state.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
multi core cluster grant trend communication processor intel benchmark cns mellanox message microsystems sun study de optimizing scalability able application 	1	Understanding the impact of multi-core architecture in cluster computing: A case study with Intel dual-core system	Multi-core processors are growing as a new industry trend as single core processors rapidly reach the physical limits of possible complexity and speed. In the new Top500 supercomputer list, more than 20% processors belong to the multi-core processor family. However, without an indepth study on application behaviors and trends on multicore clusters, we might not be able to understand the characteristics of multi-core cluster in a comprehensive manner and hence not be able to get optimal performance. In this paper, we take on these challenges and design a set of experiments to study the impact of multi-core architecture on cluster computing. We choose to use one of the most advanced multi-core servers, Intel Bensley system with Woodcrest processors, as our evaluation platform, and use benchmarks including HPL, NAMD, and NAS as the applications to study. From our message distribution experiments, we find that on an average about 50% messages are transferred through intra-node communication, which is much higher than intuition. This trend indicates that optimizing intranode communication is as important as optimizing internode communication in a multi-core cluster. We also observe that cache and memory contention may be a potential bottleneck in multi-core clusters, and communication middleware and applications should be multi-core aware to alleviate this problem. We demonstrate that multi-core aware algorithm, e.g. data tiling, improves benchmark execution time by up to 70%. We also compare the scalability of a multi-core cluster with that of a single-core cluster and find that the scalability of the multi-core cluster is promising. ∗This research is supported in part by DOE’s Grants#DE-FC0206ER25749 and #DE-FC02-06ER25755; NSF’s Grants #CNS-0403342 and #CNS-0509452; grants from Intel, Mellanox, Cisco systems, Linux Networx and Sun Microsystems; and equipment donations from Intel, Mellanox, AMD, Apple, Appro, Dell, Microway, PathScale, IBM, SilverStorm and Sun Microsystems.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
resulting live policy migration quality brings continuously customer dioxide electrical enormous high justifying led management necessity objective rapid reallocation showing 	1	Energy efficient allocation of virtual machines in cloud data centers	Rapid growth of the demand for computational power has led to the creation of large-scale data centers. They consume enormous amounts of electrical power resulting in high operational costs and carbon dioxide emissions. Moreover, modern Cloud computing environments have to provide high Quality of Service (QoS) for their customers resulting in the necessity to deal with power-performance trade-off. We propose an efficient resource management policy for virtualized Cloud data centers. The objective is to continuously consolidate VMs leveraging live migration and switch off idle nodes to minimize power consumption, while providing required Quality of Service. We present evaluation results showing that dynamic reallocation of VMs brings substantial energy savings, thus justifying further development of the proposed policy. Keywords-Energy efficiency; Cloud computing; Energy consumption; Green IT; Resource management; Virtualization; Allocation of virtual machines; Live migration of virtual machines.	['center', 'processor', 'data']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'total_power']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'total_power_consumption', 'data_centers_operate']
platform provisioning hpc consolidated need tradeoff application efficiency qos these presented energy virtualized resource ability acceptable accommodate attractive autonomic challenging 	2	Energy-efficient application-aware online provisioning for virtualized clouds and data centers	As energy efficiency and associated costs become key concerns, consolidated and virtualized data centers and clouds are attractive computing platforms for dataand computeintensive applications. These platforms provide an abstraction of nearly-unlimited computing resources through the elastic use of pools of consolidated resources, and provide opportunities for higher utilization and energy savings. Recently, these platforms are also being considered for more traditional high-performance computing (HPC) applications that have typically targeted Grids and similar conventional HPC platforms. However, maximizing energy efficiency, costeffectiveness, and utilization for these applications while ensuring performance and other Quality of Service (QoS) guarantees, requires leveraging important and extremely challenging tradeoffs. These include, for example, the tradeoff between the need to efficiently create and provision Virtual Machines (VMs) on data center resources and the need to accommodate the heterogeneous resource demands and runtimes of these applications. In this paper we present an energy-aware online provisioning approach for HPC applications on consolidated and virtualized computing platforms. Energy efficiency is achieved using a workload-aware, just-right dynamic provisioning mechanism and the ability to power down subsystems of a host system that are not required by the VMs mapped to it. We evaluate the presented approach using real HPC workload traces from widely distributed production systems. The results presented demonstrated that compared to typical reactive or predefined provisioning, our approach achieves significant improvements in energy efficiency with an acceptable QoS penalty. Keywords-Autonomic Computing; Cloud Computing; Energy Efficiency; Virtualization; Data Center; Resource Provisioning	['application', 'proposed', 'platform']	['resource_provisioning', 'provision_approach', 'application_placement', 'computing_platforms', 'consolidate_virtual']	['data_center_resources', 'service_level_agreements', 'as_energy_efficiency', 'ability_power_subsystems', 'abstracted_bin_packing']
application enacloud live approach placement proposed platform abstracted available character encapsulate ivic named place prevalence requested save specially successfully useful 	2	EnaCloud: An energy-saving application live placement approach for cloud computing environments	With the increasing prevalence of large scale cloud computing environments, how to place requested applications into available computing servers regarding to energy consumption has become an essential research problem, but existing application placement approaches are still not effective for live applications with dynamic characters. In this paper, we proposed a novel approach named EnaCloud, which enables application live placement dynamically with consideration of energy efficiency in a cloud platform. In EnaCloud, we use a Virtual Machine to encapsulate the application, which supports applications scheduling and live migration to minimize the number of running machines, so as to save energy. Specially, the application placement is abstracted as a bin packing problem, and an energy-aware heuristic algorithm is proposed to get an appropriate solution. In addition, an over-provision approach is presented to deal with the varying resource demands of applications. Our approach has been successfully implemented as useful components and fundamental services in the iVIC platform. Finally, we evaluate our approach by comprehensive experiments based on virtual machine monitor Xen and the results show that it is feasible.	['application', 'proposed', 'platform']	['resource_provisioning', 'provision_approach', 'application_placement', 'computing_platforms', 'consolidate_virtual']	['data_center_resources', 'service_level_agreements', 'as_energy_efficiency', 'ability_power_subsystems', 'abstracted_bin_packing']
sla agreement provisioning proposed level according customers’ manager meeting proposes violating resource reducing outperforms slas request component consideration experimental machine 	2	Energy-efficient resource provisioning with SLA consideration on cloud computing	Cloud computing aims at reducing energy consumption and maximizing resource efficiency without violating service level agreement (SLA). To address these important issues, this study proposes an energy-efficient resource provisioning technology with SLA consideration for virtual machine scheduling. According to SLAs, the resource manager could consolidate virtual machines onto the physical machine for meeting customers’ SLA requests. Experimental results show that the proposed approach outperforms other proposed ones in power consumption. Keywords-component; Cloud Computing; Virtualization; Energy Saving; Resource Provisioning; Service Level Agreement	['application', 'proposed', 'platform']	['resource_provisioning', 'provision_approach', 'application_placement', 'computing_platforms', 'consolidate_virtual']	['data_center_resources', 'service_level_agreements', 'as_energy_efficiency', 'ability_power_subsystems', 'abstracted_bin_packing']
relocation consolidation bound theoretical server conduct method analysis algorithm necessary trade bin fit packing cost quality problem machine experiment optimization 	3	Server consolidation algorithms with bounded migration cost and performance guarantees in cloud computing	Consolidation of virtual machines is essential to achieve energy optimization in cloud computing environments. As virtual machines dynamically enter and leave a cloud system, it becomes necessary to relocate virtual machines among servers. However, relocation of virtual machines introduces run-time overheads and consumes extra energy, thus an careful planning for relocation is necessary. We model the relocation problem as a modified bin packing problem and propose a new server consolidation algorithm that guarantees server consolidation with bounded relocation costs. We also conduct a detailed analysis on the complexity of the server consolidation problem, and give a upper bound on the cost of relocation. Finally, we conduct simulations and compare our server consolidation algorithm with other relocation methods, like First Fit and Best Fit method. The experiment results suggest an interesting trade-off between server consolidation quality and relocation cost. Our algorithm is able to trade about 1% in server consolidation quality for a reduction about 50% in relocation cost, when compared with other well known bin packing algorithms. We also note that the relocation cost incurred in our method is much less than the theoretical bound we provided. The reason is that we overestimate the amount of relocation from theoretical analysis, and the actual amount of relocation found from experiments is much less than the worst-case bound from theoretical analysis. Keywords-Energy Optimization; Server Consolidation; VM Relocation;	['consolidation', 'algorithm', 'optimization']	['relocation_costs', 'consolidation_algorithm', 'greedy_algorithms', 'bin_packing', 'ant_colony']	['ant_colony_optimization', 'multidimensional_bin_packing', 'relocate_virtual_machines', 'server_consolidation_algorithm', 'server_consolidation_quality']
aco greedy workload ant applied colony consolidation multidimensional perform algorithm ffd nature e optimization bin packing approach moreover design better 	3	Energy-aware ant colony based workload placement in clouds	With increasing numbers of energy hungry data centers energy conservation has now become a major design constraint. One traditional approach to conserve energy in virtualized data centers is to perform workload (i.e., VM) consolidation. Thereby, workload is packed on the least number of physical machines and over-provisioned resources are transitioned into a lower power state. However, most of the workload consolidation approaches applied until now are limited to a single resource (e.g., CPU) and rely on simple greedy algorithms such as First-Fit Decreasing (FFD), which perform resource-dissipative workload placement. Moreover, they are highly centralized and known to be hard to distribute. In this work, we model the workload consolidation problem as an instance of the multidimensional bin-packing (MDBP) problem and design a novel, nature-inspired workload consolidation algorithm based on the Ant Colony Optimization (ACO). We evaluate the ACO-based approach by comparing it with one frequently applied greedy algorithm (i.e., FFD). Our simulation results demonstrate that ACO outperforms the evaluated greedy algorithm as it achieves superior energy gains through better server utilization and requires less machines. Moreover, it computes solutions which are nearly optimal. Finally, the autonomous nature of the approach allows it to be implemented in a fully distributed environment. Keywords-Ant Colony Optimization, Combinatorial Optimization, Green Cloud Computing, Multidimensional Bin Packing, Swarm Intelligence, Virtualization	['consolidation', 'algorithm', 'optimization']	['relocation_costs', 'consolidation_algorithm', 'greedy_algorithms', 'bin_packing', 'ant_colony']	['ant_colony_optimization', 'multidimensional_bin_packing', 'relocate_virtual_machines', 'server_consolidation_algorithm', 'server_consolidation_quality']
