ref_title	ref_context	ref_entry	abstract	intro	ref_link	label	topic_word	topic_bigram	topic_trigram	description
Joint optimization of idle and cooling power in data centers while maintaining response time	[]	Faraz Ahmad, and T.N. Vijaykumar. 2010. Joint optimization of idle and cooling power in data centers while maintaining response time. ACM SIGPLAN Notices 45, 3 (March 2010) 243–256. DOI: http://dx.doi.org/10.1145/1735971.1736048	Server power and cooling power amount to a significant fraction of modern data centers’ recurring costs. While data centers provision enough servers to guarantee response times under the maximum loading, data centers operate under much less loading most of the times (e.g., 30-70% of the maximum loading). Previous serverpower proposals exploit this under-utilization to reduce the server idle power by keeping active only as many servers as necessary and putting the rest into low-power standby modes. However, these proposals incur higher cooling power due to hot spots created by concentrating the data center loading on fewer active servers, or degrade response times due to standby-to-active transition delays, or both. Other proposals optimize the cooling power but incur considerable idle power. To address the first issue of power, we propose PowerTrade, which trades-off idle power and cooling power for each other, thereby reducing the total power. To address the second issue of response time, we propose SurgeGuard to overprovision the number of active servers beyond that needed by the current loading so as to absorb future increases in the loading. SurgeGuard is a two-tier scheme which uses well-known over-provisioning at coarse time granularities (e.g., one hour) to absorb the common, smooth increases in the loading, and a novel fine-grain replenishment of the over-provisioned reserves at fine time granularities (e.g., five minutes) to handle the uncommon, abrupt loading surges. Using real-world traces, we show that combining PowerTrade and SurgeGuard reduces total power by 30% compared to previous low-power schemes while maintaining response times within 1.7%.	As mentioned in Section 1, spatial subsetting reduces server idle power but increases cooling power whereas inverse-temperature assignment reduces cooling cost but incurs high idle power. We propose a joint optimization, called PowerTrade, to reduce idle power and cooling power together so that the total power is reduced. Because PowerTrade builds on spatial subsetting and inverse-temperature assignment, we describe these schemes first.	https://doi.org/10.1145/1735971.1736048	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Ahmad, et al. [NO] proposes powertrade, which trades-off idle power and cooling power for each other, thereby reducing the total power. 
Energy efficient allocation of virtual machines in cloud data centers	[]	Anton Beloglazov, and Rajkumar Buyya. 2010. Energy efficient allocation of virtual machines in cloud data centers. 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid’10). 577–578. DOI:http://dx.doi.org/10.1109/CCGRID.2010.45	Rapid growth of the demand for computational power has led to the creation of large-scale data centers. They consume enormous amounts of electrical power resulting in high operational costs and carbon dioxide emissions. Moreover, modern Cloud computing environments have to provide high Quality of Service (QoS) for their customers resulting in the necessity to deal with power-performance trade-off. We propose an efficient resource management policy for virtualized Cloud data centers. The objective is to continuously consolidate VMs leveraging live migration and switch off idle nodes to minimize power consumption, while providing required Quality of Service. We present evaluation results showing that dynamic reallocation of VMs brings substantial energy savings, thus justifying further development of the proposed policy. Keywords-Energy efficiency; Cloud computing; Energy consumption; Green IT; Resource management; Virtualization; Allocation of virtual machines; Live migration of virtual machines.	"The proposed heuristics have been evaluated by simulation using CloudSim toolkit <NO>. The simulated data center comprises 100 heterogeneous physical nodes. Each node is modeled to have one CPU core with performance equivalent to 1000, 2000 or 3000 MIPS, 8 GB of RAM and 1 TB of storage. Users submit requests for provisioning of 290 heterogeneous VMs that fill the full capacity of the data center. For the benchmark policies we simulated a Non Power Aware policy (NPA) and DVFS that adjusts the voltage and frequency of CPU according to current utilization. We present results obtained using ST policy and the best two-threshold policy, MM policy. Besides that, the policies have been evaluated with different values of the thresholds.
The simulation results presented in Table I show that dynamic reallocation of VMs according to current utilization of CPU brings higher energy savings compared with static allocation policies. MM policy achieves the best energy savings: by 83%, 66% and 23% less energy consumption relatively to NPA, DVFS and ST policies respectively with thresholds 30-70% and ensuring percentage of SLA violations of 1.1%; and by 87%, 74% and 43% with thresholds 50-90% and 6.7% of SLA violations. MM policy leads to more than 10 times fewer VM migrations than ST. The results show the flexibility of the proposed algorithms, as the thresholds can be adjusted according to SLA requirements. Strict SLA (1.11%) allow achievement of the energy consumption of
1.48 KWh. However, if SLA are relaxed (6.69%), the energy consumption is further reduced to 1.14 KWh.
In this work we have proposed and evaluated heuristics for dynamic reallocation of VMs to minimize energy consumption, while providing reliable QoS. The obtained results show that the technique of dynamic reallocation of VMs and switching off the idle servers brings substantial energy savings and is applicable to real-world Cloud data centers. For the future work, we propose to investigate the consideration of multiple system resource in reallocation decisions, such as network interface and disk storage, as these resources also significantly contribute to the overall energy consumption. Other interesting directions for the future work are investigation of setting the utilization thresholds dynamically according to a current set of VMs allocated to a host, leveraging multi-core CPU architectures, and decentralization of the optimization algorithms to improve scalability and fault tolerance. Besides the reduction of operational and establishment costs, the work has social significance as it decreases carbon dioxide footprints and energy consumption by modern IT infrastructures.
REFERENCES
<NO> R. Brown et al., “Report to congress on server and data center energy efficiency: Public law 109-431,” Lawrence Berkeley National Laboratory, 2008.
<NO> R. Buyya, C. S. Yeo, and S. Venugopal, “Market-oriented cloud computing: Vision, hype, and reality for delivering it services as computing utilities,” in Proceedings of HPCC’08. IEEE CS Press, Los Alamitos, CA, USA, 2008.
<NO> D. Kusic, J. O. Kephart, J. E. Hanson, N. Kandasamy, and G. Jiang, “Power and performance management of virtualized computing environments via lookahead control,” Cluster Computing, vol. 12, no. 1, pp. 1–15, 2009.
<NO> S. Srikantaiah, A. Kansal, and F. Zhao, “Energy aware consolidation for cloud computing,” Cluster Computing, vol. 12, pp. 1–15, 2009.
<NO> R. Buyya, R. Ranjan, and R. N. Calheiros, “Modeling and simulation of scalable cloud computing environments and the CloudSim toolkit: Challenges and opportunities,” in Proceedings of HPCS’09. IEEE Press, NY, USA, 2009.
578"	https://doi.org/10.1109/CCGRID.2010.45	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Beloglazov, et al. [NO] proposes an efficient resource management policy for virtualized cloud data centers. 
Understanding the impact of multi-core architecture in cluster computing: A case study with Intel dual-core system	[]	Lei Chai, Qi Gao, and Dhabaleswar K. Panda. 2007. Understanding the impact of multi-core architecture in cluster computing: A case study with Intel dual-core system. 7th IEEE International Symposium on Cluster Computing and the Grid (CCGRID’07). IEEE, 471–478. DOI:http://dx.doi.org/10.1109/ CCGRID.2007.119.	Multi-core processors are growing as a new industry trend as single core processors rapidly reach the physical limits of possible complexity and speed. In the new Top500 supercomputer list, more than 20% processors belong to the multi-core processor family. However, without an indepth study on application behaviors and trends on multicore clusters, we might not be able to understand the characteristics of multi-core cluster in a comprehensive manner and hence not be able to get optimal performance. In this paper, we take on these challenges and design a set of experiments to study the impact of multi-core architecture on cluster computing. We choose to use one of the most advanced multi-core servers, Intel Bensley system with Woodcrest processors, as our evaluation platform, and use benchmarks including HPL, NAMD, and NAS as the applications to study. From our message distribution experiments, we find that on an average about 50% messages are transferred through intra-node communication, which is much higher than intuition. This trend indicates that optimizing intranode communication is as important as optimizing internode communication in a multi-core cluster. We also observe that cache and memory contention may be a potential bottleneck in multi-core clusters, and communication middleware and applications should be multi-core aware to alleviate this problem. We demonstrate that multi-core aware algorithm, e.g. data tiling, improves benchmark execution time by up to 70%. We also compare the scalability of a multi-core cluster with that of a single-core cluster and find that the scalability of the multi-core cluster is promising. ∗This research is supported in part by DOE’s Grants#DE-FC0206ER25749 and #DE-FC02-06ER25755; NSF’s Grants #CNS-0403342 and #CNS-0509452; grants from Intel, Mellanox, Cisco systems, Linux Networx and Sun Microsystems; and equipment donations from Intel, Mellanox, AMD, Apple, Appro, Dell, Microway, PathScale, IBM, SilverStorm and Sun Microsystems.	"Multi-core means to integrate two or more complete computational cores within a single chip <NO>. The motivation is the fact that scaling up processor speed results in dramatic rise in power consumption and heat generation. In addition, it becomes more difficult to increase processor speed nowadays that even a little increase in performance will be costly. Realizing these factors, computer architects have proposed multi-core processors that speed up application performance by dividing the workload among multiple processing cores instead of using one “super fast” single processor. Multi-core processor is also referred to as Chip Multiprocessor (CMP). Since a processing core can
be viewed as an independent processor, in this paper we use processor and core interchangeably.
Most processor vendors have multi-core products, e.g. Intel Quad- and Dual-Core Xeon, AMD Quad- and DualCore Opteron, Sun Microsystems UltraSPARC T1 (8 cores), IBM Cell, etc. There are various alternatives in designing cache hierarchy organization and memory access model. Figure 1 illustrates two typical multi-core system designs. The left box shows a NUMA <NO> based dual-core system in which each core has its own L2 cache. Two cores on the same chip share the memory controller and local memory. Processors can also access remote memory, although local memory access is much faster. The right box shows a bus based dual-core system, in which two cores on the same chip share the same L2 cache and memory controller, and all the cores access the main memory through a shared bus.
Multi-core processors have been deployed in cluster computing. In a multi-core cluster, there are three levels of communication. The communication between two processors on the same chip is referred to as intra-CMP communication in this paper. The communication across chips but within a node is referred to as inter-CMP communication. And the communication between two processors on different nodes is referred to as inter-node communication. Multi-core clusters impose new challenges in software design, both at the middleware level and application level."	https://doi.org/10.1109/CCGRID.2007.119	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Chai, et al. [NO] might not is able to understand the characteristics of multi-core cluster in a comprehensive manner and hence not be able to get optimal performance.
Cloud computing: Issues and challenges	[]	Tharam Dillon, Chen Wu, and Elizabeth Chang. 2010. Cloud computing: Issues and challenges. 24th IEEE International Conference on Advanced Information Networking and Applications (AINA). 27–33. DOI:http://dx.doi.org/10.1109/AINA.2010.187	Many believe that Cloud will reshape the entire ICT industry as a revolution. In this paper, we aim to pinpoint the challenges and issues of Cloud computing. We first discuss two related computing paradigms Service-Oriented Computing and Grid computing, and their relationships with Cloud computing We then identify several challenges from the Cloud computing adoption perspective. Last, we will highlight the Cloud interoperability issue that deserves substantial further research	"What is Cloud Computing? Although many formal definitions have been proposed in both academia and industry, the one provided by U.S. NIST (National Institute of Standards and Technology) <NO> appears to include key common elements widely used in the Cloud Computing community:
Cloud computing is a model for enabling convenient, ondemand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction <NO>.
This definition includes cloud architectures, security, and deployment strategies. In particular, five essential elements of cloud computing are clearly articulated:
On-demand self-service: A consumer with an instantaneous need at a particular timeslot can avail computing resources (such as CPU time, network storage, software use, and so forth) in an automatic (i.e. convenient, self-serve) fashion without resorting to human interactions with providers of these resources.
Broad network access: These computing resources are delivered over the network (e.g. Internet) and used by various client applications with heterogeneous platforms (such as mobile phones, laptops, and PDAs) situated at a consumer's site.
Resource pooling. A cloud service provider’s computing resources are 'pooled' together in an effort to serve multiple consumers using either the multi-tenancy or the virtualization model, ""with different physical and virtual resources dynamically assigned and reassigned according to consumer demand"" <NO>. The motivation for setting up such a pool-based computing paradigm lies in two important factors: economies of scale and specialization. The result of a pool-based model is that physical computing resources become 'invisible' to consumers, who in general do not have control or knowledge over the location, formation, and originalities of these resources (e.g. database, CPU, etc.) . For example, consumers are not able to tell where their data is going to be stored in the Cloud.
Rapid elasticity. For consumers, computing resources become immediate rather than persistent: there are no up-front commitment and contract as they can use them to scale up whenever they want, and release them once they finish to scale down. Moreover, resources provisioning appears to be infinite to them, the consumption can rapidly rise in order to meet peak requirement at any time.
Measured Service. Although computing resources are pooled and shared by multiple consumers (i.e. multi-tenancy), the cloud infrastructure is able to use appropriate mechanisms
1550-445X/10 $26.00 © 2010 IEEE DOI 10.1109/AINA.2010.187
27
to measure the usage of these resources for each individual consumer through its metering capabilities."	https://doi.org/10.1145/1735971.1736048	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Dillon, et al. [NO] aims to pinpoints the challenges and issues of cloud computing. 
Energy-aware ant colony based workload placement in clouds	[]	Eugen Feller, Louis Rilling, and Christine Morin. 2011. Energy-aware ant colony based workload placement in clouds. Proceedings of IEEE/ACM 12th International Conference on Grid Computing. 26–33. IEEE, DOI:http://dx.doi.org/10.1109/Grid.2011.13	With increasing numbers of energy hungry data centers energy conservation has now become a major design constraint. One traditional approach to conserve energy in virtualized data centers is to perform workload (i.e., VM) consolidation. Thereby, workload is packed on the least number of physical machines and over-provisioned resources are transitioned into a lower power state. However, most of the workload consolidation approaches applied until now are limited to a single resource (e.g., CPU) and rely on simple greedy algorithms such as First-Fit Decreasing (FFD), which perform resource-dissipative workload placement. Moreover, they are highly centralized and known to be hard to distribute. In this work, we model the workload consolidation problem as an instance of the multidimensional bin-packing (MDBP) problem and design a novel, nature-inspired workload consolidation algorithm based on the Ant Colony Optimization (ACO). We evaluate the ACO-based approach by comparing it with one frequently applied greedy algorithm (i.e., FFD). Our simulation results demonstrate that ACO outperforms the evaluated greedy algorithm as it achieves superior energy gains through better server utilization and requires less machines. Moreover, it computes solutions which are nearly optimal. Finally, the autonomous nature of the approach allows it to be implemented in a fully distributed environment. Keywords-Ant Colony Optimization, Combinatorial Optimization, Green Cloud Computing, Multidimensional Bin Packing, Swarm Intelligence, Virtualization	"Ant Colony Optimization (ACO) is a meta-heuristic, which was initially introduced as Ant Systems (AS) in 1992 within the PhD thesis of the Italian researcher Marco Dorigo <NO>. Initially, it was developed to solve the Traveling Salesman Problem (TSP). However, since then it has been successfully adapted to solve many other complex combinatorial optimization problems (e.g., vehicle routing, quadratic assignment, dynamic job scheduling, graph coloring and bin packing).
The main inspiration to develop this system was the natural food-discovery behavior of real ants. Because of the limited abilities of the ants to see and hear their environment they have developed a form of indirect communications (also called Stigmergy) by use of a chemical substance referred as
pheromone. This substance is deposited by each ant on the path it traverses and evaporates after a certain period of time. Other ants can smell the concentration of this substance and tend to favor paths probabilistically according to the amount of pheromone deposited on them. Surprisingly, after some time the entire ant colony converges towards the shortest path to the food source. This behavior was studied by biologists in numerous controlled experiments <NO> and can be explained as follows. At the beginning, when starting from the nest the ants choose a random path to follow. However, on the shortest path to the food source the ants will return faster. Thereby, this path will have a stronger pheromone concentration thus being more attractive for subsequent ants to follow it. When time passes, pheromone concentration on the shortest paths will continue to increase, while on the longer ones it will keep falling, making them less and less attractive.
When applied on combinatorial optimization problems such as TSP or the Bin-Packing Problem (BPP), artificial ants act as a multi-agent system and construct a complex solution based on indirect low-level communication. Thereby, several parts of the algorithm need to be defined in order to imitate real ants. Similarly, as real ants do, a decision on which path or item to choose next needs to be taken. Therefore, a probabilistic decision rule has to be defined which will be used by the algorithm to guide the ants choice towards the optimal solution. Furthermore, unlike real ants, a memory is necessary for each ant, which will be used to keep track of the local solution constructed so far. Finally, a pheromone update mechanism is required in order to: (1) simulate pheromone evaporation, (2) deposit pheromone either on the visited paths (i.e., TSP) or on the selected item-bin pairs (i.e., BPP), respectively. Thereby, a decision needs to be taken on which ant will perform the pheromone updates. This can be either done after each ants move, by the iterations best ant, or the best-so-far ant. We will describe our design choices in Section IV."	https://doi.org/10.1109/Grid.2011.13	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Feller, et al. [NO] models the workload consolidation problem as an instance of the multidimensional bin-packing (mdbp) problem and design a novel, nature-inspired workload consolidation algorithm based on the ant colony optimization (aco). 
The cost of a cloud: Research problems in data center networks	[]	Albert Greenberg, James Hamilton, David A. Maltz, and Parveen Patel. 2008. The cost of a cloud: Research problems in data center networks. ACM SIGCOMM Computer Communication Review 39, 1 (2008) 68–73. DOI:http://dx.doi.org/10.1145/1496091.1496103	The data centers used to create cloud services represent a significant investment in capital outlay and ongoing costs. Accordingly, we first examine the costs of cloud service data centers today. The cost breakdown reveals the importance of optimizing work completed per dollar invested. Unfortunately, the resources inside the data centers often operate at low utilization due to resource stranding and fragmentation. To attack this first problem, we propose (1) increasing network agility, and (2) providing appropriate incentives to shape resource consumption. Second, we note that cloud service providers are building out geo-distributed networks of data centers. Geo-diversity lowers latency to users and increases reliability in the presence of an outage taking out an entire site. However, without appropriate design and management, these geo-diverse data center networks can raise the cost of providing service. Moreover, leveraging geo-diversity requires services be designed to benefit from it. To attack this problem, we propose (1) joint optimization of network and data center resources, and (2) new systems and mechanisms for geo-distributing state.	"It is natural to ask why existing solutions for the enterprise data center do not work for cloud service data centers. First and foremost, the leading cost in the enterprise is operational staff. In the data center, such costs are so small (under 5% due to automation), that we safely omit them from Table 1. In a well-run enterprise, a typical ratio of IT staff members to servers is 1:100. Automation is partial <NO>, and human error is the cause of a large fraction of performance impacting problems <NO>. In cloud service data centers, automation is a mandatory requirement of scale, and it is accordingly a foundational principle of design <NO>. In a well run data center, a typical ratio of staff members to servers is 1:1000. Automated, recovery-oriented computing techniques cope successfully with the vast majority of problems that arise <NO>.
There are additional differences between the enterprise and the cloud service data center environments including:
Large economies of scale. The size of cloud scale data centers (some now approaching 100,000 severs) presents an opportunity to leverage economies of scale not present in the enterprise data centers, though the up front costs are high.
Scale Out. Enterprises often optimize for physical space and number of devices, consolidating workload onto a small number of high-price “scale-up” hardware devices and servers. Cloud service data centers “scale-out” — distributing workload over large numbers of low cost servers and hardware.
That said, enterprises are also moving toward the cloud. Thus, we expect innovation in cloud service data centers to benefit the enterprise, through outsourcing of computing and storage to cloud service providers <NO>, and/or adapting and scaling down technologies and business models from cloud service providers."	https://doi.org/10.1145/1496091.1496103	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Greenberg, et al. [NO] first examines the costs of cloud service data centers today. 
Server consolidation algorithms with bounded migration cost and performance guarantees in cloud computing	[]	Yufan Ho, Pangfeng Liu, and Jan-Jan Wu. 2011. Server consolidation algorithms with bounded migration cost and performance guarantees in cloud computing. 4th IEEE International Conference on Utility and Cloud Computing (UCC). 154–161. DOI:http://doi.ieeecomputersociety.org/10.1109/UCC.2011.30.	Consolidation of virtual machines is essential to achieve energy optimization in cloud computing environments. As virtual machines dynamically enter and leave a cloud system, it becomes necessary to relocate virtual machines among servers. However, relocation of virtual machines introduces run-time overheads and consumes extra energy, thus an careful planning for relocation is necessary. We model the relocation problem as a modified bin packing problem and propose a new server consolidation algorithm that guarantees server consolidation with bounded relocation costs. We also conduct a detailed analysis on the complexity of the server consolidation problem, and give a upper bound on the cost of relocation. Finally, we conduct simulations and compare our server consolidation algorithm with other relocation methods, like First Fit and Best Fit method. The experiment results suggest an interesting trade-off between server consolidation quality and relocation cost. Our algorithm is able to trade about 1% in server consolidation quality for a reduction about 50% in relocation cost, when compared with other well known bin packing algorithms. We also note that the relocation cost incurred in our method is much less than the theoretical bound we provided. The reason is that we overestimate the amount of relocation from theoretical analysis, and the actual amount of relocation found from experiments is much less than the worst-case bound from theoretical analysis. Keywords-Energy Optimization; Server Consolidation; VM Relocation;	"Data centers provide essential computing power for the operations of business, scientific organizations, and academic institutes. However, recent data centers consume significant amount of energy to sustain the system. As energy consumption and associated costs become increasingly
significant, energy management in data center becomes more and more important. As a result, researchers have been investigating mechanism for reducing resource requirements (e.g., number of servers) to decrease energy consumption in cloud data centers.
Server consolidation is a common method for energy optimization in cloud computing environments. There have been numerous works regarding energy conservation by server consolidation in data centers. Srikantaiah et al. <NO> investigate the inter-relationship between energy consumption, resource utilization, and performance of consolidated workloads. The study reveals the energy performance tradeoffs for consolidation and shows that optimal operating points exist.
Li et al. <NO> propose EnaCloud, which places applications dynamically on servers, with consideration of energy efficiency in a cloud platform. The application placement is abstracted as a bin packing problem, and an energyaware heuristic algorithm is proposed to get an appropriate solution.
Beloglazov and Buyya <NO> propose a resource management policy for virtualized cloud data centers. They propose and evaluate heuristics for dynamic reallocation of virtual machines to minimize energy consumption, while providing reliable quality of services. The heuristics are based on the idea of setting upper and lower utilization thresholds for hosts and keeping total utilization of CPU by all virtual machines between these thresholds.
Liao et al. <NO> use live migration to transfer loads among servers on a multi-layer ring-based overlay to reduce power consumption. Active servers are organized into 3-layer rings, and each ring consists of servers that have similar workloads within a specific load interval, so that the inner ring has the servers with the heavy loads, the outer ring has the the servers with light workloads, and the middle ring has the rest of the servers. They move servers, along the workloads at the servers, from the outer and the inner rings toward the middle ring. The idea is to reduce power consumption without affecting the performance of servers.
Hanson et al. <NO> propose AMP, an autonomic manager in charge of the power states of servers. AMP is designed to work in conjunction with other autonomic managers, and is responsible for cutting excess power use and preserving the lifespan of servers it manages. AMP considers broader metrics in its decision, which may include power consumption, server lifespan, and interactions with other application managers. In contrast this paper focuses on computation power as a measurement of resources that a server can provide, and a task can consume. The computation power could be a function of standard metrics like CPU, memory, and disk storage. This focus of a single objective function enables us to analyze the complex trade-off among various standard metrics, so that we can analyze the relocation cost and the quality of consolidation simultaneously.
There are also theoretical works for the server consolidation problem in the literature. The consolidation problems in homogeneous server environments are mostly modeled as a bin packing problem. The bin packing problem is a combinatorial NP-hard problem, and several well-known approximation algorithms have been developed. Let N be the number of bins in optimal solution of a bin packing problem. Dósa and György <NO> proves that the bound of a First Fit Decreasing method is 1.222N + 0.667 and this bound is tight. Xia and Tan <NO> present bounds for the First Fit algorithm. They prove the bound of a First Fit method is 1.7N + 0.7, and the absolute performance ratio of First Fit is at most 1.714.
The online bin packing problem is also studied in the literature. Lee and Lee <NO> give an algorithm for online bin packing with a worst-case performance ratio of less than 1.636. Babel <NO> presents two online algorithms for online bin packing problems with cardinality constraints.
To achieve the goal of server consolidation in dynamic environments, we must relocate virtual machines among servers. In this paper, we focus on reducing the relocation costs introduced by relocation of virtual machines, while still guaranteeing solution quality. The relocation is to relocate virtual machines in such a way that the performance guarantee of the First Fit is still valid after relocation. Note that the First Fit method not only produces a theoretically good solution in the worst case, but also a good solution in the average case. As a result we choose to maintain a First Fit ordering when we relocate virtual machines."	https://doi.org/10.1109/UCC.2011.30	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Ho, et al. [NO] models the relocation problem as a modified bin packing problem and propose a new server consolidation algorithm that guarantees server consolidation with bounded relocation costs. 
Priority-based scheduling for large-scale distribute systems with energy awareness	[]	Masnida Hussin, Young C. Lee, and Albert Y. Zomaya. 2011. Priority-based scheduling for large-scale distribute systems with energy awareness. IEEE 9th International Conference on Dependable, Autonomic and Secure Computing (DASC’11). 503–509. DOI:http://dx.doi.org/10.1109/DASC.2011.96	Large-scale distributed computing systems (LDSs), such as grids and clouds are primarily designed to provide massive computing capacity. These systems dissipate often excessive energy to both power and cool them. Concerns over greening these systems have prompted a call for scheduling policies with energy awareness (e.g., energy proportionality). The dynamic and heterogeneous nature of resources and tasks in LDSs is a major hurdle to be overcome for energy efficiency when designing scheduling policies. In this paper, we address the problem of scheduling tasks with different priorities (deadlines) for energy efficiency exploiting resource heterogeneity. Specifically, our investigation for energy efficiency focuses on two issues: (1) balancing the workload in the way utilization is maximized and (2) power management by controlling execution of tasks on processor for ensuring the energy is optimally consumed. We form a hierarchical scheduler that exploits the multi-core architecture for effective scheduling. Our scheduling approach exploits the diversity of task priority for proper load balancing across heterogeneous processors while observing energy consumption in the system. Simulation experiments prove the efficacy of our approach; and the comparison results indicate our scheduling policy helps improve energy efficiency of the system. Keywords– energy efficiency, dynamic scheduling, task priority.	"Energy management has been an active area of research over the years for computing components. Processors are the major energy consumer <NO>, thus, accounting its energy consumption is necessary for energy-efficient computing. There are numerous research efforts on energy efficiency that use scheduling algorithms to optimize energy consumption (e.g., <NO>). Since the performance of LDSs greatly influences processing time, heuristics are most popularly adopted in the scheduling model. This is because heuristic methods tend to produce competitive solutions with lower time complexity and react competently in the highly heterogeneous environment. Generally, resource manager or scheduler can contribute much to the overall energy efficiency of the system. It has the ability to work within the processing requirements/ constraints that put forth by the system users. The processing constraints must be effectively handled particularly in the present of dynamic computing; otherwise it may lead to load imbalance, over-provisioning of resources, and system unreliability. The schedulers in <NO> adaptively deal with processing constraints for reliable execution while minimizing energy consumption. The work in <NO> developed a software framework to implement and evaluate various scheduling techniques to save energy with the minimal performance impact. The EASY backfilling policy is proposed in <NO> to increase resource utilization by continuously monitoring the load in the system. It adaptively selects a certain number of resources that need to be put into ‘sleep mode.’ In <NO> a meta-scheduler is used to select the most energy efficient resource site. The scheduler decides the time slot in which tasks should be executed at the minimum CPU frequency for saving energy. A task consolidation technique is proposed in <NO> aiming to maximize resource utilization. The approach contributes for promising energy-saving capability as the energy consumption is significantly reduced when the task is consolidated with one or more tasks. These approaches have demonstrated the effectiveness in minimizing energy consumption while still meeting certain performance goals. However, the efficacy of these approaches in dealing with system dynamicity is limited to a certain level. The scope of energy efficiency also should be stretched further incorporating dynamicity and heterogeneity of both resources and tasks. For the case of large-scale dynamic environment, it is much beneficial for a scheduler to
measure its performance and adapt accordingly. The scheduler typically, strives for minimizing response time and ensuring fairness among the running tasks in the system. The impending widespread usage of multiple processor cores appear to be an excellent opportunity for realizing performance and energy benefits <NO>. To seek for the optimal performance, the scheduler needs to actively adapt of the multi-core processors topologies while being aware of task characteristics. Due to the fact that cores in a processor are in a very close proximity to each other <NO>, load balancing can be done very effectively reducing idle time of processors. Dynamic scheduling can be of a very effective approach for proper load balancing while tracking energy consumption. While most previous energy efficiency solutions deal with homogenous resources and/or adopt static scheduling policy, our scheduling approach in this work is explicitly taking into account processing priority with heterogeneous resources."	https://doi.org/10.1109/DASC.2011.96	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Hussin, et al. [NO] addresses the problem of scheduling tasks with different priorities (deadlines) for energy efficiency exploiting resource heterogeneity. 
Virtual machine scheduling for multicores considering effects of shared on-chip last level cache interference	[]	Shin-gyu Kim, Hyeonsang Eom, and Heon Y. Yeom. 2012. Virtual machine scheduling for multicores considering effects of shared on-chip last level cache interference. International Green Computing Conference (IGCC). IEEE, 1–6. DOI:http://dx.doi.org/ 10.1109/IGCC.2012.6322250	As the cloud markets grow, the cloud providers are faced with new challenges such as reduction of power consumption and guaranteeing service level agreements (SLAs). One reason for these problems is the use of server consolidation policy based on virtualization technologies for maximizing the efficiency of resource usage. Because current virtualization technologies do not ensure performance isolation among active virtual machines (VMs), it is required to consider resource usage pattern of VMs to improve total throughput and quality of service. In this paper, we propose a virtual machine scheduler for multicore processors, which exploits the lastlevel cache (LLC) reference ratio. Specifically, we focus on the performance impact of contention in a shared LLC. We have found that the ratio of the number of LLC references to that of instructions (LLC reference ratio) is highly associated with the amount of cache demand, and a Performance-Maximizing VM (PMV) scheduling algorithm can be devised by using the ratio. We show that our PMV scheduler is effective by evaluation for various workloads. Keywords-Virtual machine consolidation; Shared resource interference; Multicore processor	In this section, we describe a cache hierachy in modern multicore processors and how to characterize cache demand of a workload by LLC reference ratio.	https://doi.org/10.1109/IGCC.2012.6322250	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Kim, et al. [NO] proposes a virtual machine scheduler for multicore processors, which exploits the lastlevel cache (llc) reference ratio. 
Energy-aware scheduling for infrastructure clouds	[]	Thomas Knauth, and Christof Fetzer. 2012. Energy-aware scheduling for infrastructure clouds. 4th International Conference on Cloud Computing Technology and Science (CloudCom’12). IEEE, 58–65. DOI:http://dx.doi.org/10.1109/CloudCom.2012.6427569	More and more data centers are built, consuming ever more kilo watts of energy. Over the years, energy has become a dominant cost factor for data center operators. Utilizing lowpower idle modes is an immediate remedy to reduce data center power consumption. We use simulation to quantify the difference in energy consumption caused exclusively by virtual machine schedulers. Besides demonstrating the inefficiency of wide-spread default schedulers, we present our own optimized scheduler. Using a range of realistic simulation scenarios, our customized scheduler OptSched reduces cumulative machine uptime by up to 60.1%. We evaluate the effect of data center composition, run time distribution, virtual machine sizes, and batch requests on cumulative machine uptime. IaaS administrators can use our results to quickly assess possible reductions in machine uptime and, hence, untapped energy saving potential.	"In this paper, we make the following contributions: • Building on our previous initial study <NO> on the use-
fulness of timed instances, we extend the evaluation to include more varied settings such at heterogeneous hosts, heterogeneous instance sizes, run time distributions, and batch requests. • We provide an extensive (re)-evaluation of the energy saving potential of timed instances. • Based on the changed simulation parameters, we adapt the original optimizing scheduler to achieve even better results in the new environment. • We share with the scientific community our simulator and workload generator. Other researchers can thus repeat and verify our results easily. The code and other artifacts can be found at http://bitbucket.org/tknauth/cloudcom2012/"	https://doi.org/10.1109/CloudCom.2012.6427569	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Knauth, et al. [NO] uses simulation to quantify the difference in energy consumption caused exclusively by virtual machine schedulers. 
Fundamentals of green communications and computing: Modeling and simulation	[]	Murat Kocaoglu, Derya Malak, and Ozgur Akan. 2012. Fundamentals of green communications and computing: Modeling and simulation. Computer 45, 9 (2012), 40–46. DOI:http://dx.doi.org/10.1109/ MC.2012.248	"A bot tom-up approach to minimizing energy dissipation starts with establishing a fundamental energy dissipation limit, which shows the true gap between current and optimum energy savings and which can serve as a springboard for developing techniques to achieve that limit. Unfortunately, for point-to-point communications, such an approach applies only in certain scenarios; using information-theory approaches to derive energy dissipation limits is largely impractical for large-scale networks, and even some small networks, because incorporating the dynamics of practical networks from an informationtheory perspective is difficult.
As an alternative way to find the minimum energy consumption in larger networks, we propose combining an architecture that uses Internet layers with a physical layer operating at the fundamental limit of energy dissipation. We can then view energy consumption as the fundamental energy consumed per information bit. For large networks, this layered approach is more feasible than an analysis based on information theory.
Our exploration of this approach highlighted some novel implementation challenges, particularly how to address the effects of constraints on the upper layers— constraints that stem from requiring minimal energy consumption at the physical layer. It also revealed new directions and open issues for green network simulation and standardization.
A s society becomes more aware of how carbon diox-ide (CO2) emissions are affecting the environment, the information and communications technology (ICT) community is investigating how to ensure that communication systems consume less energy and thus collectively have a substantially smaller carbon footprint. To that end, researchers have been working on novel techniques to reduce the energy dissipation of point-to-point communication links and computer networks.
Although modifying existing ICT systems can lead to incremental energy savings, the primary purpose of lowering energy dissipation is to reduce the CO2 emission rate. The relationship between these two ideas is more complex than many organizations realize. The ICT community has long assumed that energy savings will reduce CO2 emissions,1 but the amounts of emitted CO2 and dissipated energy are not always linearly related. In some scenarios, optimum CO2 savings in fact do not stem from the lowest possible energy consumption. Minimizing the total energy consumption of links over all possible network
A layered architecture incorporates the concept of minimum energy consumption for communication links and computer networks with multiple terminals, where emission-reduction approaches based on information theory are impractical."	"As the “Green Communication Networks” sidebar describes, ICT researchers have many ideas about how to reduce a network’s energy dissipation. Significantly reducing the carbon footprint of ICT systems is not easy, particularly if the solution is to use only energy-efficient techniques and algorithms to improve existing network components. For the past decade, ICT researchers have actively sought to satisfy the demand for high performance and high bit rates, optimizing communication links and networks to maximize data rate within power and energy constraints.
To continue meeting demand and satisfy the need for lower energy consumption, the ICT community must take a more revolutionary approach to developing green ICT solutions: optimizing ICT systems with the objective of minimizing energy consumption while using data rate and reliability as constraints could significantly reduce ICT’s adverse effects on Earth’s atmosphere. A cornerstone of this new order is the creation of fundamental energy limits that are independent of a particular technology."	https://doi.org/10.1109/MC.2012.248	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Kocaoglu, et al. [NO] proposes combines an architecture that uses internet layers with a physical layer operating at the fundamental limit of energy dissipation. 
EnaCloud: An energy-saving application live placement approach for cloud computing environments	['<NO> propose EnaCloud, which places applications dynamically on servers, with consideration of energy efficiency in a cloud platform.']	Bo Li, Jianxin Li, Jinpeng Huai, Tianyu Wo, Qin Li, and Liang Zhong. 2009. EnaCloud: An energy-saving application live placement approach for cloud computing environments. IEEE International Conference on Cloud Computing (CLOUD’09). 17–24. DOI:http://dx.doi.org/10.1109/CLOUD.2009.72	With the increasing prevalence of large scale cloud computing environments, how to place requested applications into available computing servers regarding to energy consumption has become an essential research problem, but existing application placement approaches are still not effective for live applications with dynamic characters. In this paper, we proposed a novel approach named EnaCloud, which enables application live placement dynamically with consideration of energy efficiency in a cloud platform. In EnaCloud, we use a Virtual Machine to encapsulate the application, which supports applications scheduling and live migration to minimize the number of running machines, so as to save energy. Specially, the application placement is abstracted as a bin packing problem, and an energy-aware heuristic algorithm is proposed to get an appropriate solution. In addition, an over-provision approach is presented to deal with the varying resource demands of applications. Our approach has been successfully implemented as useful components and fundamental services in the iVIC platform. Finally, we evaluate our approach by comprehensive experiments based on virtual machine monitor Xen and the results show that it is feasible.	"The infrastructure of cloud computing environment <NO><NO> is usually composed of hundreds or even thousands of server nodes. The nodes can be categorized into two types – computing nodes and storage nodes. We assume that all the data and files are stored in storage nodes, which are running network file system. Each computing node consists of processor, memory, as well as network interfaces. For simplicity, we assume all the computing nodes are
homogenous and the resource capacity of every server is 1 unit. The nodes are interconnected by high-speed LAN such as Infiniband. Each computing node runs a virtual machine monitor (VMM) and hosts one or more VMs. Each VM encapsulates an application or a component of the application. The application and the underlying operating system, which are encapsulated by a VM, are referred to as workload. We assume each workload has a predefined resource requirement when being submitted to our system. We use the term open box for a server node that is running VMs. The idle server node without running VMs is referred to as close box."	https://doi.org/10.1109/CLOUD.2009.72	1	['application', 'proposed', 'platform']	['resource_provisioning', 'provision_approach', 'application_placement', 'computing_platforms', 'consolidation_virtual']	['as_energy_efficiency', 'ability_power_subsystems', 'abstracted_bin_packing', 'abstraction_nearly_unlimited', 'acceptable_qos_penalty']	Li, et al. [NO] proposes a novel approach named enacloud, which enables application live placement dynamically with consideration of energy efficiency in a cloud platform. 
Energy-efficient resource provisioning with SLA consideration on cloud computing	[]	Jian-Sheng Liao, Chi-Chung Chang, Yao-Lun Hsu, Xiao-Wei Zhang, Kuan-Chou Lai, and ChingHsien Hsu. 2012. Energy-efficient resource provisioning with SLA consideration on cloud computing. 41st International Conference on Parallel Processing Workshops (ICPPW’12), 206–211. DOI:http://dx.doi.org/10.1109/ICPPW.2012.31	Cloud computing aims at reducing energy consumption and maximizing resource efficiency without violating service level agreement (SLA). To address these important issues, this study proposes an energy-efficient resource provisioning technology with SLA consideration for virtual machine scheduling. According to SLAs, the resource manager could consolidate virtual machines onto the physical machine for meeting customers’ SLA requests. Experimental results show that the proposed approach outperforms other proposed ones in power consumption. Keywords-component; Cloud Computing; Virtualization; Energy Saving; Resource Provisioning; Service Level Agreement	"where ""$6/ ""$'is require time of executing a job with sufficient resources. !77-0! $ is time of allocating sufficient resources to this job. 9: is the penalty of violating SLA.
Figure 4(a) shows a demonstration of applying the round-robin approach to allocate limited resources to VMs. In this demonstration, the round-robin manner distributes virtual machines to different hosts in order to balance load. However, the number of hosts could be reduced for saving energy. When the VMs are consolidated onto fewer hosts, as shown in Figure 4(b), the unused hosts could be turned off and save energy.
In order to obtain the optimal host of allocating VMs, the number of unused processors in a host is defined as
(?@9 )*?@9 # A ) @?@9 # B C?@9
and the amount of the unused memory size is defined as
(? )*? # A ) @? # B C?
and the amount of unused storage disk is defined as
(?C D )*?C D # A ) @?C D # B C?C D
Therefore, the optimal host of allocating an incoming VM is the host with the minimal value, as show in following.
EFGH/%?0I/JK""?0I/LM! !7?0I/J N O /%?,$,JK""?,$,L M! !7?,$,J P O /%?& QJK""?& QL M! !7?& QJ RS (8)
where ?@9 is the requirement of the incoming virtual machine. N is the percentage of overall energy consumption donate by CPU, P is the percentage of overall energy consumption donate by memory, and R is the percentage of overall energy consumption donate by storage disk. Based on the literature <NO>, N is 58%, P is 28% and R is 14%, as shown in Figure 5.
This study proposes a SLA-Based Resource Constraint VM Scheduling approach to allocate resources to the incoming VMs without violating SLAs, as shown in the following algorithm. When a user submits a request to allocate a VM to a suitable host, the proposed approach assigns a priority and checks running hosts for determining whether the remaining resources are enough for executing the incoming VM (steps 9-12). If the running hosts couldn’t satisfy the incoming VM request, a new host is turn-on for this VM (steps 13-16). If there is more than one of hosts with sufficient resources, the proposed approach selects the host with the minimal value obtained from equation (8) (step 17-18).
Algorithm SLA-Based Resource Constraint VM Scheduling
1. Input HostList, VmList, CurrentHostList
2. Output allocation of VMs
3. HostList {Host1, Host2, …, HostN};
4. VmList {Vm1, Vm2, …, VmN};
5. CurrentHostList null;
6. OptimalHost null; 7. for Vm from Vm1 to VmN in VmList do{ 8. if(CurrentHostList != null){ 9. for Host from Host1 to HostN in
CurrentHostList{ 10. if(Host.GetUnusedResource >
Vm.GetResource) 11. EnoughHostList += Host;"	https://doi.org/10.1109/ICPPW.2012.31	1	['application', 'proposed', 'platform']	['resource_provisioning', 'provision_approach', 'application_placement', 'computing_platforms', 'consolidation_virtual']	['as_energy_efficiency', 'ability_power_subsystems', 'abstracted_bin_packing', 'abstraction_nearly_unlimited', 'acceptable_qos_penalty']	Cloud computing aims at reducing energy consumption and maximizing resource efficiency without violating service level agreement (SLA) [NO].
Server consolidation in clouds through gossiping	[]	Moreno Marzolla, Ozalp Babaoglu, and Fabio Panzieri. 2011. Server consolidation in clouds through gossiping. International Symposium on World of Wireless, Mobile and Multimedia Networks (WoWMoM’11), IEEE, 1–6. DOI:http://dx.doi.org/10.1109/WoWMoM.2011.5986483	The success of Cloud computing, where computing power is treated as a utility, has resulted in the creation of many large datacenters that are very expensive to build and operate. In particular, the energy bill accounts for a significant fraction of the total operation costs. For this reason a significant attention is being devoted to energy conservation techniques, for example by taking advantage of the built-in power saving features of modern hardware. Cloud computing offers novel opportunities for achieving energy savings: Cloud systems rely on virtualization techniques to allocate computing resources on demand, and modern Virtual Machine (VM) monitors allow live migration of running VMs. Thus, energy conservation can be achieved through server consolidation, moving VM instances away from lightly loaded computing nodes so that they become empty and can be switched to low-power mode. In this paper we present V-MAN, a fully decentralized algorithm for consolidating VMs in large Cloud datacenters. V-MAN can operate on any arbitrary initial allocation of VMs on the Cloud, iteratively producing new allocations that quickly converge towards the one maximizing the number of idle hosts. V-MAN uses a simple gossip protocol to achieve efficiency, scalability and robustness to failures. Simulation experiments indicate that, starting from a random allocation, V-MAN produces an almost-optimal VM placement in just a few rounds; the protocol is intrinsically robust and can cope with computing nodes being added to or removed from the Cloud.	"The problem of migrating running processes from one processor to another has been initially considered for balancing workload in distributed multiprocessor systems <NO>. Recent advances in virtualization technologies allow entire running VMs to be transferred across different physical hosts <NO>. This opportunity is being investigated for different purposes, mostly related with various Quality of Service aspects.
Stage and Setzer <NO> describe a network-aware migration scheduler which takes into consideration the workload type of each VM. The migration takes into explicit consideration the network topology and the bandwidth requirements to move VM images within a given deadline. Wood et al. <NO> describe Sandpiper, a system which automatically identifies performance bottlenecks, identifies a new VM allocation which removes them and finally initiate the required migrations to instantiate the new allocation. Sandpiper is OS and application independent, relying on monitoring disk and network usage inside the Xen VM monitor.
Some recent works considered distributed (hierarchical) approaches for energy management in large datacenters. Bennani and Menasce <NO> present a hierarchical approach addressing the problem of dynamically redeploying servers in a continuously varying workload scenario. In this case, servers are grouped according to an application environmental logic, and a so-called local controller that is in charge of managing a set of servers. Das et al. <NO> present a multiagent system approach to the problem of green performance
in data center. As for aforementioned papers, the framework is based on a hierarchy, according to which a resource arbiter assigns resources to the application managers, which in turn become in charge of managing physical servers. Srikantaiah et al. <NO> study the impact of consolidation of multiple workloads with different resource usage on performance, energy usage, and resource utilization. This is not achieved by migrating applications, but rather by consolidating the workload so that each server receives a “balanced mix” of requests. Finally, Barbagallo et al. <NO> describe a bioinspired algorithm based on the scout-worker migration method, in which some entities (the scouts) are allowed to move from one physical node to another in order to cooperatively identify a suitable destination for VMs (the workers) which are migrated.
V-MAN uses a fully decentralized approach with no shared data structures or central controllers. Also, V-MAN does not require any instrumentation of either VMs or hosted applications, V-MAN does not rely on a small subset of special entities (e.g., the scouts of <NO>): instead, all servers cooperate to identify a new VM allocation, and this ensures that V-MAN is capable of scaling with the size of the datacenter."	https://doi.org/10.1109/WoWMoM.2011.5986483	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Marzolla, et al. [NO] present v-man, a fully decentralized algorithm for consolidating vms in large cloud datacenters. 
A tale of clouds: Paradigm comparisons and some thoughts on research issues	[]	Lijun Mei, Wing Kwong Chan, and T.H. Tse. 2008. A tale of clouds: Paradigm comparisons and some thoughts on research issues. Asia-Pacific Services Computing Conference (APSCC’08). IEEE, 464– 469. DOI:http://dx.doi.org/10.1109/APSCC.2008.168	Cloud computing is an emerging computing paradigm. It aims to share data, calculations, and services transparently among users of a massive grid. Although the industry has started selling cloud-computing products, research challenges in various areas, such as UI design, task decomposition, task distribution, and task coordination, are still unclear. Therefore, we study the methods to reason and model cloud computing as a step toward identifying fundamental research questions in this paradigm. In this paper, we compare cloud computing with service computing and pervasive computing. Both the industry and research community have actively examined these three computing paradigms. We draw a qualitative comparison among them based on the classic model of computer architecture. We finally evaluate the comparison results and draw up a series of research questions in cloud computing for future exploration.	"This section reviews the preliminaries of cloud computing, service computing, and pervasive computing.
2.1. Cloud computing As we have introduced in Section 1, a computing cloud is a massive network of nodes. Thus, scalability should be a quality feature of the computing cloud. It has at least two dimensions, namely horizontal cloud scalability and vertical cloud scalability (adapted from <NO>).
Horizontal cloud scalability is the ability to connect and integrate multiple clouds to work as one logical cloud. For instance, a cloud providing calculation services (calculation cloud) can access a cloud providing storage services (storage cloud) to keep intermediate results. Two calculation clouds can also integrate into a larger calculation cloud.
Vertical cloud scalability is the ability to improve the capacity of a cloud by enhancing individual existing nodes in the cloud (such as providing a server with more physical memory) or improving the bandwidth that connects two nodes. In addition, to meet increasing market demand, a node can be gradually upgraded from a single power machine to a data center. Scalability should be transparent to users. For instance, users may store their data in the cloud without the need to know where it keeps the data or how it accesses the data.
For simplicity, we will refer to horizontal and vertical cloud scalability, respectively, as horizontal scalability and vertical scalability in this paper.
2.2. Service computing Service computing (or service-oriented computing) is an emerging paradigm to model, create, operate, and manage business services. In this paradigm, services publish themselves in public registries, discover peer services, and bind to the latter services to form service compositions using standardized protocols <NO>. To create a service composition, engineers may use a specification, such as WS-BPEL <NO>, to model the collaborative need in workflows. To carry out individual workflow steps, software developers may use Web services, the most
popular way to fulfill service-oriented architecture in the industry. A set of service-oriented applications over the Web services thus creates a network of services.
We briefly describe a service-oriented network <NO> to facilitate the comparison in the rest of the paper. An element in such a network is a service registry, service consumer, or service provider. A service provider registers itself in a service registry. A service consumer first discovers the service from a registry, and then binds to the service. A service provider may register itself to more than one registry. A registry may also associate its registered services to other registries, and acts as a service itself. Such a treatment on a registry provides a generic view among elements in service-oriented modeling.
2.3. Pervasive computing Pervasive computing (or ubiquitous computing) <NO><NO> is another emerging computing paradigm. Software (often referred as pervasive software) can be embedded in a constantly changing computing environment. Therefore, pervasive software users do not need to be concerned about how to adjust the software to adapt to the surrounding computing environment. A well-developed environment will enable users to use pervasive software everywhere without extra effort.
To understand and react to a user, applications use environmental features, known as contexts, extensively. Sensors can capture these contexts. To allow ubiquitous support to end users, smart sensors are placed around users to preserve different information, such as the locations, contexts, and user-relevant data.
Figure 2 shows a pervasive computing example. Sensors, mobile phones and PDAs, desktop computer, and servers are interconnected logically to form an application.
Suppose a nomadic user at the top left corner of Figure 2 moves from using a laptop to using a desktop computer. The laptop and the desktop computer both serve as UI portals to the tuple space maintained by the pervasive software. The remarked information from various display portals (such as the PDAs on the right-hand part) may need adapting. For example, a desktop computer may be equipped with a high-definition webcam. Thus, a presentation display portal may display the contents with a camera image kept in the tuple space of the application when using a laptop."	https://doi.org/10.1109/APSCC.2008.168	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Mei, et al. [NO] studies the methods to reason and model cloud computing as a step toward identifying fundamental research questions in this paradigm. 
The current state of understanding of the energy efficiency of cloud computing	[]	Francis Owusu, and Colin Pattinson. 2012. The current state of understanding of the energy efficiency of cloud computing. IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom’12). 1948–1953. DOI:http://dx.doi.org/10.1109/TrustCom.2012.270	Cloud computing has been hailed as the achievement of the longheld dream of computing as a utility and has the potential to transform a large part of the Information and Communication Technology (ICT) industry. Cloud computing is both a business and an economic model which has been gaining popularity since 2006 and it is currently the most talked about technology in the ICT industry. Because it views hardware and software as commodities, the cloud is an example of a disruptive technology. It offers enterprises the opportunity to reduce hardware and software cost and the potential reduction of maintenance and support staff. Data centers and cloud computing services providers hope that the widespread adoption of the cloud will bring them more profit and they are actively promoting the technology. The cloud has had its share of controversy; ranging from the definition of cloud computing to its energy efficiency. This paper discusses one area of controversy; the energy efficiency of cloud computing. We outline previous contributions to the discussion of energy efficiency of cloud computing, provide a working definition of cloud computing and discuss its importance, which will grow as the technology matures and becomes well known.	"Arif wrote that cloud computing has evolved through a number of phases including grid and utility computing, and application service provision (ASP) <NO>. Arif wrote Salesforce.com pioneered the concept of delivering enterprise applications via a website in 1999 followed by Amazon Web Services for storage and computation in 2002. Cloud computing started gaining general popularity in 2006 when Amazon launched its Elastic Compute Cloud (EC2) as a commercial web service, allowing small businesses and individuals to rent computing resources. After the introduction of Web 2.0, Google and others started to offer browser-based enterprise applications such as Google Apps in 2009. Other technologies enabling the evolution of cloud computing include virtualization and broadband. The many definitions of cloud computing has generated some controversy because the technology is new and not well understood resulting in confusion among IT professionals and vendors. This confusion was captured in “Twenty one experts define cloud computing” when these experts gave twenty one different definitions for cloud computing <NO>.
978-0-7695-4745-9/12 $26.00 © 2012 IEEE DOI 10.1109/TrustCom.2012.270
1948
Gartner lamented that the contrasting views on cloud computing are causing confusion then added their own definition by defining cloud computing as ""a style of computing where scalable and elastic IT-enabled capabilities are provided 'as a service' to external customers using Internet technologies” <NO>. IDC defines it as ""an emerging IT development, deployment and delivery model, enabling realtime delivery of products, services and solutions over the Internet"" <NO>. Accenture defines cloud computing as “the dynamic provisioning of IT capabilities, whether hardware, software, or services from a third party over the network” <NO>. Kenneth K. Chellappa gave the first academic definition of cloud computing as “a computing paradigm where the boundaries of computing will be determined by economic rationale rather than technical limits” <NO>. Ambrust et al writes that “Cloud computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the data centers that provide those services” <NO>. Although there are many different definitions for cloud computing, there is a broad consensus on the definition by the National Institute of Standards and Technology (NIST). They define cloud computing as: “A model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model promotes availability and is composed of five essential characteristics, three service models, and four deployment models”. This paper accepts the NIST definition but with the understanding that “network” comprises the telecommunication networks and the Internet. The hope of many is that a standard definition will be found and adopted as the technology matures.
III. COMPONENTS OF CLOUD COMPUTING AND THEIR ENERGY EFFICIENCY
Cloud computing can be considered as a system with three main components."	https://doi.org/10.1145/1735971.1736048	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Owusu, et al. [NO] discusses one area of controversy ; the energy efficiency of cloud computing. 
Variation-aware server placement and task assignment for data center power minimization	[]	Ali Pahlavan, Mahmoud Momtazpour, and Maziar Goudarzi. 2012. Variation-aware server placement and task assignment for data center power minimization. 2012 IEEE 10th International Symposium	Size and number of data centers are fast growing all over the world and their increasing total power consumption is a worldwide concern. Moreover, increase in the amount of process variation in nanometer technologies and its effect on total power consumption of servers has made it inevitable to move toward variation-aware power reduction strategies. This paper formulates a variation-aware joint server placement and task assignment method using Integer Linear Programming (ILP) to minimize total power consumption of data centers. We first determine the optimum placement of servers in the data center racks based on total power consumption of each server and the data center recirculation model obtained by Computational Fluid Dynamics (CFD) simulations. Then, we dynamically consolidate the ON servers in chassis and racks such that the use of powergreedy servers is minimized. Experimental results reveal up to 14.85% and an average of 8.92% power saving at different server utilization rates with respect to conventional methods. Keywords-Data center, Power reduction, Process variation, Server placement, Task assignment.	"The authors in <NO> proposed a method to minimize the total energy consumption of data center while considering thermal management for their reliable function. They have used CFDbased simulations in order to evaluate their task scheduling methods such as Minimal Computing Energy (MCE) which is the best one among others. The aforementioned algorithm tries to minimize the total number of running servers and turn off all other idle ones. The algorithm first assigns the tasks to the nodes having the lowest inlet temperature. In another CFDbased work <NO> an analysis of a data center with temperature variation has been presented. The authors have obtained static provisioning for an arbitrary distribution of cooling resources that will lead to a reference state. They try to minimize the inlet temperature by dividing the workload on other available systems.
CFD-based techniques are often time consuming and complex. This issue will not lead to tackling online scheduling problem efficiently <NO>. Therefore, fast thermal evaluation models are developed such as <NO>, <NO>. In <NO>, the goal is to reduce the peak inlet temperature in order to obtain the lowest power consumption of cooling system using heat recirculation model. As a result, 20% to 30% cooling power saving will occur in different data center utilization rates. In <NO> fast prediction of temperature distribution is done using distributed sensors to reduce energy consumption in high performance data centers considering recirculation properties. So, this method is suitable for real time and online management. The authors in <NO> demonstrated a thermal aware resource management method considering heat transfer properties and workloads having thermal features. Their scheduling algorithm will result in reduced power consumption without performance degradation.
Reference <NO> presented the chassis consolidation technique as a mathematical optimization problem and a heuristic algorithm. Optimization problem has been solved via ILP. Their experiments show that they gain 13% power saving for different utilization rates in comparison with the technique lacking consolidation.
None of the above works considers process variation effects on total power consumption of high performance servers. As will be explained below, variability effects in nanometer-scale technologies has caused dramatic variations in leakage and total power consumption of processor cores especially in high performance processors <NO>. Such variation effects are visible in today processors and are expected to further rise with technology scaling when further approaching atomic scales. Process variation effects are already studied in highperformance multiprocessor and embedded systems <NO>, <NO>, <NO>, but to the best of our knowledge such effects have not been previously considered at data center scales."	https://doi.org/10.1109/ISPA.2012.29	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Pahlavan, et al. [NO] formulates a variation-aware joint server placement and task assignment method using integer linear programming (ilp) to minimize total power consumption of data centers. 
A quantitative analysis of cooling power in container-based data centers	[]	Amer Qouneh, Chao Li, and Tao Li. 2011. A quantitative analysis of cooling power in container-based data centers. IEEE International Symposium on Workload Characterization (IISWC). 61–71. DOI:http://doi.ieeecomputersociety.org/10.1109/IISWC.2011.6114197	Cooling power is often represented as a single taxed cost on the total energy consumption of the data center. Some estimates go as far as 50% of the total energy demand. However, this view is rather simplistic in the presence of a multitude of cooling options and optimizations. In response to the rising cost of energy, the industry introduced modular design in the form of containers to serve as the new building block for data centers. However, it is still unclear how efficient they are compared to raised-floor data centers and under what conditions they are preferred. In this paper, we provide comparative and quantitative analysis of cooling power in both container-based and raised-floor data centers. Our results show that a container achieves 80% and 42% savings in cooling and facility powers respectively compared to a raised-floor data center and that savings of 41% in cooling power are possible when workloads are consolidated onto the least number of containers. We also show that cooling optimizations are not very effective at high utilizations; and that a raised-floor data center can approach the efficiency of a container at low utilizations when employing a simple cooling optimization.	The efficiency of the cooling architecture greatly affects the recurring costs of data centers. In this section we describe the operation and characteristics of both raised-floor and container-based data centers. We also provide background on calculating the cooling power.	https://doi.org/10.1109/IISWC.2011.6114197	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Qouneh, et al. [NO] provides comparative and quantitative analysis of cooling power in both container-based and raised-floor data centers. 
Energy-efficient application-aware online provisioning for virtualized clouds and data centers	[]	Ivan Rodero, Juan Jaramillo, Andres Quiroz, Manish Parashar, Francesc Guim, and Stephen Poole. 2010. Energy-efficient application-aware online provisioning for virtualized clouds and data centers. International Green Computing Conference. 31–45. DOI:http://dx.doi.org/10.1109/GREENCOMP.2010.5598283	As energy efficiency and associated costs become key concerns, consolidated and virtualized data centers and clouds are attractive computing platforms for dataand computeintensive applications. These platforms provide an abstraction of nearly-unlimited computing resources through the elastic use of pools of consolidated resources, and provide opportunities for higher utilization and energy savings. Recently, these platforms are also being considered for more traditional high-performance computing (HPC) applications that have typically targeted Grids and similar conventional HPC platforms. However, maximizing energy efficiency, costeffectiveness, and utilization for these applications while ensuring performance and other Quality of Service (QoS) guarantees, requires leveraging important and extremely challenging tradeoffs. These include, for example, the tradeoff between the need to efficiently create and provision Virtual Machines (VMs) on data center resources and the need to accommodate the heterogeneous resource demands and runtimes of these applications. In this paper we present an energy-aware online provisioning approach for HPC applications on consolidated and virtualized computing platforms. Energy efficiency is achieved using a workload-aware, just-right dynamic provisioning mechanism and the ability to power down subsystems of a host system that are not required by the VMs mapped to it. We evaluate the presented approach using real HPC workload traces from widely distributed production systems. The results presented demonstrated that compared to typical reactive or predefined provisioning, our approach achieves significant improvements in energy efficiency with an acceptable QoS penalty. Keywords-Autonomic Computing; Cloud Computing; Energy Efficiency; Virtualization; Data Center; Resource Provisioning	"In our previous work <NO>, we investigated decentralized online clustering. We also presented autonomic mechanisms for VM provisioning to improve resource utilization <NO>. This approach focused on reducing the over-provisioning that occurs because of the difference between the virtual resources allocated to VM instances and those contained in individual job requests. In particular, we used DOC to efficiently characterize dynamic, rather than generic (such as Amazon’s EC2 VM types <NO>), classes of resource requirements that can be used for proactive VM provisioning. To address the inaccuracies in client resource requests that lead to over-provisioning, we explored the use of workload modeling techniques and their application to the highly varied workloads of cloud environments.
In the VM provisioning mechanism that we proposed, as with most predictive approaches, the flow of arriving jobs was divided into time periods that we call analysis windows. During each window, an instance of the clustering algorithm was run with the jobs that arrived during that window, producing a number of clusters or VM classes. At the same time, each job was assigned to an available VM as it arrived if one was provisioned with sufficient resources to meet its requirements. The provisioning was done based on the most recent analysis results from the previous analysis window. For the first window, the best option was to reactively create VMs for incoming jobs. However, the job descriptions were sent to the processing node network and by the end of the analysis window each node could quickly determine if a cluster existed in its particular region. If so, the node could locally trigger the creation of new VMs for the jobs in the next analysis window with similar resource requirements. According to <NO>, the time required to create batches of VM in a cloud infrastructure does not differ significantly
from the time for creating a single VM instance. Thus, the VMs for each class could be provisioned within the given time window. In order to match jobs to provisioned VMs, the cluster description could be distributed in the node network using the range given by the space occupied by the cluster in the information space. Thus, when a new job arrived, it would be routed to a node that holds descriptors for VMs that had close resource requirements."	https://doi.org/10.1109/GREENCOMP.2010.5598283	1	['application', 'proposed', 'platform']	['resource_provisioning', 'provision_approach', 'application_placement', 'computing_platforms', 'consolidation_virtual']	['as_energy_efficiency', 'ability_power_subsystems', 'abstracted_bin_packing', 'abstraction_nearly_unlimited', 'acceptable_qos_penalty']	Rodero, et al. [NO] presents an energy-aware online provisioning approach for hpc applications on consolidated and virtualized computing platforms. 
Virtualization: A survey on concepts, taxonomy and associated security issues	[]	Jyotiprakash Sahoo, Subasish Mohapatra, and Radha Lath. 2010. Virtualization: A survey on concepts, taxonomy and associated security issues. 2nd International Conference on Computer and Network Technology (ICCNT’10). IEEE. 222–226. DOI:http://dx.doi.org/10.1109/ICCNT.2010.49	Virtualization is a term that refers to the abstraction of computer resources. The purpose of virtual computing environment is to improve resource utilization by providing a unified integrated operating platform for users and applications based on aggregation of heterogeneous and autonomous resources. More recently, virtualization at all levels (system, storage, and network) became important again as a way to improve system security, reliability and availability, reduce costs, and provide greater flexibility. This paper explains the basics of system virtualization and addresses pros and cons of virtualization along with taxonomy and challenges. Keywords— Virtualization; hypervisor; VMM; Security; Threats.	"Virtualization was first developed in 1960’s by IBM Corporation, originally to partition large mainframe computer into several logical instances and to run on single physical mainframe hardware as the host. This feature was invented because maintaining the larger mainframe computers became cumbersome. The scientist realized that this capability of partitioning allows multiple processes and applications to run at the same time, thus increasing the efficiency of the environment and decreasing the maintenance overhead. Although the main focus of this paper is to provide an overview of security vulnerabilities in a virtual environment. It
is worth mentioning some of the security benefits that comes together with virtualization. Two primary benefits offered by any virtualization technology are
• Resource sharing - Unlike in non-virtualized environment where all the resources are dedicated to the running programs, in virtualized environment the VMs shares the physical resources such as memory, disk and network devices of the underlying host.
• Isolation - One of the key issues in virtualization provides isolation between virtual machines that are running on the same physical hardware. Programs running in one virtual machine cannot see programs running in another virtual machine."	https://doi.org/10.1109/ICCNT.2010.49	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	Sahoo, et al. [NO] explains the basics of system virtualization and addresses pros and cons of virtualization along with taxonomy and challenges. 
Low-power Amdahl-balanced blades for data intensive computing	[]	Alexander S. Szalay, Gordon C. Bell, Howie Huang, Andreas Terzis, and Alainna White. 2010. Low-power Amdahl-balanced blades for data intensive computing. ACM SIGOPS Operating Systems Review 44, 1 (2010), 71–75. DOI:http://dx.doi.org/10.1145/1740390.1740407	Enterprise and scientific data sets double every year, forcing similar growths in storage size and power consumption. As a consequence, current system architectures used to build data warehouses are about to hit a power consumption wall. In this paper we propose an alternative architecture comprising large number of so-called Amdahl blades that combine energy-efficient CPUs with solid state disks to increase sequential read I/O throughput by an order of magnitude while keeping power consumption constant. We also show that while keeping the total cost of ownership constant, Amdahl blades offer five times the throughput of a state-of-theart computing cluster for data-intensive applications. Finally, using the scaling laws originally postulated by Amdahl, we show that systems for data-intensive computing must maintain a balance between low power consumption and per-server throughput to optimize performance per Watt.	"Data-Intensive Computing. Scientific data sets are approaching petabytes today; enterprise data warehouses routinely store and process even more data. Most analyses performed over these datasets (e.g., data mining, regressions, aggregates and statistics) need to look at a large fraction of the stored data. Thereby, sequential read throughput is becoming the most relevant metric to measure the performance of data-intensive systems. Given that the relevant data sets do not fit in main memory, they have to be stored and retrieved from disks. For this reason, understanding the scaling behavior of hard disks is critical for predicting the
performance of existing data-intensive systems as data sets continue to grow.
Over the last decade the rotation speed of large disks used in disk arrays has only changed by a factor of three, from 5,400 RPM to 15,000 RPM, while disk sizes have increased by a factor of 1,000. Likewise, seek times have improved only modestly over the same time period because they are limited by mechanical strains on the disk’s heads. As a result, random access times have only improved slightly. Moreover, the sequential I/O rate continues to grow with the square root of disk capacity since it depends on the disk platter density <NO>.
As a concrete example of the trends described above, the sequential I/O throughput of commodity SATA drives is 60- 80 MB/sec today, compared to 20 MB/sec ten years ago. However, considering the vast increase in disk capacity this modest increase in throughput has effectively turned the hard disk to a serial device: reading a terabyte disk at this rate requires 4.5 hours. Therefore, the only way to increase aggregate I/O throughput is to read in parallel from more smaller disks. In fact, modern data warehouse systems, such as the GrayWulf cluster described next, aggressively use this approach to improve application performance.
GrayWulf. The GrayWulf system <NO> represents a state-ofthe-art architecture for data-intensive applications, having won the Storage Challenge at SuperComputing 2008. Focusing primarily on sequential I/O performance, each GrayWulf server consists of 30 locally attached 750 GB SATA drives, connected to two Dell PERC/6 controllers in a Dell 2950 server with 24 GB of memory and two four-core Intel Xeon processors clocked at 2.66 GHz. The raw read performance of this system is 1.5 GB/s, translating to 15,000 seconds (4.2 hours) to read all the disks. Such a building block costs approximately $12,000 and offers a total storage capacity of 22.5TB. Its power consumption is 1,150 W.
The GrayWulf cluster consists of 50 such servers and this parallelism linearly increases the aggregate bandwidth to 75 GB/sec, the total amount of storage to more than 1.1 PB and the power consumption to 56 kW. However, the time to read all the disks remains 4.2 hours, independent of the number of servers.
Doubling the storage capacity of the GrayWulf cluster, while maintaining its per-node current throughput, would require using twice as many servers, thereby doubling its power consumption. Alternatively, one could divide the same amount of data over twice as many servers to double the system’s throughput at the cost of doubling its power consumption.
At this rate, the cost of building and operating these ever expanding facilities is becoming a major roadblock not only for universities but even for large corporations <NO>. Thus tackling the next generation of data-intensive computations in a power-efficient fashion requires a radical departure from existing approaches."	https://doi.org/10.1145/1740390.1740407	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	S. et al. [NO] proposes an alternative architecture comprising large number of so-called amdahl blades that combine energy-efficient cpus with solid state disks to increase sequential read i/o throughput by an order of magnitude while keeping power consumption constant. 
System-level virtualization for high performance computing	[]	Geoffroy Valle, Thomas Naughton, Christian Engelmann, Hong Ong, and Stephen L. Scott. 2008. System-level virtualization for high performance computing. 16th IEEE Euromicro Conference on Parallel, Distributed and Network-Based Processing (PDP’08). 636–643. DOI:http://dx.doi.org/	System-level virtualization has been a research topic since the 70’s but regained popularity during the past few years because of the availability of efficient solution such as Xen and the implementation of hardware support in commodity processors (e.g. Intel-VT, AMD-V). However, a majority of system-level virtualization projects is guided by the server consolidation market. As a result, current virtualization solutions appear to not be suitable for high performance computing (HPC) which is typically based on large-scale systems. On another hand there is significant interest in exploiting virtual machines (VMs) within HPC for a number of other reasons. By virtualizing the machine, one is able to run a variety of operating systems and environments as needed by the applications. Virtualization allows users to isolate workloads, improving security and reliability. It is also possible to support nonnative environments and/or legacy operating environments through virtualization. In addition, it is possible to balance work loads, use migration techniques to relocate applications from failing machines, and isolate fault systems for repair. This document presents the challenges for the implementation of a system-level virtualization solution for HPC. It also presents a brief survey of the different approaches and ∗ORNL’s research sponsored by the Laboratory Directed Research and Development Program of Oak Ridge National Laboratory (ORNL), managed by UT-Battelle, LLC for the U. S. Department of Energy under Contract No. DE-AC05-00OR22725. techniques to address these challenges.	In this section we present the challenges for the implementation of a system-level virtualization solution: a hypervisor for HPC, virtual system environments, high availability and fault tolerance, system management and administration, resource management, and I/O & storage. We also present a brief survey for each of these challenges.	https://doi.org/10.1109/PDP.2008.85	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	This document presents the challenges for the implementation of a system-level virtualization solution for HPC [NO].
Dynamic heterogeneity and the need for multicore virtualization	[]	Philip M. Wells, Koushik Chakraborty, and Gurindar S. Sohi. 2009. Dynamic heterogeneity and the need for multicore virtualization. ACM SIGOPS Operating Systems Review 43, 2 (2009), 5–14. DOI:http://dx.doi.org/10.1145/1531793.1531797	As the computing industry enters the multicore era, exponential growth in the number of transistors on a chip continues to present challenges and opportunities for computer architects and system designers. We examine one emerging issue in particular: that of dynamic heterogeneity, which can arise, even among physically homogeneous cores, from changing reliability, power, or thermal conditions, different cache and TLB contents, or changing resource configurations. This heterogeneity results in a constantly varying pool of hardware resources, which greatly complicates software’s traditional task of assigning computation to cores. In part to address dynamic heterogeneity, we argue that hardware should take a more active role in the management of its computation resources. We propose hardware techniques to virtualize the cores of a multicore processor, allowing hardware to flexibly reassign the virtual processors that are exposed, even to a single operating system, to any subset of the physical cores. We show that multicore virtualization operates with minimal overhead, and that it enables several novel resource management applications for improving both performance and reliability.	Several proposals have exalted the benefits of designing processors with statically heterogeneous cores — cores that are designed to have different physical characteristics in order to capitalize on different engineering trade-offs (e.g., <NO>). Future multicore chips will similarly contain dynamically heterogeneous cores as well — cores which exhibit different, and rapidly changing, execution characteristics, even though they may be physically homogeneous in design.	https://doi.org/10.1145/1531793.1531797	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	M. et al. [NO] examines one emerges issue in particular : that of dynamic heterogeneity, which can arise, even among physically homogeneous cores, from changing reliability, power, or thermal conditions, different cache and tlb contents, or changing resource configurations. 
Survivable virtual infrastructure mapping in virtualized data centers	[]	Jielong Xu, Jian Tang, Kevin Kwiat, Weiyi Zhang, and Guoliang Xue. 2012. Survivable virtual infrastructure mapping in virtualized data centers. IEEE 5th International Conference on Cloud Computing. 196– 203. DOI:http://doi.ieeecomputersociety.org/10.1109/CLOUD.2012.100	In a virtualized data center, survivability can be enhanced by creating redundant Virtual Machines (VMs) as backup for VMs such that after VM or server failures, affected services can be quickly switched over to backup VMs. To enable flexible and efficient resource management, we propose to use a service-aware approach in which multiple correlated VMs and their backups are grouped together to form a Survivable Virtual Infrastructure (SVI) for a service or a tenant. A fundamental problem in such a system is to determine how to map each SVI to a physical data center network such that operational costs are minimized subject to the constraints that each VM’s resource requirements are met and bandwidth demands between VMs can be guaranteed before and after failures. This problem can be naturally divided into two sub-problems: VM Placement (VMP) and Virtual Link Mapping (VLM). We present a general optimization framework for this mapping problem. Then we present an efficient algorithm for the VMP subproblem as well as a polynomial-time algorithm that optimally solves the VLM subproblem, which can be used as subroutines in the framework. We also present an effective heuristic algorithm that jointly solves the two subproblems. It has been shown by extensive simulation results based on the real VM data traces collected from the green data center at Syracuse University that compared with the First Fit Descending (FFD) and single shortest path based baseline algorithm, both our VMP+VLM algorithm and joint algorithm significantly reduce the reserved bandwidth, and yield comparable results in terms of the number of active servers.	"VM management has attracted research attention from both industry and academia due to its potential for reducing operation costs of data centers. A few commercial software tools
(such as VMware Capacity Planner <NO>) have been developed to determine VMP according to resources at hosting servers such as CPU, memory, etc. The problems of determining how to place VMs with the objective of minimizing server power consumption have been studied in <NO>, <NO>, <NO>. In <NO>, Li et al. proposed a power efficient approach named EnaCloud, which uses application scheduling and VM live migration to minimize the number of running servers. In <NO>, mathematical programming formulations were presented for various VMP problems and heuristic algorithms were presented to solve them. Extensive simulations were conducted based on a large set of real server load data from a data center. Unlike <NO>, the VMP problem with bandwidth demand constraints was formulated into a stochastic (instead of deterministic) bin packing problem and an online approximation algorithm was presented in <NO>.
In <NO>, Verma et al. presented the design, implementation and evaluation of a power-aware application placement controller, pMapper, in virtual server clusters. They presented multiple ways to formulate the cost-aware VMP problem and present simple and practical algorithms to solve them. In <NO>, Meng et al. , for the first time, considered VMP with the objective of minimizing the communication cost. The problem was showed to be NP-hard. The authors designed a two-tier heuristic algorithm to solve it. In <NO>, the authors introduced a computationally efficient scheme, AppAware, to incorporate inter-VM dependencies and the underlying network topology into VM migration decisions. Using simulations, they showed that it decreases network traffic by up to 81% compared to a well-known method that is not application-aware.
The mapping problem studied in this paper shares some similarities with the NV problems, which have been studied in recent works <NO>, <NO>, <NO>, <NO>. In <NO>, the authors developed heuristic algorithms for two versions of the problem: Virtual Network (VN) assignment without reconfiguration and VN assignment with reconfiguration. In <NO>, Yu et al. presented heuristic algorithms to solve an NV problem which allows the substrate (physical) network to split a virtual link over multiple substrate paths and employ path migration to periodically re-optimize the utilization of the physical network. In <NO>, a fast VN mapping algorithm based on subgraph isomorphism detection was presented, which maps nodes and links during the same stage. The authors of <NO>, for the first time, presented heuristic algorithms to solve a survivable NV problem, in which a certain percentage of bandwidth of each link is reserved to support survivability.
The closest work is a very recent paper <NO>, in which an NV architecture called SecondNet was designed and evaluated for virtualized data centers. SecondNet introduces a centralized resource allocation algorithm for bandwidth guaranteed virtual to physical mapping. Moreover, the proposed approach was implemented using source routing and the Multi-Protocol Label Switching (MPLS) <NO>.
The differences between our work and these related works are summarized as follows: 1) The commercial software tools <NO> and most of the recent works on VM management <NO>, <NO>, <NO> did not consider bandwidth demands between VMs. 2) as mentioned above, our mapping problem
is different from the NV problems <NO>, <NO>, <NO>, <NO> since multiple VMs in an SVI are allowed to be placed on a common server. 3) Survivability has not been addressed in NV works <NO>, <NO>, <NO> or other closely related works <NO>, <NO>, <NO>, <NO>. 4) Unlike heuristic algorithms presented in <NO> which cannot provide any performance guarantees, our algorithms can ensure sufficient link bandwidth for failover traffic after any single server failure."	https://doi.org/10.1109/CLOUD.2012.100	0	['algorithm', 'consolidation', 'optimization']	['relocation_costs', 'v_man', 'consolidation_algorithm', 'energy_conservation', 'first_fit']	['total_power_consumption', 'ant_colony_optimization', 'definition_cloud_computing', 'multidimensional_bin_packing', 'placement_task_assignment']	Xu, et al. [NO] proposes to uses a service-aware approach in which multiple correlated vms and their backups are grouped together to form a survivable virtual infrastructure (svi) for a service or a tenant. 
Analysis of virtualization technologies for high performance computing environments	[]	Andrew J. Younge, Robert Henschel, James T. Brown, Gregor von Laszewski, Judy Qiu, and Geoffrey C. Fox. 2011. Analysis of virtualization technologies for high performance computing environments. IEEE International Conference on Cloud Computing (CLOUD). 9–16. DOI:http://dx.doi.org/10.1109/ CLOUD.2011.29	As Cloud computing emerges as a dominant paradigm in distributed systems, it is important to fully understand the underlying technologies that make Clouds possible. One technology, and perhaps the most important, is virtualization. Recently virtualization, through the use of hypervisors, has become widely used and well understood by many. However, there are a large spread of different hypervisors, each with their own advantages and disadvantages. This paper provides an in-depth analysis of some of today’s commonly accepted virtualization technologies from feature comparison to performance analysis, focusing on the applicability to High Performance Computing environments using FutureGrid resources. The results indicate virtualization sometimes introduces slight performance impacts depending on the hypervisor type, however the benefits of such technologies are profound and not all virtualization technologies are equal. From our experience, the KVM hypervisor is the optimal choice for supporting HPC applications within a Cloud infrastructure.	"While the use of virtualization technologies has increased dramatically in the past few years, virtualization is not specific
978-0-7695-4460-1/11 $26.00 © 2011 IEEE DOI 10.1109/CLOUD.2011.29
9
to the recent advent of Cloud computing. IBM originally pioneered the concept of virtualization in the 1960’s with the M44/44X systems <NO>. It has only recently been reintroduced for general use on x86 platforms. Today there are a number of public Clouds that offer IaaS through the use of virtualization technologies. The Amazon Elastic Compute Cloud (EC2) <NO> is probably the most popular Cloud and is used extensively in the IT industry to this day. Nimbus <NO>, <NO> and Eucalyptus <NO> are popular private IaaS platforms in both the scientific and industrial communities. Nimbus, originating from the concept of deploying virtual workspaces on top of existing Grid infrastructure using Globus, has pioneered scientific Clouds since its inception. Eucalyptus has historically focused on providing an exact EC2 environment as a private cloud to enable users to build an EC2-like cloud using their own internal resources. Other scientific Cloud specific projects exist such as OpenNebula <NO>, In-VIGO <NO>, and Cluster-on-Demand <NO>, all of which leverage one or more hypervisors to provide computing infrastructure on demand. In recent history, OpenStack <NO> has also come to light from a joint collaboration between NASA and Rackspace which also provide compute and storage resources in the form of a Cloud.
While there are currently a number of virtualization technologies available today, the virtualization technique of choice for most open platforms over the past 5 years has typically been the Xen hypervisor <NO>. However more recently VMWare ESX <NO> 1, Oracle VirtualBox <NO> and the Kernelbased Virtual Machine (KVM) <NO> are becoming more commonplace. As these look to be the most popular and featurerich of al virtualization technologies, we look to evaluate
1Due to the restrictions in VMWare’s licensing agreement, benchmark results are unavailable.
all four to the fullest extent possible. There are however, numerious other virtualizaton technologies also available, including Microsoft’s Hyper-V <NO>, Parallels Virtuozzo <NO>, QEMU <NO>, OpenVZ <NO>, Oracle VM <NO>, and many others. However, these virtualization technologies have yet to seen widespread deployment within the HPC community, at least in their current form, so they have been placed outside the scope of this work.
In recent history there have actually been a number of comparisons related to virtualization technologies and Clouds. The first performance analysis of various hypervisors started with, unsurprisingly, the hypervisor vendors themselves.
VMWare published their performance analysis in <NO> as did the Xen developers in an their first paper <NO>. The Xen paper compares Xen, XenoLinux, and VMWare across a number of SPEC and normalized benchmarks, resulting in a conflict between the two works. From here, a number of more unbiased reports originated, concentrating on server consolidation and web application performance <NO>, <NO>, <NO> with fruitful yet sometimes incompatible results. A feature base survey on virtualization technologies <NO> also illustrates the wide variety of hypervisors that currently exist. Furthermore, there has been some investigation into the performance within HPC, specifically with InfiniBand performance of Xen <NO> and rather recently with a detailed look at the feasibility of the Amazon Elastic Compute cloud for HPC applications <NO>, however both works concentrate only on a single deployment rather than a true comparison of technologies.
As these underlying hypervisor and virtualization implementations have evolved rapidly in recent years along with virtualization support directly on standard x86 hardware, it is necessary to carefully and accurately evaluate the performance implications of each system. Hence, we conducted an investigation of several virtualization technologies, namely Xen, KVM, VirtualBox, and in part VMWare. Each hypervisor is compared alongside one another with bare-metal as a control and (with the exeption of VMWare) run through a number of High Performance benchmarking tools."	https://doi.org/10.1109/CLOUD.2011.29	2	['processor', 'center', 'virtualization']	['multi_core', 'cooling_power', 'core_cluster', 'energy_dissipation', 'energy_consumption']	['multi_core_cluster', 'floor_data_centers', 'raised_floor_data', 'data_centers_operate', 'minimum_energy_consumption']	J. et al. [NO] provides an in-depth analysis of some of today ’ s commonly accepted virtualization technologies from feature comparison to performance analysis, focusing on the applicability to high performance computing environments using futuregrid resources. 
