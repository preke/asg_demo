Online Signature Verification Based on Generative Models
Enrique Argones Rúa,José Luis Alba Castro
enrique.argones@gts.uvigo.es;,jalba@gts.uvigo.es).

Abstract
The success of generative models for online signature verification has motivated many research works on this topic. These systems may use hidden Markov models (HMMs) in two different modes: user-specific HMM (US-HMM) and user-adapted universal background models (UBMs) (UA-UBMs). Verification scores can be obtained from likelihood ratios and a distance measure on the Viterbi decoded state sequences. This paper analyzes several factors that can modify the behavior of these systems and which have not been deeply studied yet. First, we study the influence of the feature set choice, paying special attention to the role of dynamic information order, suitability of feature sets on each kind of generative model-based system, and the impor- tance of inclination angles and pressure. Moreover, this analysis is also extended to the influence of the HMM complexity in the performance of the different approaches. For this study, a set of experiments is performed on the publicly available MCYT-100 database using only skilled forgeries. These experiments provide interesting outcomes. First, the Viterbi path evidences a notable stability for most of the feature sets and systems. Second, in the case of US-HMM systems, likelihood evidence obtains better results when lowest order dynamics are included in the feature set, while likelihood ratio obtains better results in UA-UBM systems when lowest dynamics are not included in the feature set. Finally, US-HMM and UA-UBM systems can be used together for improved verification performance by fusing at the score level the Viterbi path information from the US-HMM system and the likelihood ratio evidence from the UA-UBM system. Additional comparisons to other state-of-the-art systems, from the ESRA 2011 signature evaluation contest, are also reported, reinforcing the high performance of the systems and the generality of the experimental results described in this paper.

I. INTRODUCTION
NOWADAYS, the society demands secure means for per-son authentication. Traditional authentication methods are based on the knowledge (password, Personal Identification Number numbers) or on the possession of a token (Identificator card, keys), which can be forgotten or stolen. This fact places a lot of attention in biometrics as an alternative method for person authentication and identification. Biometrics is defined in [1] as the use of physiological or behavioral characteristics for person recognition, and hence, they are not affected by the disadvantages of the traditional authentication methods since they cannot be forgotten or stolen.
Biometrics can be coarsely categorized into behavioral and physiological biometrics. Physiological biometrics are based on measurable physiological traits, such as fingerprints or the iris pattern. Behavioral biometrics are based on measurements extracted from an activity performed by the user, in a conscious or unconscious way, and they are inherent to his/her own personality or learned behavior, although influenced also by the physical characteristics of the person. In this sense, behavioral biometrics have some interesting advantages, like user acceptance and cancelability, but they still lack the same level of uniqueness as physiological biometrics. Among all the biometric traits that can be categorized as pure behavioral, the signature, and the way that we sign, is the one that has the widest social acceptance for identity authentication.
On the basis of the signature acquisition method, signature recognition methods can be categorized into static (or offline) and dynamic (or online) methods. Offline signature verification uses the shape of the signature to authenticate the signer. Online signature verification uses dynamic characteristics of the signature (time-dependent signals) to authenticate the signer. Learning the dynamics of the real signer is a difficult task for an impostor, compared to replicate only the shape of a signature. Moreover, the use of devices with built-in pen input such as smartphones, Personal Digital Assistants, or tablet PCs has been spread in the last years. These facts have motivated great research efforts in the last decade on dynamic or online signature verification, as reviewed in [2].

A. Previous Works in Online Signature Verification
Online signature verification methods can be coarsely categorized attending to the feature extraction process and the signature representation and matching strategy. Several different features have been proposed for signature representation, and they can be divided into local and global representations. Some examples of global feature-based signature verification systems can be found in [3]–[5]. The exclusive use of global features leads to reduced verification time, but the performance of algorithms also incorporating local features is generally better, as stated in [6]. A large variety of local feature-based signature verification systems can be found in the literature and summarized in [2]. Some multiexpert systems use combinations of global and local features, such as the systems presented in [7] and [8]. Signature verification systems can also be classified with respect to the matching technique into template
1083-4419/$31.00 © 2012 IEEE
matching and statistical approaches. Most commonly used template matching algorithms are based on dynamic time warping (DTW), such as [9]–[11], although some other approaches have been used, such as regional correlation and skeletal tree matching, presented in [12]. Regarding statistical signature verification, we can find some alternatives, such as the systems in [13] and [14], based on support vector machines, although most common approaches are based on generative models. The most common approach adopted in these systems is based on the use of user-specific hidden Markov models (HMMs) (US-HMMs) or Gaussian mixture models (US-GMMs), such as the works in [4] and [15]–[19]. The verification score in these systems is usually obtained as the signature log-likelihood. An important part in generative model-based signature verification systems is the verification score normalization (see [20] and [21]). Universal background models (UBMs) have been applied separately for score normalization and user model generation for GMM-based systems (see [19] and [22]). In [19], the user models are trained from the scratch using user signatures, and therefore, the UBM is used only for score normalization, whereas in [22], the UBM is used both for user model adaptation and score normalization, but it is based on global characteristics of the signature, which leads to reduced verification performance. More recently, the user-adapted UBM (UA-UBM) system presented in [23] also applied UBMs for model generation and score normalization to HMM-based online signature verification based on time sequences: User models are generated by adapting the UBM parameters to the enrollment data by means of maximum a posteriori (MAP) adaptation. The verification score is obtained as the signature log-likelihood ratio between the user model and the UBM. Another important advance in HMMbased signature verification is the incorporation of the Viterbi path into the verification process, such as done in [16] and [24]. Verification evidence derived from the Viterbi path can be applied to any HMM-based system, including the UA-UBM system proposed in [23].

B. Motivation
Generative models’ behavior has been analyzed from different points of view in the literature. The importance of instant pen inclination angles and pressure, model order, and fusion between likelihood and Viterbi path evidence has been deeply described in other papers for US-HMM systems. The influence of inclination angles and pressure has been analyzed in [15] and [25], and order selection has been studied in [19], but only US-HMM systems based on the log-likelihood verification evidence are considered. The fusion of the Viterbi path evidence and log-likelihood evidence has been addressed in [24], but again, only US-HMM systems are considered. The influence of number of acquisitions in verification performance for US-HMM systems is analyzed in [15]. However, in all the cases cited earlier, the studies are limited to US-HMM systems, and they provide only limited analysis on the suitability of the used feature spaces for using each of the available verification evidences. Finally, it is important to notice that none of the aspects studied in the cited papers has been analyzed for online signature verification based on UA-UBM.

C. Paper Outline
To the best of our knowledge, a complete analysis of the several factors affecting online signature verification based on generative models is still missing in the literature. Thus, loosely speaking, this is the first attempt to fill this gap in. Towards this direction, the contribution of this paper is threefold: First, there exist physical motivations to argue that signature dynamics contain information beyond the second-order time derivatives, but as far as we know, only up to second-order time derivatives have been used in feature spaces. However, the behavior of US-HMM systems and UA-UBM systems and even the performance of the different verification evidences can be affected by the specific dynamic features finally used. This motivates us to analyze which dynamic features are best suited for each system based on generative models, paying special attention to the use of time derivatives of different orders and to the use of features provided by complex capture devices, such as pen inclination angles and pressure measurements. This analysis is also extended to analyze the scenarios where the fusion of these verification evidences is useful, both in single-expert and multiexpert systems. Moreover, an analysis on the influence of model complexity on the verification performance obtained by each verification evidence is also presented, thus extending the previous analysis. With these analyses, we intend to provide the necessary understanding to design high performance online signature verification systems based on generative models.
Systems are compared on the basis of verification performance of the different verification evidences available for each system (Viterbi path, and log-likelihood or log-likelihood ratio in the case of US-HMM systems or UA-UBM systems, respectively). The analyses are based on experimental results obtained on extensive tests on the MCYT-100 database, described in [26], using only skilled forgeries for performing the impostor verification attempts.
The rest of this paper is structured as follows. Section II is dedicated to the different online signature verification systems based on generative models. Namely, US-HMM and UA-UBM systems are described. Viterbi path-based evidence for signature verification is exposed in Section III. A rule for a priori assessing the expected suitability of a feature set for UA-UBM user verification is described in Section IV. Dynamic features used in this paper for online signature verification are shown in Section V. The experimental framework is described in Section VI. Experimental results are shown and discussed in Section VII, where a comparison with other state-of-the-art methods is also reported. This paper is finally drawn to conclusions and some ideas for future works are shown in Section VIII.

II. GENERATIVE MODELS
Statistical-based approaches for online signature verification mostly rely on building a generative model for the user’s signature. These models try to estimate the distribution of the dynamic feature vectors. The most commonly used generative models are based on HMMs. In US-HMM systems, the verification scores can be obtained directly from the log-likelihood
of the online signature vectors. One of the main drawbacks of these systems is the dependence of the verification performance on the amount of signatures available for enrollment and the dependence of the optimal threshold on the user. The use of a UBM for score normalization purposes or for generation of user models through MAP adaptation is useful to thwart the effects of enrollment data scarcity and user-dependent score distribution drifts, providing verification performance improvements, as shown in the UA-UBM systems proposed in [22] and [23], where the UBM is a GMM and an HMM, respectively (although the UA-UBM system in [22] uses global features instead of time sequences). US-HMM and UA-UBM systems are explained in the following sections.

A. US-HMM System
An HMM [27] is a statistical model with an unobserved first-order discrete Markov process. Each state of this hidden (nonobservable) Markov chain is associated with a probability distribution. The observations of an HMM are produced according to these distributions and, hence, according to the hidden state. An HMM is formally defined by the following parameters:
1) S = {S1, . . . , SN}: the state set of the Markov chain, where N is the number of states; 2) A = {aij}; aij = P (qt = Sj |qt−1 = Si); i, j ∈ {1, . . . , N}: state transition matrix; 3) B = {bi(x)}; i ∈ {1, . . . , N}, where bi(x) denotes the probability density functions of the observations at state Si; 4) Π = {πi}: set of the initial state probabilities, where πi = P (q1 = Si).
The structure of an HMM is illustrated in Fig. 1. Output distributions are commonly modeled as GMMs
bi(x) = M∑
m=1
wi,mN (x,µi,m,Σi,m) (1)
where N (x,µi,m,Σi,m) denotes a multivariate normal probability density function with mean µi,m and covariance matrix Σi,m and M is the number of mixtures in the GMM. An HMM is hence fully characterized by the parameter set Λ = {A,B,Π}. In a US-HMM system for online signature verification, a user HMM Λu is generated for each user u. Different strategies can be adopted for the state labeling required before the HMM training. In [15], enrollment signatures are divided in N equal-length segments. A label is assigned to each segment, and each label corresponds to a state in the HMM. User-specific models built using this procedure have a left-to-right structure due to the sequential labeling process. In [16], a two-stage
stochastic approach is adopted. In the first step, a clustering based on the Linde-Buzo-Gray algorithm [28] is used to label the enrollment signatures. In the second step, these labeled signatures are then fed to the Baum–Welch algorithm [29] to obtain the user model Λu. User models generated using this procedure are ergodic. This is the approach that we adopted in this paper for user model generation in US-HMM systems. This user model generation process is illustrated in Fig. 2(a).
The verification score in a US-HMM verification system for a given probe signature O = {o1, . . . ,oT } is provided by the log-likelihood of the sequence, given by P (O|Λu). However, this is usually approximated by P (O,QVO |Λu), where QVO = {q1, . . . , qT } = maxQ{P (O,Q|Λu)} is the best path found by means of the Viterbi algorithm. This score is usually provided in the form of a log-likelihood: log[P (O,QVO |Λu)]. Time normalization is adopted to avoid the undesirable dependence of this log-likelihood on the signature duration. Moreover, US-HMMs lead to user-dependent score distributions. An additional userdependent score normalization is performed, obtaining the following verification score: sLlkh(O, u) = log [ P ( O,QVO |Λu )] T
− 1 K ∑ Oe∈E
log [ P ( Oe, QVOe |Λu )] T e (2)
where E is the enrollment set, T e is the duration of the Oe enrollment signature, and K is the cardinality of E , i.e., number of enrollment signatures.

B. UA-UBM Systems
UA-UBM systems based on HMMs employ a userindependent HMM ΛUBM as UBM, trained using signatures provided by many different users [23]. Then, user models are obtained by adapting this UBM to the enrollment signatures.
The training of a universal background HMM must be faced in two stages. In the first step, UBM training signatures must be labeled with a user-independent strategy in order to initialize the Baum–Welch training algorithm. In [23], this labeling is performed by means of an activity detection process based on
a dynamic feature, such as the logVelocity or the pressure. However, an alternative initial state labeling can be obtained using the full feature vector adopting a general stochastic approach. LBG algorithm, usually used for the initialization of the Expectation-Maximization algorithm in GMM training, can be used here to cluster the full feature space into a userindependent state space. UBM training signatures are labeled according to this clustering. In the second step, labeled signatures are used to obtain the user-independent HMM ΛUBM by means of the Baum–Welch algorithm, as illustrated in Fig. 2(b). The obtained UBM ΛUBM is, in general, an ergodic HMM.
User models are obtained adapting the UBM to the enrollment signatures using the MAP adaptation. In this paper, only the adaptation of the means of the output distributions is performed. Given the K enrollment signatures for the user u, Xu = {x1u, . . . ,xKu }, where xku = {xku,0, . . . ,xku,T k}, we can compute the probability of state Si at time t in the enrollment signature xku, denoted as γu,t(i, k). The soft count of samples belonging to the Gaussian mixture m of the state Si, denoted as cu,i,m, is defined as (we obviate the index u from now on for the sake of clarity)
ci,m = K∑
k=1 Ts−1∑ t=0 γt(i, k) wi,mN
( xkt ,µi,m,Σi,m ) ∑M
j=1 wi,jN ( xkt ,µi,j ,Σi,j ) (3) where γt(i, k) is the probability of state Si at time t in the enrollment signature xk. The MAP estimates for the model means for user u can be written as
µ̂i,m = µ̂ ML i,m ci,mri,m ri0,m+ci,mri,m +µi,m ri0,m ri0,m+ci,mri,m (4)
where µ̂MLi,m is the ML mean estimate given the enrollment data, µi,m is the value of the mean in the UBM, ri,m = 1/σ2i,m denotes the precisions, and ri0,m denotes the prior precisions. A more complete MAP formula description can be found in [30].
The verification score is derived from the classical hypothesis test.
1) Hu: The signature belongs to the claimed user u, represented by the HMM Λu. 2) Hū: The signature does not belong to the claimed user u, represented by the HMM Λubm.
Given a probe signature O, this hypothesis test leads to a verification score that can be expressed in the form of loglikelihood ratio
sLlkhR(exact)(O, u) = log [P (O|Λu)] − log [ P ( O|Λubm)] .
(5) Again, as in the case of the US-HMM, the likelihoods in the previous expression are approximated by the best path likelihood, obtained by means of the Viterbi algorithm, and time normalized sLlkhR(O, u)= log [ P ( O,QVO |Λu )] T − log [ P ( O,QVO |Λubm )] T .
(6)

III. SIGNATURE VERIFICATION SCORE BASED ON THE VITERBI PATH
HMM-based systems provide two complementary sources of information, as shown in [16]: The first one is based on likelihood measurements of the signature, and it is encoded in the scores shown in (2) and (6) for the US-HMM and UA-UBM systems, respectively; the second one is the decoded state sequence, also called the Viterbi path or the best path.
The likelihood information is computed taking into account only the time-local information along the whole probe signature; hence, a partial forgery of a signature could easily mislead a system based only on a time-normalized likelihood-based score.
Given two state sequences Q1 and Q2, we denote d(Q1, Q2) as the city block distance (CBD) between them. In [16], the authors propose to use the average CBD between the probe signature Viterbi path Qp and the Viterbi paths of the enrollment signatures, normalized by the average duration of enrollment signatures, as a segmentation score
saltseg = exp
( − 1 K ∑ Qe∈E d(Q p, Qe)
T e
) (7)
where Qp is the Viterbi path of the probe signature, E = {Qe1 , . . . , QeK} is the enrollment set of Viterbi paths with K elements, T e = (1/K) ∑K k=1 Tek is the mean duration of the signatures in the enrollment set, and the exponential function is used only to map the score into a similarity measure. Differently to [16], we define a new segmentation score, as our preliminary experiments have revealed a slight improvement in the verification performance. This score can be expressed as
sseg = −minQe∈E {d(Qp, Qe)}
Tp (8)
where Tp is the duration of the probe signature. The min operator is useful to cope with the high intrauser variability in the signature space. Fig. 3 illustrates the segmentation score computation.
The segmentation score shown in (8) can be fused with the likelihood-based scores shown in (2) and (6). In the scorelevel fusion experiments carried out in this paper, z-Norm is applied to likelihood- and Viterbi-based scores, and then, fusion is performed using the sum rule
sSR = szseg + s z Llkh|LlkhR. (9)

IV. A PRIORI FEATURE SET SUITABILITY MEASURE FOR
USER VERIFICATION BASED ON UBM-ADAPTED MODEL
It is difficult to know a priori whether a given feature set is well suited for user verification in a UA-UBM system. As shown in Section VII, a feature set can be a good choice for a user-specific model approach while it can result in low verification performance in a UA-UBM approach and vice versa. To the best of our knowledge, there is not any method in the literature to assess the suitability of a given feature space for UA-UBM systems. The common methodology is to train a UBM in that space and check the system performance with a verification experiment afterward. In this section, we shed some light on the problem of feature set suitability for UAUBM schemes by designing a priori measures to determine the suitability of a given feature set for this framework.
In order to provide a priori rules for feature set suitability, it would be preferable that only genuine enrollment loglikelihood ratios were used since this would eliminate the need of skilled forgeries in the design phase of a specific system. Let P be a set of NP persons used as probe population for estimating feature set suitability. Let SP = {OP1 , . . . , OPNe} be the enrollment signature set of the user P ∈ P . Let µP and σ2P be the mean and variance of the log-likelihood ratios of the user P ’s enrollment signatures between the adapted model of user P and the UBM
µP = 1
Ne Ne∑ i=1 sLlkhR ( OPi , P ) (10)
σ2P = 1 Ne − 1 Ne∑ i=1 [ sLlkhR ( OPi , P )− µP ]2 . (11) From these statistics, we can define the between-class vari-
ance of the enrollment log-likelihood ratios as
σ2P,b = 1 NP − 1 ∑ P∈P [µP − µP ]2 (12)
where µP = (1/NP) ∑
P∈P µP . Similarly, the within-class variance of the enrollment log-likelihood ratio can be defined as
σ2P,w = 1
NP ∑ P∈P σ2P . (13)
Nonsuitability of a given feature set for being used by a UBM-adapted model system can be due to two main reasons. First, a feature set where user representation is too sparse can impair the ability of the UBM to represent all the users with equal proficiency, producing user models overfitted to the training data. In such circumstances, some users provoke only a small modification of the UBM parameters in the adaptation process, leading to small log-likelihood ratios in the enrollment set, while other users provoke a huge modification of the UBM parameters, leading to high log-likelihood ratios in the enrollment set. In this case, high values of the between-class variance of the enrollment log-likelihood ratios σ2P,b should be expected. Furthermore, some enrollment signatures from a given person
can remain much worse represented in the adapted model than others, which leads to large within-class variance of the enrollment log-likelihood ratio σ2P,w. Therefore, this behavior can be monitored by observing the value of σ2P,b · σ2P,w. Second, even if a UBM was able to properly cover all the space regions where the users’ data lay, the model adaptation might be unable to capture enough discriminant identity information (at least encoded in the actual feature set). In such a case, the betweenclass variance of the enrollment log-likelihood ratio σ2P,b would be high when compared to the within-class variance σ2P,w. This second case can therefore be monitored by observing the value of the ratio σ2P,b/σ 2 P,w. Thus, by using simple checks, illposed feature sets can be easily detected. Nevertheless, they are unable to predict how good the verification results will be since this depends on the impostor claims’ log-likelihood ratio distribution, which is not observed by these measures. Loosely speaking, the only objective of these measures is to detect systems that will underperform. The feature set-dependent performance analysis shown in Section VII will allow us to set thresholds on these measures for the two ill behaviors described earlier.

V. ONLINE SIGNATURE PARAMETERIZATION
As described in [26] and [31], signatures are captured using a pen tablet model INTUOS A6 Universal Serial Bus, branded by [32]. The tablet spatial resolution is 100 lines per millimeter. The precision is ±0.25 mm. The maximum detection height is 1 cm, and the sampling rate is 100 Hz. Time signals provided by the digitizer are as follows.
1) Coordinate information: x and y. 2) Pressure: pr. 3) Angles: elevation γ and azimuth φ. 4) Pressure state: ps = 1 ⇐⇒ pr > 0. Otherwise, ps = 0. The pressure state is not used in the online signature verification systems proposed in this paper. Fig. 4 illustrates the angles provided by the digitizer. Additional dynamic features are derived from these features.
1) Velocity v= √ (δx/δt)2 + (δx/δt)2 = √
(v2x + v2y), and logVelocity logV = log(1.0 + v). 2) Acceleration a = δv/δt. 3) Tangential angle θ = tan−1(vy/vx). 4) Curvature radius cr = (δθ/δt)/v. 5) logPressure logPr = log(1.0 + pr). The previous dynamic features can be used directly for online
signature representation
o0 = [x, y, pr, γ, φ, v, a, θ, cr, logV, logPr]. (14)
Indeed, this signature representation has been used in previous works for US-HMM systems [20], [21], [24]. This feature set includes temporal information up to the second derivative. However, there are no reasons to think that the signature production biomechanic process can rely only on these low-order descriptors, and the possible contributions of higher order time dependences remain unknown. This motivates us to include also first, second and third derivatives of all the previous dynamic
features. As a result, a total of 44 different dynamic features are available for signature verification computations
oi = δi
δti o0, i ∈ {1, 2, 3} (15) o = [o0|o1|o2|o3]. (16)
Systems will be tested using different subsets of the full feature set. The sets have been chosen in order to answer to the following important questions in online signature verification.
1) Do features obtained by complex tablet devices, such as inclination angles or numerical pressure, actually improve signature verification performance? What is their contribution within the different verification evidences? Two kinds of basic vectors are used for this purpose: the full basic vector o0, defined in (14), and a reduced basic vector or0
or0 = [x, y, v, a, θ, cr, logV ]. (17)
2) Are high-order derivatives useful in online signature verification? Are they equally useful within all the signature verification evidences provided by the different generative models?
This is an important point since the question of which features are best suited for UA-UBM online signature verification is open, mainly due to the low number of previous works within this framework. Furthermore, the dependence of the Viterbi path evidences on the employed feature space has not been analyzed yet. Feature vectors will be built using combinations of the basic vectors o0 or or0, denoted, in general, as o (r) 0 , and their first-, second-, or third-order derivatives. Resultant feature vectors can be noted as
o (r) S(r) = [ o (r) i |i ∈ S(r) ] (18)
where o(r)S(r) is fully characterized by the S(r) set. For example, if S(r) = {0, 1}, then o(r)S(r) = [o (r) 0 |o(r)1 ], meaning the basic vector (reduced or not) and its first derivative.

VI. EXPERIMENTAL FRAMEWORK
The MCYT bimodal biometric database [26] consists of fingerprint and online signature modalities. MCYT-100 is a subcorpus of 100 users from the MCYT database. The signature modality used in our experiments includes both genuine signatures and skilled forgeries with natural dynamics: Impostors were asked to imitate the shape trying to generate a smooth and natural signature. Each user in the data set has 50 associated signatures, 25 of which are genuine, and 25 are skilled forgeries generated by subsequent contributors. For UBM training, we use a set of 50 users from the BIOSECURE-DS2 handwritten signature corpus (see [31]). This signature corpus was acquired using the same acquisition device, which makes it compliant with the MCYT-100 corpus. Fig. 5 illustrates the division of the MCYT-100 in enrollment and test partitions and the UBM training set, taken from the BIOSECURE-DS2 corpus.

VII. EXPERIMENTS
Our experiments, as described in the previous sections of this paper, are oriented to discover which combination of features is best suited for online signature verification for each system, which system and verification evidence obtain the best verification performance, and whether it is possible to obtain competitive results using a reduced set of features, which would be provided even by simple tablet devices. Systems are tested on the MCYT-100 data set using only skilled forgeries. The enrollment size is ten signatures for each user, following MCYT-100 protocol. A study of the performance dependence of US-HMM systems on the enrollment size has been carried out in [15], and it is widely known that enrollment data requirements for MAP model adaptation are smaller than for the US-HMM model training. Therefore, in the experiments shown in this paper, we just set the number of enrollment signatures to ten, which guarrantees good performance for both UA-UBM and US-HMM approaches.
The system parameters used in the experiments carried out in this paper were chosen accordingly to previous experiments, and agreeing to orientative results regarding model order selection shown in [19]. Specifically, US-HMM systems have N = 8 states and M = 32 Gaussians per state; UA-UBM systems have also N = 8 states and M = 32 Gaussians per state. An additional experiment is carried out in order to analyze the model order influence on the performance of the different verification evidences.

A. Experiments Using Pressure and Inclination
Angle Information
The main goal of our first experiment is to detect which set of features is best suited for the different generative modelbased online signature verification systems and verification evidences. An exhaustive feature selection approach, such as sequential forward floating search [33], is not practical in this case since each iteration would require computationally expensive testing and model training. Given the feature vector notation provided in (18), the feature set suitability evaluation is performed by testing all the possible S sets (except the null set): S ⊆ {0, 1, 2, 3},S = ∅.
Since each system and verification evidence described in Section II can present different behavior depending on the input feature space, all the systems and verification evidences are evaluated in this experiment. It will also provide performance comparison among the different systems and statistics for online signature verification.
Observing the results shown in Table I, it is clear that the log-likelihood of US-HMMs does not obtain satisfactory results when no score normalization is employed. This verification evidence obtains specially bad performance when the basic feature vector is not in the feature set. When the basic feature vector o0 is included in the feature set, the verification rates obtained using this evidence significantly improve, but verification performance is still not satisfactory. This bad behavior of the log-likelihood evidence is mainly due to the need of an a posteriori user-specific score normalization, such as the one used in [20]. However, the use of these techniques depends on the availability of skilled forgeries for every new user in the system, which is not reasonable in a real-world system. On the other hand, it is remarkable that the Viterbi path score obtains much more competitive and feature-space independent results. In conclusion, in the absence of an a posteriori score normalization technique, the Viterbi path verification evidence is the best performing for US-HMM systems. This seems to be due to the nature of this score, which does not need a user-specific normalization or thresholding owing to the length normalization and minimum distance selection.
The verification performance of UA-UBM systems is shown in Table II. The Viterbi path verification evidence shows, as in the US-HMM systems’ case, a very stable performance independently on the employed signature representation, and the verification rates are a little bit worse than those shown by the same evidence for US-HMM systems. Log-likelihood ratio evidence also exhibits competitive verification results, but only when combinations of derivatives of the basic feature vector oi, i ∈ {1, 2, 3} are used. In these cases, log-likelihood ratio evidence provides consistently better verification rates when compared to Viterbi path evidence and very clear advantages over US-HMM log-likelihood evidences. However, if the basic feature vector is included in the feature set, the verification performance dramatically drops. This behavior can be explained by paying attention to the values of the feature set suitability measures plotted in Fig. 6, where high values of σ2P,b · σ2P,w are found in these sets when using the basic feature vectors (second half of the abscissa), which indicates the user’s data sparsity or overfitting, as explained in Section IV. The values of σ2P,b/σ 2 P,w indicate that the between-class variance is consistently higher in all the feature sets tested. This indicates that the adaptation process is able to extract enough discriminant information. However, the overfitting problem degrades the verification performance. It should be noticed that the overfitting cannot be eliminated by adding more features to the input space since the same problem shows up in all the input spaces containing the basic feature vector and combinations of derivatives of this basic feature vectors. This analysis corroborates the importance of selecting the feature space correctly, i.e., using only higher order dynamics for online signature verification based on the log-likelihood ratio evidence provided by UA-UBM systems.
1) Fusion of US-HMM and UA-UBM Approaches: It is also noticeable that the best performing US-HMM systems using the Viterbi path score obtain almost the same performance levels as those obtained by the best performing UAUBM systems (the best user-specific system’s Viterbi path evidence obtains 2.93%, whereas the best UA-UBM system’s log-likelihood ratio obtains 2.87% equal error rate (EER)). These verification evidences come from different information
sources, which makes us wonder whether the score-level fusion of Viterbi path scores from a US-HMM and log-likelihood ratio scores from a UA-UBM can be useful or not. Benefits of fusing Viterbi and likelihood information when using the same feature space were already experimentally demonstrated for US-HMM and UA-UBM systems in Tables I and II, respectively, but now, we want to check the convenience of fusing both systems, US-HMM and UA-UBM, using the best feature space and verification evidences for each one. In order to analyze this issue, we performed an additional fusion experiment using the sum rule. The chosen systems were the UA-UBM system with S ∈ {{1, 2}, {1, 3}} and the US-HMM system with S = {{0, 1}, {0, 1, 2}}. The EERs of these fused systems are shown in Table III. Statistically significant improvements in verification performance are obtained in all the cases. This brings out an important conclusion: The Viterbi path from US-HMM systems and the log-likelihood ratio from UA-UBM systems are providing complementary information regarding the identity verification question, or in other words, these verification evidences are very well suited to be used for intramodal fusion. It is also remarkable that the best monoexpert dual-evidence system, i.e., the UA-UBM using S = {1, 3}, obtains a 2.27% EER, as shown in Table II, which is consistently outperformed by multiexpert dual-evidence sum rule verification performances shown in Table III. This enhances the possibility of improving verification rates when fusing US-HMM and UA-UBM approaches.
2) Model Order Influence on the Different Verification Evidences: The dependence between training and test complexity and model parameters has been thoroughly studied in the literature. Specifically, each Baum–Welch iteration complexity is O(N2TMD) [27], where D is the samples’ dimen-
sion, and LBG clustering method complexity is O(IMNTD) [34], where I is the number of iterations required to meet the stop criterion. The UA-UBM method’s main computation requirements are located in the UBM training stage, which is performed offline, before the system is working, so it can be ignored here. If we pay attention only to the user model creation complexity, it is clear that the US-HMM approach is much more time consuming since it requires a full training process, with an LBG run and tens of Baum–Welch iterations, while the UA-UBM only requires a MAP adaptation, with a complexity equivalent to a single Baum–Welch iteration. On the other hand, test complexity is twice smaller for US-HMM systems since only one model is involved in computations. However, using optimizations such as fast scoring [35], if the complexities of the UBM and the US-HMM are the same, test time will be almost the same for both approaches. Therefore, in terms of time comsumption, US-HMM is more time demanding in the enrollment stage, while both UA-UBM and US-HMM approaches are almost equivalent in test time. However, it is not clear which model complexity performs best for each approach. This motivates the following experiment.
In Table IV, we analyzed the dependence of the verification evidences’ performance on the model complexity when using suitable feature sets for both UA-UBM and US-HMM systems. In the case of the US-HMM system, the Viterbi path verification evidence has a quite stable performance for N ≥ 4, although the best result is obtained with N = 8 states. This also happens for UA-UBM systems, underlining that a too small number of states can degrade the verification performance obtained by this verification evidence. The verification performance obtained by US-HMM systems when using only the log-likelihood verification evidence is very low. As explained earlier, these results could be improved if an a posteriori user-specific log-likelihood normalization is used. Since only a priori normalization is used, user-dependent drifts in the log-likelihood distribution hide the influence of the model order in the verification performance. In the case of the UA-UBM system, the best verification performance for all the verification evidences is obtained with N = 8 states, which seems to be an adequate tradeoff between model complexity and data overfit: Models with less states seem to be too simple, while more complex models seem to slightly overfit the training data. Moreover, it is noticeable that the Viterbipath evidence is more affected by the model complexity. The
log-likelihood ratio’s behavior is very stable due to the additional resilience to overfitting and data scarcity derived problems provided by the model adaptation. In this experiment, the good performance of sum-rule fusion is also noticeable, minimizing the influence of badly chosen complexity parameters and providing stability to the verification performance.
3) Comparison With Other Systems: Table V shows the verification equal error rates of all the systems involved in Task 2 of the recently performed signature verification evaluation held in the BioSecure Signature Evaluation Campaign 2011: the International Joint Conference on Biometrics (IJCB) 2011 Evaluation of Signature Resistance to Attacks (ESRA’2011) [36]. In this task, systems are compared within a common data set with 382 signers, the DS2-382 [31], when using pen coordinates, pressure, and inclination angles. Systems are compared taking into account the measured quality of the presented forgeries [37]. The system labeled as VIGO is one of the systems presented in this paper (trained using the contest data sets), namely, it is a weighted sum fusion of US-HMM Viterbi path evidence and UA-UBM log-likelihood ratio evidence, as suggested in Section VII-A1. Hence, this table provides a direct comparison in terms of performance of the methods proposed in this paper with other state-of-the-art approaches. Results in Table V confirm the generalization of the results shown in this paper and also demonstrate the competence of the generative model approach. Indeed, the VIGO approach outperforms the other systems in this case. It is also important to note that the second performing system, labeled as Ref. Syst., is also using an HMM-based approach. However, the fusion of US-HMM Viterbi and UA-UBM log-likelihood ratio evidences makes the difference between our system and the Ref. system since the latter uses Viterbi and loglikelihod evidences from a single USHMM system.

B. Experiments Without Pressure and Inclination
Angle Information
Our second experiment is aimed to compare the reliability of generative model-based online signature verification evidences when using reduced feature sets, where features provided only by complex acquisition devices, such as pressure or inclination angles, are discarded. For these experiments, we used the same system configurations, changing only the input features.
Verification performance using the reduced feature vector defined in (17) and its time derivatives, which do not include pressure and inclination angle information, is shown in
Tables VI and VII for US-HMM systems and UA-UBM systems, respectively. Again, as in the standard feature vector case, the Viterbi-path evidence is the best verification evidence in the US-HMM systems, showing only slightly degraded performance for S = {0}. In the case of UA-UBM systems, Viterbi path shows a similar behavior, showing competitive results when compared to log-likelihood ratio evidence, and a high performance stability on the different feature sets. If we compare results obtained by the Viterbi path evidence for standard (see Tables I and II) and reduced feature sets (see Tables VI and VII), it stands out that this verification evidence is able to provide competitive verification performance, even when inclination angle and pressure information is not available.
The behavior of the log-likelihood ratio can be analyzed for the different input feature spaces attending to the suitability measures introduced in Section IV. When inclination angle and pressure information is not available, the only feature set where log-likelihood ratio obtains clearly bad verification
performance is when only the basic feature vector is used: S(r) = {0}. In this case, the inclusion of additional features seems to be helpful in order to improve verification performance, which enhances the role of higher order time dependences for boosting log-likelihood ratio verification rates. From the plot of the suitability measures for this experiment shown in Fig. 7, it stands out that S(r) = {0} is not an overfitting or user data sparsity case. The coefficient σ2P,b · σ2P,w remains in moderate values, and the only symptom of the problem arises attending to the value of the ratio σ2P,b/σ 2 P,w, which is clearly the lowest in the whole set of experiments. This indicates that the reduced basic feature vector does not provide enough discrimination performance (at least, it is not properly captured in the log-likelihood ratio evidence) by itself. This is reinforced by the fact that verification performance improves as other time derivatives are included, which would not happen if it were an overfitting problem.
1) Importance of Inclination Angle and Pressure Information: Comparing results obtained using pen inclination angle and pressure information shown in Tables I and II with results in Tables VI and VII, where these features are discarded, leads us to the following conclusion: The use of these additional features can result in improved verification performance, but results obtained by fusing evidences derived from the Viterbi path and likelihoods can overcome the lack of these information sources. For example, the best systems using the full feature vector achieve 2.27% EER, while the best system using the reduced feature set achieves 3.07% EER, which is competitive despite that inclination angles and pressure are not taken into account.
2) Fusion of US-HMM and UA-UBM Approaches: Table VIII shows the performance of the sum-rule fusion of the Viterbi path verification evidence provided by the best performing US-HMM systems and the log-likelihood ratio provided by the best performing UA-UBM systems when using this verification evidence. We can observe that the sum-rule fusion is useful in all the cases, obtaining statistically significant improvements with respect to the individual fused system’s verification performances. This reinforces the hypothesis of complementarity of the Viterbi path and log-likelihood ratio evidences and encourages the use of this intramodal multiexpert score-level fusion.
3) Comparison With Other Systems: For a direct comparison of the proposed systems with other state-of-the-art systems in a setup where pressure and inclination angles are not available, we can see the EER performance shown in Table IX. These results have been extracted from the BioSecure Signature Evaluation Campaign 2011, the IJCB ESRA’2011 [36], in Task 1. Systems using different state-of-the-art methods are involved, including one of the systems derived from this paper, labeled as VIGO, several DTW approaches, and an alternative HMM approach, the Ref. Syst. approach. This Ref. Syst. performs a sum rule fusion of US-HMM log-likelihood and Viterbi path evidence, while the VIGO system performs a sum fusion of UA-UBM log-likelihood ratio and US-HMM Viterbi path evidence, which should obtain better results, as suggested in Section VII-B2. In this case, both VIGO and Ref. Syst. HMMbased approaches outperform the other methods, but the VIGO shows increased robustness to high-quality forgeries, which enhances the importance of the proposed multiexpert scorelevel fusion.

VIII. CONCLUSION
In this paper, we have analyzed the influence of the feature set choice on the verification performance of generative modelbased online signature verification systems using verification evidences provided by the Viterbi path and signature loglikelihoods, paying special attention to the inclusion of higher order dynamic information, inclination angles, and pressure information. Fusion of the different verification evidences provided by these systems has also been investigated.
Verification evidence derived from the Viterbi path shows a notable stability and competitive verification performance for both US-HMM and UA-UBM systems, for most of the feature spaces employed. The dependence of this verification evidence on the model complexity has also been analyzed with regard to the number of states, revealing that it is very important to ensure a rich enough state representation (at least eight) to achieve a good performance for dynamic signature representation.
Likelihood evidence in US-HMM systems obtains better verification performance when lowest order dynamic information is included in the feature set, but even in this case, performance is not competitive without additional score normalizations.
Log-likelihood ratio evidence obtained for UA-UBM systems exhibits a high dependence on the chosen feature set. Specifically, the use of higher order dynamic information leads to significantly improved verification performance, which enhances the importance of dynamic information beyond the second-order time derivatives in modeling the signature production process. This behavior has been deeply analyzed in this paper, owing to two suitability measures specifically designed, which allow to detect ill-posed feature sets for this kind of verification evidence. This analysis demonstrates that the inclusion of the lowest-order dynamic information in the used feature set can lead to degraded verification performance for UA-UBM systems.
Finally, the score-level fusion of log-likelihood ratio from UA-UBM systems and Viterbi path verification evidences from US-HMM or UA-UBM systems leads to improved verification performance, highlighting the complementarity of these evidences and suitability of the different generative model-based online signature verification approaches for score-level fusion.

References
[1]N.K. Ratha,A.W. Senior,R.M. BolleAutomated biometricsProc. 2nd Int. Conf. Adv. Pattern Recog., Rio de Janeiro, Brazil, Mar. 2001, pp. 445–474.2001
[2]D. Impedovo,G. PirloAutomatic signature verification: The state of the artIEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 38, no. 5, pp. 609–635, Sep. 2008.2008
[3]H. Ketabdar,J. Richiardi,A. DrygajloGlobal feature selection for on-line signature verificationProc. 12th IGS Conf., Salerno, Italy, Jun. 2005, pp. 59–63.2005
[4]R. Kashi,J. Hu,W.L. Nelson,W. TurinOn-line handwritten signature verification using hidden Markov model featuresProc. 4th Int. Conf. Doc. Anal. Recog., Ulm, Germany, Aug. 1997, pp. 253–257.1997
[5]L.L. Lee,T. Berger,E. AviczerReliable on-line human signature verification systemsIEEE Trans. Pattern Anal. Mach. Intell., vol. 18, no. 6, pp. 643–647, Jun. 1996.1996
[6]A.K. Jain,F.D. Griess,S.D. ConnellOn-line signature verificationPattern Recognit., vol. 35, no. 12, pp. 2963–2972, 2002.2002
[7]J. Richiardi,H. Ketabdar,A. DrygajloLocal and global feature selection for on-line signature verificationProc. IAPR 8th ICDAR, Seoul, Korea, Aug. 2005, vol. 2, pp. 625–629.2005
[8]J. Fiérrez Aguilar,L. Nanni,J. López-Peńalba,J. Ortega García,D. MaltoniAn on-line signature verification system based on fusion of local and global informationProc. IEEE Int. Conf. Audio Video-Based Person Authentication, Halmstad, Sweden, Jun. 2005, pp. 523–532.2005
[9]M. Faúndez-ZanuyOn-line signature recognition based on VQ-DTWPattern Recognit., vol. 40, no. 3, pp. 981–992, Mar. 2007.2007
[10]Y. Chen,X. DingOn-line signature verification using direction sequence string matchingProc. SPIE 2nd Int. Conf. Image Graph., Hefei, China, Jul. 2002, vol. 4875, pp. 744–749.2002
[11]J. Putz-LeszczyskaOn-line signature verification using dynamic time warping with positional coordinatesProc. SPIE Int. Soc. Opt. Eng., Wilga, Poland, Oct. 2006, vol. 6347, no. 2, pp. 634 724-1–634 724-08.2006
[12]M. Parizeau,R. PlamondonA comparative analysis of regional correlation, dynamic time warping, and skeletal tree matching for signature verificationIEEE Trans. Pattern Anal. Mach. Intell., vol. 12, no. 7, pp. 710–717, Jul. 1990.1990
[13]M. Fuentes,S. Garcia-Salicetti,B. DorizziOn-line signature verification: Fusion of a hidden Markov model and a neural network via a support vector machineProc. 8th Int. Workshop Frontiers Handwriting Recog., Niagara-on-the-Lake, ON, Canada, Aug. 2002, pp. 253–258.2002
[14]A. Kholmatov,B. YanikogluIdentity authentication using improved online signature verification methodPattern Recognit. Lett., vol. 26, no. 15, pp. 2400–2408, Nov. 2005.2005
[15]J. Fiérrez Aguilar,J.G.J. Ortega García,D. RamosHMM-based on-line signature verification: Feature extraction and signature modelingPattern Recognit. Lett., vol. 28, no. 16, pp. 2325–2334, Dec. 2007.2007
[16]B. Ly Van,S. García-Salicetti,B. DorizziOn using the Viterbi path along with HMM likelihood information for online signature verificationIEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1237–1247, Oct. 2007.2007
[17]J. Dolfing,E. Aarts,J. van OosterhoutOn-line signature verification with hidden Markov modelsProc. 14th ICPR, Brisbane, Australia, Aug. 1998, vol. 2, pp. 1309–1312.1998
[18]M. Pascual-Gaspar,V. Cardeñoso-PayoAutomatic online signature verification using HMMs with user-dependent structureProc. ICB, Seoul, Korea, Aug. 2007, pp. 1057–1066.2007
[19]J. Richiardi,A. DrygajloGaussian mixture models for on-line signature verificationProc. ACM SIGMM Workshop Biometrics Methods Appl.—Int. Conf. Multimedia, Berkeley, CA, Nov. 2003, pp. 115–122.2003
[20]J. Fiérrez-Aguilar,J. Ortega-Garcia,J. Gonzalez-RodriguezTarget dependent score normalization techniques and their application to signature verificationIEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 35, no. 3, pp. 418–425, Aug. 2005.2005
[21]J. Ortega-Garcia,J. Fiérrez-Aguilar,J. Martin-Rello,J. Gonzalez- RodriguezComplete signal modeling and score normalization for function-based dynamic signature verificationProc. 4th Int. Conf. Audio Video-Based Biometrie Person Authentication, Guildford, U.K., Jun. 2003, pp. 658–667.2003
[22]M. Martínez Díaz,J. Fiérrez Aguilar,J. Ortega GarcíaUniversal background models for dynamic signature verificationProc. IEEE Int. Conf. Biometrics—Theory Appl. Syst., 2007, pp. 1–6.2007
[23]E. Argones Rúa,D. Pérez-Piñar López,J. Alba CastroErgodic HMM-UBM system for on-line signature verificationProc. BIOID Multicomm—Lecture Notes Comput. Sci., Sep. 2009, vol. 5707, pp. 340–347.2009
[24]B.L. Van,S. Garcia-Salicetti,B. DorizziFusion of HMMs likelihood and Viterbi path for on-line signature verificationProc. Eur. Conf. Comput. Vis., Prague, Czech Republic, May 2004, pp. 318–331.2004
[25]N. Houmani,S. Garcia-Salicetti,B. DorizziOn assessing the robustness of pen coordinates, pen pressure and pen inclination to time variability with personal entropyProc. 3rd IEEE Int. Conf. BTAS, Piscataway, NJ, 2009, pp. 159–164.2009
[26]J. Ortega-Garcia,J. Fierrez-Aguilar,D. Simon,J. Gonzalez,M. Faundez- Zanuy,V. Espinosa,A. Satue,I. Hernaez,J.-J. Igarza,C. Vivaracho,D. Escudero,Q.-I. MoroMYCT baseline corpus: A bimodal biometric databaseProc. Inst. Elect. Eng.—Vis. Image Signal Process., vol. 150, no. 6, pp. 395–401, Dec. 2003.2003
[27]L.R. RabinerA tutorial on hidden Markov models and selected applications in speech recognitionProc. IEEE, vol. 77, no. 2, pp. 257–286, Feb. 1989.1989
[28]Y. Linde,A. Buzo,R. GrayAn algorithm for vector quantizer designIEEE Trans. Commun., vol. COM-28, no. 1, pp. 84–95, Jan. 1980.1980
[29]L. Baum,T. Petrie,G. Soules,N. WeissA maximization technique occurring in the statistical analysis of probabilistic functions of Markov chainsAnnals Math. Stat., vol. 41, no. 1, pp. 164–171, Feb. 1970.1970
[30]X. Huang,A. Acero,H. HonSpoken Language Processing: A Guide to Theory, Algorithm, and System DevelopmentUpper Saddle River, NJ: Prentice-Hall,2001
[31]J. Ortega-Garcia,J. Fierrez,F. Alonso-Fernandez,J. Galbally,M.R. Freire,J. Gonzalez-Rodriguez,C. Garcia-Mateo,J.-L. Alba-Castro,E. Gonzalez- Agulla,E. Otero-Muras,S. Garcia-Salicetti,L. Allano,B. Ly-Van,B. Dorizzi,J. Kittler,T. Bourlai,N. Poh,F. Deravi,M.N.R. Ng,M. Fairhurst,J. Hennebert,A. Humm,M. Tistarelli,L. Brodo,J. Richiardi,A. Drygajlo,H. Ganster,F.M. Sukno,S.-K. Pavani,A. Frangi,L. Akarun,A. SavranThe multi-scenario multi-environment biosecure multimodal database (BMDB)IEEE Trans. Pattern Anal. Mach. Intell., vol. 32, no. 6, pp. 1097–1111, Jun. 2010.2010
[32]P. Pudil,J. Novovicová,J. KittlerFloating search methods in feature selectionPattern Recognit. Lett., vol. 15, no. 11, pp. 1119–1125, Nov. 1994.1994
[33]J. Shanbehzadeh,P.O. OgunbonaOn the computational complexity of the LBG and PNN algorithmsIEEE Trans. Image Process., vol. 6, no. 4, pp. 614–616, Apr. 1997.1997
[34]J. McLaughlin,D.A. Reynolds,T. GleasonA study of computation speed-ups of the GMM-UBM speaker recognition systemProc. 6th Eurospeech ISCA, 1999, pp. 1215–1218.1999
[35]N. Houmani,S. Garcia-Salicetti,B. Dorizzi,J. Montalvao,J.C. Canuto,M.V. Andrade,Y. Qiao,X. Wang,T. Scheidat,A. Makrushin,D. Muramatsu,J. Putz-Leszczynska,M. Kudelski,M. Faundez-Zanuy,J.M. Pascual-Gaspar,V. Carde noso-Payo,C. Vivaracho-Pascual,E. Argones-Rúa,J.L. Alba-Castro,A. Kholmatov,B. YanikogluBioSecure Signature Evaluation Campaign (ESRA’2011): Evaluating systems on quality-based categories of skilled forgeriesProc. IEEE Int. Joint Conf. Biometrics, Washington, DC, Oct. 2011, pp. 1–10.2011
