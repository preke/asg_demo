Generation of Duplicated Off-Line Signature Images for Verification Systems
Moises Diaz,Miguel A. Ferrer,George S. Eskander


Abstract
Biometric researchers have historically seen signature duplication as a procedure relevant to improving the performance of automatic signature verifiers. Different approaches have been proposed to duplicate dynamic signatures based on the heuristic affine transformation, nonlinear distortion and the kinematic model of the motor system. The literature on static signature duplication is limited and as far as we know based on heuristic affine transforms and does not seem to consider the recent advances in human behavior modeling of neuroscience. This paper tries to fill this gap by proposing a cognitive inspired algorithm to duplicate off-line signatures. The algorithm is based on a set of nonlinear and linear transformations which simulate the human spatial cognitive map and motor system intra-personal variability during the signing process. The duplicator is evaluated by increasing artificially a training sequence and verifying that the performance of four state-of-the-art off-line signature classifiers using two publicly databases have been improved on average as if we had collected three more real signatures.

1 INTRODUCTION
FOR centuries, the handwritten signature has beenaccepted world-wide for the purpose of authentication. Classical applications include the legal validation of documents such as contracts, last wills or testaments, corporative tax statements, financial transfers and so on. It leads forensic scientists, graphologists, neurological practitioners and therapists among others to be interested in the creation and validity of handwritten signatures. This interest is manifested in many publications and surveys [1], [2], [3], [4], [5], [6], [7], [8] published in the literature during previous decades. However, modeling its intra-personal variability is still an open challengewhich has caught the attention of researchers on pattern recognition andmachine intelligence.
It is important to understand intra-personal variability of the signatures of a signer. Its modeling allows the widening of the distinction between genuine and non-genuine signatures. The generation of duplicated specimens with realistic appearance helps in gaining a better understanding of signature execution from several neuroscientific perspectives. This also supports coherent decision making in psychology and forensic science and assists in optimizing speed and performance for indexing purposes.
This paper is focused onmodeling intra-personal variability for duplicating static signatures. In this context, duplicating a signature means generating artificially a new specimen from a real or several real signatures. Among its advantages, signature duplication can improve the training of ASV systems, allows the carrying out of statistically meaningful evaluations, enlarges the number of signatures in databases, can match the baseline performances for real signatures, which are often difficult to obtain, and can improve the performances of existing automatic signature verifiers.
According to the literature, there are three methods of signature duplication: iÞ the creation of dynamic (on-line) signatures by using real on-line samples (On-2-On); iiÞ the creation of static (off-line) signatures by using dynamic specimens (On-2-Off) and iiiÞ the production of signature images (off-line) from static signatures (Off-2-Off). Note that on-line signature generation from off-line specimens (Off-2On) remains to the best of our knowledge an open issue.
Most of the recent advances in modeling intra-personal variability are focused on on-line signatures. For this category of signature capture we can find how, by applying random and affine deformations, it is possible to improve the performance of an HMM-based classifier [12]. In [13] another method is studied for increasing the training set on the basis of a clonal selection of the enrolled signatures without modifying either the diversity of the overall set or the sparse feature distribution. Also, in Diaz et al. [14], the kinematic theory of rapid movement is applied to enlarge the enrolled signature data set. Furthermore, the resultant set has been used for testing purposes in [9].
There are other proposals in the literature focused on the generation of signature images from on-line signatures [11], [15], [16], [17], [19]. The common tendency is to apply different methods to dynamic signatures since these record the kinematic and the timing order in which the traces are registered. Once a new trajectory is obtained, the samples of the new specimen are interpolated in order to create new images. Then, an off-line automatic classifier is used to assess the performance improvement. Parallel to this approach, a method of generating enhanced synthetic signatures images has been formulated using a novel architecture to improve the performance of dynamic verifiers [18].
In our review of previous work, we have found little on duplication from off-line to off-line signatures. One example is in [10] where an off-line signature dataset composed of 6 genuine specimens per user and 38 signers is enlarged by applying affine transformations to the original signatures. Since the database contained only genuine signatures, this study was focused only on recognition. The authors did not include the deliberate forgery test. Although the authors enlarged the training set, the paper scarcely addressed either how the duplicated signatures were constructed or gave reference to the cognitive signing procedure.
In order to locate in the current literature the work we report here, Table 1 summarizes schematically the state-ofthe-art in duplicated signature generation. This analysis reveals the need for more research in duplicating off-line signatures from off-line real signatures.
As well as covering geometrical and affine image deformations, the work reported in this paper is addressed at filling the gap between heuristic methods used for off-line signature duplication and methods for intra-personal variability modeling. The techniques we develop are based on human behavior, as examined by neuroscience. Specifically, a duplication procedure is proposed on the basis of modeling neuromotor equivalence theory [20], which divides human action into effector dependent and effector independent parts of the signing procedure. Note that we do not pretend to model human behavior as neuroscience does: we simply use ideas from neuroscience to generate signature duplicates. Our results are encouraging.
The realism of the intra-personal variability model is evaluated by increasing a training sequence with duplicates and ascertaining the improvement in performance of four different state-of-the-art generative classifiers. So as to consider as many aspects of the variability as possible, we have chosen verifiers which are based on different features and classifiers. Additionally, we have used two different public datasets. The improved performance after training with the enlarged set is discussed as well as the complementary information contained in data produced by the cognitive inspired duplication algorithm.
The reminder of this paper has the following organization. Section 2 surveys the cognitive ideas used to design our method which is the algorithm detailed in Section 3. Section 4 describes the method used to evaluate the duplicator, while Sections 5 and 6 present the results and conclusions respectively.

2 COGNITIVE INSPIRED MODEL
In this section, the equivalence model is introduced along with our duplication model. Around the middle of the last century, Lashley [21], then Hebb [22] and later Bernstein [23] formulated the motor equivalence theory. This was studied from a musculo-skeletal viewpoint by focusing on central nervous system (CNS) activity used to control posture and movement. Such a theory deals with the ability of the relevant effectors to generate arm and wrist movement.
As in [20], [24], [25], the generation of the handwritten signature can be divided into two main effectors which are active in the brain: the effector dependent cognitive level and effector independent motor level. It is well known that signing requires highly complex, fine motor control and cognitive skills to generate the signature. However, once learnt, signing soon becomes an automatic and effortless process. In [26] such ability is attributed to an inverse model of the subject being controlled by motor learning. Additionally, previous to its execution, the movement is designed by
TABLE 1 State-of-the-Art on Duplicated Signature Generation
Authors Methods Conversion Seed Target
Munich and Perona, 2003 [9] On-2-On > 1 Sign. Statistically meaningful evaluation Frias et al.1, 2006 [10] Affine-scale/geometrical Off-2-Off 1 Sign. Enlarge database Rabasse et al., 2008 [11] transformations On-2-Off 2 Sign. Approaching the baseline performance Galbally et al., 2009 [12] On-2-On 1 Sign. Improve the performance
Song and Sun, 2014 [13] Clonal Selection Algorithm On-2-On > 1 Sign. Improve the performance
Diaz et al., 2015 [14] Kinematic Theory On-2-On 1 Sign. Improve the performance
Ferrer et al., 2013 [15] On-2-Off 1 Sign. Approaching the baseline performance Guest et al., 2014 [16] Interpolation On-2-Off 1 Sign. Approaching the baseline performance Diaz-Cabrera et al., 2014 [17] methods On-2-Off 1 Sign. Approaching the baseline performance Galbally et al., 2015 [18] On-2-Off 1 Sign. Approaching the baseline performance Diaz-Cabrera et al.2, 2014 [19] Cognitive Inspired Model On-2-Off 1 Sign. Improve the performance
This method, 2015 Cognitive Inspired Model Off-2-Off 1 Sign. Improve the performance Open Issue, ? ? Off-2-On3 1 Sign. ?
(On-2-On = From real on-line to duplicated on-line signature; On-2-Off = From real on-line to duplicated off-line signature; Off-2-Off = From real off-line to duplicated off-line signature;Off-2-On = From real off-line to duplicated on-line signature) 1This paper is focused on two classifiers. However, how much the duplicates improve the performance has not been as fully studied as the effects of a higher number of signatures in the database. 2Because the real signatures were on-line, temporal signature execution was understood. 3To the best of the authors’ knowledge, this problem has not yet been examined in the scientific literature.
a determined spatial position of each handwritten component and its relative position. In practice, this might be considered as an action plan that links target points. After Hafting et al. [27], the target points are considered to be nodes belonging to an hexagonal grid.
Although both effectors are fairly stable, they have a certain degree of variability besides being affected by external inputs and internal, psychological conditions. In fact, under pressure, an individual usually needs to recall the shape of his/her signature before and during signing, and this leads to producing specimens with unusual variability.
On the cognitive level variability, it is proposed that human spatial orientation is represented by a hexagonal grid spanned in the space occupied. Because the grid is not rigid, each of its nodes change slightly every time it is traversed [27] in conducting a signature. In the case of a signature, this deformation depends on the stroke direction and speed at every grid node, i.e., the velocity vector. This variability can be altered as a consequence of psychiatric diseases and with aging.
On the motor level variability, it may be considered as a general motor command that a signer tries to follow through the cognitive grid map. Driven by the muscular path reaction, this effect aims the signature’s ballistic trajectory at a different position among its repetitions according to individual muscle activity. It can be also interpreted from the kinematic theory point of view [28] as various agonist or antagonist strokes increasing or decreasing their amplitudes.
The novelty of our paper relies on the design of a signature duplicator, inspired by this theory. The intention is to provide a better human-like intra-personal variability than other duplicators [11], [15], [16], [17], [18], [19]. On the one hand, the cognitive level variability is approached inspired on the grid deformations. Among the different grid deformation patterns in the literature, we selected the sinusoidal one which has been successfully applied in CAPTCHA generation [29]. While this deformation enlarges some strokes, others are shortened. When the concept of sinusoidal deformation is applied to an hexagonal grid, the result is a new grid similar to that represented at Fig. 1. This concept enables the generation of intra-personal variability, which involves all signature components, without reconstructing the trajectory. This is also known as intra-component variability.
On the other hand, it could be said that the effector independent deals mainly with the dynamic aspects of the handwriting. Certainly, to estimate the pseudo-dynamic information needed to make the handwritten trajectories is a classic challenge [30]. Different approaches have been used to address this problem, e.g., the application of specialized pens [31], [32], recovering the skeleton of the handwriting by thinning the trajectories with 1-pixel width images [33], [34],
calculating the contour to study the critical parts, such as the loops [35], [36] or even estimating the stroke order by using hierarchical reconstruction [37]. Nevertheless, the problem is still an open challenge in handwriting.
Because of both the cognitive grid deformation and different values for the motor arm inertia, caused by the pose, wearing of different clothes, jewelry, etc., changes are produced in the relation between different non connected components. These are the positions of the pen before and after a pen-up. As the images do not contain the pen-up trajectories, this kind of variability is dealt with by labeling the different unconnected signature components in the image. This applies to all individuals and is a way of taking into account the pen-up variability from sample to sample. This further variability in our model is the so called inter-component variability.
A certain degree of inclination occurs in the repetitions of the signatures. Often this is related to the pose, the way the paper is located or how the pen is held, etc. Thus, the final stage of the duplicator introduces a skew modification to the signature.
We should make it clear that we are not modeling brain function or motor activity. We use our interpretation of motor equivalence to inspire the design of the algorithm and thus to improve the intra-personal variability models.

3 GENERATION OF DUPLICATED OFF-LINE SIGNATURES FROM REAL OFF-LINE SIGNATURES
This section describes the duplicator algorithm steps, which are listed as follows: signature segmentation, intra-component variability, component labeling, inter-component variability and signature inclination. A general overview of this duplicator is depicted in Fig. 2, and its main steps are formalized in Algorithm 1.
Algorithm 1. The Cognitive Inspired Duplicator
Input: Iinðx; yÞ, a grayscale original signature image. Output: Idupðx; yÞ, a grayscale duplicated signature image. 1: " Signature Segmentation. 2: IP ðx; yÞ SigSegfIinðx; yÞg 3: " Intra-Component Variability 4: ISðxs; ysÞ IntraCVfIP ðx; yÞ; ½aminA ;amaxA ;aminP ; . . .
amaxP ;a min S ;a max S g
5: " Component Labeling 6: fIiðx; yÞgLi¼1 ISðxs; ysÞ 7: " Inter-Component Variability 8: Idisðx; yÞ InterCVffIiðx; yÞgLi¼1; ½ð 1x; s1x;m1xÞ; . . .
ð 2x; s2x;m2xÞ; ð 3x; s3x;m3xÞ; ð 1y; s1y;m1yÞ; ð 2y; s2y;m2yÞ; . . . ð 3y; s3y;m3yÞ; k1; k2; gT ;c g
9: " Signature Inclination 10: Idupðx; yÞ SigIncfIdisðx; yÞ; ½ S; sS;mS g

3.1 Signature Segmentation
Let Iðx; yÞ be the 256-level gray scale signature image input to the duplicator. The segmentation process is performed to remove the background from the scanned images. A simple thresholding operation is applied [38] to obtain a binary image Ibwðx; yÞ. Because this image still contains noise, careful
Fig. 1. Hexagonal cell unit distortion with sinusoidal transformation. Original grid on the left and distorted one on the right.
processing is carried out to remove it [39]. The resulting image is used as a mask to remove the background and segment the original inked signature. Next, the canvas size is processed by cropping the white borders of the image thus obtaining the preprocessed image IP ðx; yÞ according toAlgorithm 2.
Algorithm 2. Border Cropped Procedure
Function: Iðx̂; ŷÞ BorderCropfIðx; yÞg 1: Ibwðx; yÞ im2bwfIðx; yÞg "Binary image 2: h sumfIbwðx; yÞg "horizontal pixel distribution 3: i findfh > 0g 4: Ibwðx; ŷÞ Ibwðx; i Þ 5: Iðx; ŷÞ Iðx; i Þ 6: v sumfIbwðx; ŷÞTg "vertical pixel distribution 7: j findfv > 0g 8: Iðx̂; ŷÞ Iðj ; ŷÞ

3.2 Intra-Component Variability
The intra-component variability is introduced by a piecewise sine wave function. Let IP ðx; yÞ be a segmented gray scale signature whose canvas size is defined by M columns and N rows. A sinusoidal transformation is applied to the rows and columns of the image according to equation (1) to obtain ISðxs; ysÞ,
xs ¼ xþAx sin vxxþ ’xð Þ ys ¼ yþAy sin vyyþ ’y :
(1)
Where the parameters of the sine wave are defined as follows: iÞ The sinusoidal amplitudes are calculated for both coordinates:Ax ¼M=aA andAy ¼ N=aA, where aA is a factor which follows a uniform distribution UðaminA ; amaxA Þ. iiÞ The angular frequencies are obtained through the oscillation period vx ¼ 2p=tx and vy ¼ 2p=ty. iiiÞA certain variability is added to the period similar to the amplitude: tx ¼M=aP and ty ¼ N=aP . In the same way, the parameter aP follows a uniform distribution UðaminP ; amaxP Þ. ivÞ Finally, the phase is defined by: ’ ¼ 2paS , where aS follows a uniform distributionUðaminS ; amaxS Þ. Accordingly, we compute ’x and ’y.
Algorithm 3 calculates this intra-component variability distortion.
Algorithm 3. Intra-component Variability
Function: ISðxs; ysÞ IntraCVfIP ðx; yÞ; ½aminA ;amaxA ; . . . aminP ;a max P ;a min S ;a max S g
1: " Let fM;Ng be the rows and columns of IP ðx; yÞ 2: " Let fP;Qg be the rows and columns of ISðxs; ysÞ 3: " Random parameter selection 4: aA UðaminA ; amaxA Þ; Ax M=aA 5: aA UðaminA ; amaxA Þ; Ay N=aA 6: aP UðaminP ; amaxP Þ; tx M=aP ; vx 2p=tx 7: aP UðaminP ; amaxP Þ; ty N=aP ; vy 2p=ty 8: aS UðaminS ; amaxS Þ; ’x 2paS 9: aS UðaminS ; amaxS Þ; ’y 2paS 10: "Building the distorted image 11: xs xþAx sin vxxþ ’xð Þ 12: ys yþAy sin vyyþ ’y 13: for i 0 to i ðP 1Þ do 14: for j 0 to j ðQ 1Þ do 15: if ð0 xi P 1Þ ^ ð0 yi Q 1Þ then 16: ISðxsi ; ysjÞ IP ðxi; yjÞ 17: else 18: ISðxsi ; ysjÞ 1 19: end if 20: end for 21: end for
Visual details of this transformation on the word da are shown in Fig. 3. Several sinusoidal transformation parameters distort the inked image producing different duplications. The figure illustrates how the intra-component relationship is modified.

3.3 Component Labeling
In this step each connected area is separately labeled [40] in the binary image. Starting with the first detected pixel, the algorithm searches for all 8-connected areas. Using the information in each label, an enclosing box is built for each isolated, inked component. Fig. 4 shows different detected
components in different handwriting signatures. In some examples it is possible to see that the flourish is merged with the text. In such cases, a large area of the signature is detected as one component (see Figs. 4c or 4d, among others). This stage allows the generation of a set of L individual images fIiðx; yÞgLi¼1 from each labeled component of the image ISðxs; ysÞ.

3.4 Inter-Component Variability
The inter-component variability is dealt with by applying different horizontal and vertical independent displacements to each labeled component. In an ideal case, each labeled component represents an inked trace from a pen tip which touches the paper until it is lifted up. This section assumes that the larger the component ratio, the more rapidly the component was drawn and that eventually it will be subjected to more inter-component variability. Fig. 4 reveals that many components are not correctly labeled mainly because their flourishes are drawn over many letters. Although this could introduce certain errors in classification in signatures with a prominent flourish, this classification has been used in the algorithm for convenience [19]. Additionally, for signatures with small or without a flourish at all, this stage still introduces personal variability to the duplicates (see Figs. 4f and 4j).
Let us define a sequence of labeled images fIiðx; yÞgLi¼1 where each image represents each detected component. The new image Idis with the displaced component is computed as:
Idisðx; yÞ ¼ XL i¼1 Iiðxþ dxi ; yþ dyiÞ: (2)
Three kinds of section were identified for each of the horizontal and vertical coordinates, which are delimited by k. Thus, the displacement of each component ðdx; dyÞ is worked out as follows:
dx ¼ gevrndf 1x; s1x;m1xg if Gi < k1 gevrndf 2x; s2x;m2xg if k1 Gi < k2 gevrndf 3x; s3x;m3xg if Gi k2
8< : (3)
dy ¼ gevrndf 1y; s1y;m1yg if Gi < k1 gevrndf 2y; s2y;m2yg if k1 Gi < k2 gevrndf 3y; s3y;m3yg if Gi k2: 8>< >: (4)
To categorize each component, a ratio is calculated per component: Gi ¼ gi=gT . This ratio denotes the relationship
between the number of pixels in each individual component gi and the total number of inked pixels gT in ISðxs; ysÞ. These displacements are obtained by pseudo-random values drawn from a Generalized Extreme Value (GEV) distribution [41]. In the algorithms illustrated, we have indicated its use with a function named gevrnd whose inputs are the parameters defined by such a distribution.
Algorithm 4. Inter-component Variability
Function: Idisðx; yÞ InterCVffIiðx; yÞgLi¼1; ½ð 1x; s1x;m1xÞ; . . . ð 2x; s2x;m2xÞ; ð 3x; s3x;m3xÞ; ð 1y; s1y;m1yÞ; ð 2y; s2y;m2yÞ; . . . ð 3y; s3y;m3yÞ; k1; k2; gT ;c g 1: Idisðx; yÞ I1ðx; yÞ 2: for i 2 to i L do 3: gi " The total inked pixels of the component i 4: Gi gi=gT 5: if Gi < k1 then 6: dx gevrndf 1x; s1x;m1xg dy gevrndf 1y; s1y;m1yg 7: else 8: if k1 Gi < k2 then 9:
dx gevrndf 2x; s2x;m2xg dy gevrndf 2y; s2y;m2yg
10: else 11: dx gevrndf 3x; s3x;m3xg dy gevrndf 3y; s3y;m3yg 12: end if 13: end if 14: A Idisðx; yÞ; B Iiðxþ dx; yþ dyÞ; 15: C ¼ ðA n BÞ [ ðB nAÞ "Symmetric difference 16: D ¼ A \B "Intersection 17: Dbw im2bwfDg 18: E ¼ A Dbw cþB Dbw ð1 cÞ 19: Idisðx; yÞ C [ E "Union 20: end for
This kind of distribution is traditionally used for modeling extremes of natural phenomena such as waves, winds, temperatures, earthquakes, floods, etc. Additionally, its use has been previously studied in handwriting signature modeling [42], and offers a higher flexibility with respect to other distributions such as the Gaussian or Normal distribution. The GEV distribution is parameterized according to f ki ; ski ;mki g which represent the location, scale and shape distribution parameters respectively, where i represents the horizontal or vertical coordinates and k the different sections. More formally, let x be an independent variable. Its
density function is:
fðx;m; s; Þ ¼ 1 s 1þ x m s 1 1e 1þ x msð Þ½ 1 : (5) After the displacement, the summation of individual images over Idis could overlap certain pixels of two or more individual images. In real handwriting, a similar effect of ink summation is noted in crossed over traces. If there are such crossovers, to obtain the gray scale values in the relevant pixels, two steps are taken: Step 1:One of the individual components is randomly chosen to be the first drawn trace and the second is summed to make the new image. Step 2: For only the crossed traces, a simple blending factor c is worked out to mimic the effect of having two overlapped traces.
If any pixel is not overlapped, step 2 is omitted during the summation of the two relevant individual Ii images. We formalized this stage using simple concepts in set theory, along with the inter-component variability stage in Algorithm 4. Finally, an extra stage to introduce variability is generated to thewhole image, it is explain in the next section.

3.5 Signature Inclination Modification
The signatures can be written in an ascendant, descendent or longitudinal manner. This inclination is the so called skew. Ref. [42] studies the skew of signatures from different signers (inter-personal variability). Here, we focus on the signature inclination of each signer and how it varies from the average signature inclination (intra-personal variability). The procedure to measure this intra-personal distribution is as follows: Let N be a set of genuine signatures from a signer. The skew with respect to the horizontal is measured for each specimen ri. Then, the user’s average inclination is computed to finally obtain the difference ðr̂iÞ between each individual value and its average,
r̂i ¼ 1
N XN i¼1 ri
! ri: (6)
When the inclination dispersion is calculated forN signers, a global Probability Density Function (pdf) is estimated by the histogram non-parametric method. Accordingly, a Generalized ExtremeValue distribution has been used to approximate themeasured pdfwith the parameters ½ S; sS;mS .
This stage is summarized in Algorithm 5. Due to the fact that the skew of the signature introduces personal
variability in the set of genuine signatures, each image has been rotated a certain angle calculated using a GEV distribution. Again, the image borders are cropped to remove the white pixels at the edges of the signature. At the end of this stage, a duplicated signature Idupðx; yÞ is obtained. Algorithm 5. Signature Inclination Algorithm
Function: Idupðx; yÞ SigIncfIdisðx; yÞ; ½ S; sS;mS g 1: M gevrndf S; sS;mSg 2: Irotðx; yÞ imrotatefIdisðx; yÞ;Mg 3: Idupðx; yÞ BorderCropfIrotðx; yÞg
As a final example, Fig. 5 illustrates the effect of each stage in an off-line signature.

4 EVALUATION METHODOLOGY
One way of evaluating whether the duplicator produces signatures with human-like variability, is to process the training samples in an automatic signature verifier (ASV) and look for performance improvement. In the training stage, theASV tries to model the signer’s signature and its variability. The accuracy of this model is evaluated in the testing phase. The more information provided to the ASV, the better its performance will be. Therefore, anASV trainedwith the original signatures plus their duplicateswill improve the performance in the testing phase if, and only if, the duplicator generates duplicated signature with similar variability to the genuine users. The performance comparison will be analyzed and it is expected to be much more competitive by using the proposed novel scheme. Fig. 6 summarizes the evaluation methodology, highlighting the performance comparison between the cognitive-inspired duplicationmodel and the traditional one.
This procedure is conducted with two off-line signature databases, namely the GPDS-300 [43] and MCYT-75 [44] alongwith four published state-of-the-art-ASVs so as to avoid biased results and to obtain more consistent and general conclusions. Specifically, System A [45] works with geometrical features and Hidden Markov Models (HMM); System B [46] employs the Boosting Feature Selection (BFS) approach and single grid-based features; System C [39] is a Support Vector Matching (SVM) classifier with texture features; and System D [47], which is a third-party system, uses pose-orientated grid features and an SVM.
Signature verification systems are designed to be effective in two specific tests: the random forgery test and the
deliberate forgery test. The random forgery test is applied in the situation in which an impostor, without previous knowledge of a specific signature, tries to verify the identity of a signer by using his own genuine signature. The random forgery test is a typical test used in access control and commercial transactions. Conversely, the deliberate forgery test simulates the case where an impostor learns the signature of a signer and tries to reproduce it with a similar intra-class variability. This test is the most relevant in signature verification for its impact in forensic applications in signature forgery detection.
For the training, different strategies have been carried out. In this work, the training set consists of the first two, the first five and first eight real genuine signatures. As such, for each strategy, we have added the duplicated signatures to the training. For instances, let 5 be the number of the first real signatures enrolled in the system. We have trained with these five real signatures plus 0, 1, 5, 10 and 20 duplicated signatures, obtained from each individual real enrolled specimen.
To test the GPDS-300 database, we used from the ninth to the 23rd genuine signature for all cases, i.e., 15 signatures per user in total. So as to do a fair comparison, we used the identical test in all experiments. For the MCYT, the testing set is composed of seven signatures: from the ninth to the 15th. This way, the false rejection rate (FRR) is calculated with 15 300 = 4,500 scores for GPDS-300 and 7 75=525 scores forMCYT-75.
For the random forgery test, we have selected the first testing signature of other users, i.e., the signature number nine according to the database nomenclature. We compute the false acceptance rate (FAR) with 1 (300-1) 300 = 89,700 scores for GPDS-300 and 1 (75-1) 75 = 5,550 scores for MCYT-75. For the deliberate forgery test, all deliberately forged signatures in the databases were used. Therefore, we compute the false acceptation rate using 30 300 = 9,000 scores for GPDS300 and 15 75 = 1,125 scores for MCYT-75. We note that the deliberately forged signatures are never used for training.
To study the efficiency of the duplicated signatures in these biometric verification systems, two classical types of errors were evaluated: Type I error or FRR to measure the rejection of authentic signatures and type II or FAR, which evaluates the acceptance of a forgery. To assess the systems with a commonmetric, the results are given in terms of Equal Error Rate (EER) as well as Area Under Curve (AUC) since these represent the operative point when the error type I and
II are coincident. In thiswork, we compensate for unbalanced classes, by using the method in [48], [49] which estimates the threshold for each class separately. Finally, in order to show how the system thresholds are varied according to the performance of the classifiers, we have illustrated some receiver operating characteristic (ROC) curves in graphical form.

5 RESULTS AND DISCUSSION
5.1 Cognitive Inspired Duplicator Set Up
Setting up the duplicator algorithms requires optimization of their parameters. Therefore a development dataset and ASV are required. To avoid adjusting the data, this is conducted on a subset of one of the two training databases and with one of the four ASVs. Specifically, the development set is composed of the first five samples of the first 150 users of the GPDS-300. This is used to train the System C which is based on texture features followed by applying a Support Vector Machine ASV.
The parameters were heuristically optimized in a trial and error procedure in three steps. First, initial values were given to each parameter in order to produce the desired distortion effect; second, a coarse tuning of the parameters by a perceptual evaluation of the results was conducted; and third, a fine-tuning of the parameters to produce the best performancewith the abovementionedASVwas undertaken.
On intra-component variability, incorrect selection of a parameter could produce an unnatural handwriting image. Because aA is inversely proportional to the amplitude, while large values do not produce any effect because the amplitude results are close to 0, lower valueswould produce rectangular traces if aP and aS were 1 and 0, respectively. In the case that the amplitude is near to one, and the sinusoidal phase is null, large values in aP create highly sinusoidal images that are not human-like. Nevertheless a combination of them in the correct range produces acceptable human-like results. As example of writing style modification is illustrated in Fig. 7. The correct parameter combinations are highlighted with a tick whereas unnatural looking signatures are shown by a cross.
On the inter-component variability, too much deformation displays strange effects in the text. Specifically, an extra large value for dx can change the order of the text: for instance, the original name “Peter” could be converted to “Peert”. Thus, an excessive deformation in vertical
Fig. 6. Procedure to evaluate the human-like variability of the duplicator. Following the novel scheme branch, performance in B is expected to be better than performance in A.
displacement dy yields an unnatural order of the letters in the vertical direction. These effects are observed in Fig. 7b. Also, the inter-component variability becomes too sensitive to the size of the image. Therefore, it became necessary to fix a location parameter . Because the natural variation in vertical displacement is usually positive, was fixed at 0.5 in order to bring the center of mass of the distribution back to the lower position. Because the scale s controls the opening of the range of possible values, it is incremented according to the kind of sector it is in, thus giving more variability to most inked components. Finally, the parameter m moves the distribution without changing the shape. Experimentally, this parameter is related to the scale for natural writing and to the relationship between sections. The sections were then divided into equal ranges, k1 and k2, and c was visually fixed at 0.8 to account for the natural effect of the ink.
Table 2 shows the parameters and their range used in this work. Finally, we can visualize the natural writing style obtained through ourmodel in Fig. 8. In this case a set of five possible duplicates are generated fromonly one original signature.
The computational time needed to generate a duplicated signature from a real image is on average less than 4 s although this depends on the size of input image. This time is calculated using the duplicator on a regular PC Ubuntu 12.04 LTS with with Intel CoreTMi7-3770 CPU @ 3.40 GHz with 15.6 Gb RAM memory. The signature duplicator has been made publicly available for research purposes at www.gpds.ulpgc.es.

5.2 Impact of Adding Duplicated Generated Signatures as Training
The aim of this experiment is to ascertain whether our duplicated signatures present a human-like variability through the complementarity between them and the signatures used to generate them. Accordingly, we have trained different classifiers without duplicates, with duplicates and with the same number of real signatures. Also the test used is identical in all
cases. The goal is to determine the ability of the cognitive approach to generate samples with complementary information about the signature owner, especially in critical conditionswhen only a few signatures for training are available.
The essential part of this section focuses on demonstrating that the progressive addition of duplicated signatures to a training set improves the system performance, highlighting the cognitive-based signature duplicator’s capability of working out human-like variability in signature verification. This concrete finding has been demonstrated by testing two off-line publicly available databases and four state-of-theart off-line signature verifiers, as is mentioned in Section 4. Tables 3 and 4 analyze the resulting performance, both in terms of Equal Error Rate and Area Under Curve.
“GPDS-300 and System A”. We could observe the same tendency in both random and deliberate forgery tests: the more duplicates we use, the better the results. This highlights the potential of the duplicated signatures in both tests, but the biggest improvement is for deliberate forgeries.
“GPDS-300 and System B”. Excellent improvements in the verification rates are achieved, especially in the case where we have few signatures to train the model and for deliberate forgeries. Note that, the deliberate forgery test is the most critical one for ASV systems. Hence these results highlight the potential of this duplicator for security or forensic applications. Moreover, it is worth taking into consideration how close the performance of 5 R + 20 D/R is to that for 8 R + 0 D/R, which suggest that the duplicates are equivalent to three real signatures.
“GPDS-300 and System C”. This case confirms the hypothesis that for whatever traditional training set, the GPDS database provides a significant improvement in performance. Again, the most significant improvements are observedwhen the trainingmodels have a few signatures. But it is relevant to say that although we use eight real signatures to train it, the cognitive model itself still benefits in all cases from additional information. Moreover, it is observed that this method is able to achieve a promising performance with only eight real signatures.
TABLE 2 Configuration of the Duplicator Parameters
Intra-Component Variability
aminA ¼ 5 amaxA ¼ 30 aminP ¼ 0:5 amaxP ¼ 1 aminS ¼ 0 amaxS ¼ 1
Inter-Component Variability
f 1x; s1x;m1xg ¼ f 0:5; 20; 2 s1xg f 2x; s2x;m2xg ¼ f 0:5; 1:4 s1x; 2 1:4 s1xg f 3x; s3x;m3xg ¼ f 0:5; 1:8 s1x; 2 1:8 s1xg f 1y; s1y;m1yg ¼ f 0:5; 8; s1yg f 2y; s2y;m2yg ¼ f 0:5; 1:2 s1y; 1:2 s1yg f 3y; s3y;m3yg ¼ f 0:5; 1:5 s1y; 1:5 s1yg k1 ¼ 0:33 k2 ¼ 0:67 c ¼ 0:8
Signature Inclination
S ¼ 0:19 sS ¼ 3:28 mS ¼ 1:30
“GPDS-300 and System D”. The robustness of our duplicating procedure is successfully proved with this fourth system since it was not designed by the authors of this article. The relevant improvement with the three different training sets confirms the utility of the cognitive duplication method to outperform the traditional method. The most relevant effect is observed in the case of two real enrolled signatures, where the performance improvement is five 5 percent for the random forgery test.
In Fig. 9, we show, as an example for a model composed of five real signatures, the two errors (FAR and FRR) in a ROC plot for each system and each test. This curve shows the real behavior in all operative points. The general observation in the middle case of five real signatures again demonstrates how the improvement is not only at the operational point, but at all points of the ROC curves.
Similar findings can be assessed in Table 4 for MCYT: “MCYT-75 and System A”. The most notable improvements are for the training set with two real signatures for the random forgery test and for five real ones for the deliberate forgery test, duplicating at 20 times per real enrolled specimen. The table in this case shows consistent results which verify the targeted goal.
“MCYT-75 and System B”. Excellent results are observed here. We could highlight the effect in the random forgery test where both the EER and AUC indicate the maximum performance for five real signatures. An anomaly in our results occurs at an outlier which produces a strange performance (EER=0.19 %) in the random forgery test with 5 R + 10 D/R. As we said in Section 4, the FRR error is computed with 525 scores. Failure here implies a value of 1=525 ¼ 0:0019 (or 0.19 percent). Such a value in the table indicates that only one genuine signature was incorrectly classified. Note that, statistically speaking, this inconsistency is irrelevant to the impact of the duplicator so we do not need to adjust our conclusions. Moreover, the most relevant improvement is due to the training set with two real enrolled samples. It highlights the convenience of this method in criminology and forensics, where only one or two genuine samples may be available. In this case, we can observe for deliberate forgeries—the most difficult and relevant test—the notable improvement when only two real signatures are enrolled.
“MCYT-75 and System C”. Again, this system tends to reinforce the hypothesis that the proposed duplicator is robust enough to categorize the intra-personal variability. It is worth pointing out that under experimental conditions, using an objectively fair protocol, impressive performance is achieved with 5 R + 20 D/R of the deliberate forgeries.
“MCYT-75 and System D”. The potential of the cognitive method is demonstrated with this system. The best impact is achieved with deliberate forgeries using only two real signatures in the training set whereas the minimum impact is observed when the performance is still quite competitive, as in the case of eight real enrolled signatures in the random forgeries test.
Graphically, the case of five real enrolled signatures is summarized at Fig. 10 using a ROC plot. Beyond the operative points, once again, we can see the significant and consistent improvement in all cases.
These experiments attempt to validate the robustness of our verifier for experiments in respect to each database where, at zero human cost and in all assessed conditions, the duplicator outperforms the baseline. As general
TABLE 3 Equal Error Rate (First) and Area Under Curve (Second) Results in % for the GPDS-300 Off-Line Signature DB for Four Validations
Training Random Forgery Deliberate Forgery

R D/R System A System B System C System D System A System B System C System D
2 0 8.30–97.13 17.10–92.20 2.84–99.58 8.88–96.98 34.34–71.30 34.19–72.28 24.86–82.74 28.87–78.24 2 1 8.42–96.91 13.12–95.23 2.59–99.64 7.53–97.58 33.62–71.88 31.80–74.19 25.11–82.69 29.42–78.11 2 5 7.63–97.25 9.71–97.10 1.90–99.79 4.65–98.95 33.55–71.73 29.20–77.37 23.70–84.16 26.88–80.64 2 10 7.10–97.59 8.63–97.48 1.69–99.84 4.22–99.16 33.05–72.30 28.67–77.92 22.68–85.32 25.73–81.74 2 20 6.25–97.87 8.04–97.75 1.43–99.88 3.81–99.30 32.01–73.67 28.55–78.12 21.63–86.46 25.95–82.06 5 0 4.95–98.63 5.58–98.92 0.92–99.93 4.38–99.04 29.37–76.78 25.57–82.05 20.91–86.95 24.69–82.64 5 1 5.29–98.64 4.09–99.36 0.75–99.95 3.42–99.31 30.61–75.88 24.91–82.87 19.99–87.66 24.36–83.50 5 5 4.41–98.87 3.01–99.56 0.54–99.98 2.41–99.60 28.58–77.77 24.19–83.29 18.98–88.73 23.25–84.93 5 10 4.23–98.89 2.76–99.61 0.48–99.98 2.19–99.68 28.60–77.51 23.82–83.61 17.98–89.70 22.90–84.91 5 20 4.16–99.00 2.64–99.64 0.36–99.98 1.83–99.73 27.86–78.57 24.04–83.39 17.19–90.39 22.57–85.36 8 0 4.80–98.78 4.01–99.33 0.57–99.97 2.85–99.53 29.03–77.63 23.96–84.10 19.02–88.96 22.16–85.48 8 1 4.85–98.80 3.19–99.57 0.45–99.98 2.65–99.54 28.89–77.96 23.32–84.38 18.21–89.46 22.16–85.81 8 5 4.02–99.00 2.46–99.74 0.29–99.99 2.01–99.65 27.82–78.85 23.54–84.43 16.45–91.29 21.52–86.07 8 10 4.19–99.00 2.29–99.75 0.22–99.99 1.81–99.72 27.10–79.76 23.11–84.51 15.08–92.17 21.60–86.57 8 20 4.28–99.03 2.78–99.62 0.20–99.99 1.34–99.82 26.60–80.29 20.39–87.19 14.58–92.72 19.97–88.08
R means the real enrolled signatures and D/R means the duplicated per real enrolled signatures. The baselines are shaded in gray.
Fig. 9. ROC plots training with the first five real signatures plus the duplicates for GPDS-300.
tendency, our experimental results lead to the conclusion that 20 duplicated specimens have a similar effect, in performance average terms, to three real signatures. In one particular case, in the random forgery test, five real specimens in the training set and System B is equivalent to adding more than five real signatures from both databases.
It should be noted that the feature extraction in each ASV and the classifier are completely different. This explains the different sensitivities in each case. Nevertheless, the sensitivities always have a positive effect on the performance, which sustains the hypothesis that the cognitive inspired method is able to introduce certain intra-class variability to the systems. Actually, the controlled deformation allows us to enlarge and adapt better the model boundaries for each classifier and for each kind of training model.

5.3 Impact on the Performance of the Individual Signers
This experiment aims to quantify how the addition of duplicated signatures affects the performance of an individual user. We thus evaluate the number of users which obtain benefit in performance when duplicated signatures are used as the training set alongside the real ones.
Previous sections suggest that the more duplications we use, the lower is the error rate obtained. Therefore, the
comparison will be conducted with no real duplicates in the model and duplicating 20 times each enrolled signature image. The difference in the performance obtained will indicate how the duplicator affects the individual user’s performance. We have employed the Equal Error Rate metric for this experiment. Thus, the users are arranged in ascending order according to the differences of EER between the performance training with and without duplicates. So, an analysis for each database under the proposed evaluation methodology, as explained in Section 4, is carried out.
“GPDS-300”. The random forgery improvements are over 85 percent in almost all cases, as shown at Fig. 11. It is also noted that Systems B and C achieve the most improved results. Also, the fewer real signatures we include in the training set, the bigger the individual performance increase we obtain. The number of successful users is similar in all cases. It is reasonable to deduce that with two real signatures the improvement will be even greater. In this case, the duplicator model contribution would be more efficient. Additionally, modest but very promising improvements are obtained in the deliberate forgery test. We can see that more than 75 percent of users improve their individual performance. In this test, it is not the findings on the fewer real enrolled images that are important but the performance of the individuals. In these cases, the individual improvement is quite stable, achieving with Systems B and C slightly better improvement than with Systems A and D.
“MCYT-75”. Again, the random forgery appears to offer the best test where the improvement is practically at the maximum per user, especially for Systems B and C, as can be seen in Fig. 12. Moreover, this reinforces the finding that the fewer real signature images enrolled, the higher the proportion of improvement per individual user. Again in the deliberate forgery test, the average performance improvement applies to around of 75 percent of users. System B shares such a finding for random forgery test but this does not apply to Systems A and C.
Finally, Table 5 indicates numerically the proportion of the users which have a higher performance when duplicated signatures are used to train their models. In spite of the fact
Fig. 10. ROC plots training with the first five real signatures plus the duplicates for MCYT-75.
TABLE 4 Equal Error Rate (First) and Area Under Curve (Second) Results in % for the MCYT-75 Off-Line Signature DB for Four Validations
Training Random Forgery Deliberate Forgery

R D/R System A System B System C System D System A System B System C System D
2 0 6.84–97.81 17.42–93.08 1.95–99.77 3.09–99.29 21.40–86.35 34.36–73.04 16.88–89.98 21.15–87.45 2 1 5.31–98.51 7.78–98.39 1.77–99.80 3.44–99.31 22.94–83.83 30.84–76.53 17.90–88.82 20.54–88.28 2 5 3.51–99.22 1.39–99.93 1.69–99.86 2.36–99.58 20.37–86.94 25.20–82.58 17.63–89.67 18.41–89.48 2 10 3.59–99.03 0.17–100.00 1.29–99.92 1.72–99.73 20.09–87.16 24.73–83.74 16.70–90.38 16.88–90.88 2 20 3.05–99.25 0.17–100.00 0.69–99.96 1.11–99.81 19.03–87.86 23.67–84.44 16.06–91.47 16.50–91.50 5 0 3.18–99.11 6.09–99.08 0.81–99.96 1.31–99.81 18.18–90.53 24.26–83.84 14.06–93.25 16.42–91.40 5 1 2.24–99.35 1.81–99.92 0.89–99.95 1.25–99.83 17.17–90.44 20.99–86.41 13.58–93.19 15.71–92.30 5 5 2.01–99.53 0.00–100.00 0.48–99.99 0.81–99.91 16.08–91.50 19.02–88.32 12.44–94.16 15.17–92.63 5 10 2.11–99.56 0.19–100.00 0.22–100.00 0.50–99.94 16.35–91.50 20.15–88.25 11.99–94.82 14.19–93.65 5 20 2.26–99.57 0.00–100.00 0.32–100.00 0.34–99.96 15.27–91.63 16.58–90.09 11.90–95.05 14.02–93.83 8 0 1.78–99.72 1.41–99.93 0.36–99.99 0.37–99.96 13.42–93.50 15.13–92.08 11.05–95.06 12.90–93.49 8 1 1.90–99.72 0.36–99.99 0.25–99.99 0.50–99.96 14.32–93.02 14.62–92.07 11.61–95.45 12.76–94.05 8 5 1.56–99.81 0.19–100.00 0.23–100.00 0.32–99.97 14.34–92.71 14.72–92.24 9.72–96.34 12.43–94.74 8 10 1.20–99.86 0.38–100.00 0.09–100.00 0.31–99.98 13.06–93.73 16.11–91.34 9.78–96.66 12.57–94.69 8 20 1.06–99.90 0.38–100.00 0.14–100.00 0.30–99.98 12.02–94.08 15.26–91.61 9.12–97.01 11.57–94.92
R means the real enrolled signatures and D/R means the duplicated per real enrolled signatures. The baselines are gray.
that the performance of a few users could be degraded, these results suggest that it is more effective to use the proposed cognitive duplicator in signature verification and to produce asmany signatures as our computer resources permit.

5.4 Comparison with Other Duplication Methods
Duplication procedures have been widely used in signature verification to enlarge artificially the training set. While many different proposals have contributed to the state-ofthe-art with on-line signatures, affine transformation is the most popular approach to duplicating the image-based signatures. To compare our cognitive duplication method with the state-of-the-art, we have duplicated the real enrolled signatures with affine transformations according to the method described in [10]. Following the same evaluation methodology described in Section 4, the experiments have been repeated and results are given at Table 6, where each real enrolled signature is duplicated twenty times.
Experimental results show a better performance in all cases for System A. In favor of the cognitive duplicate method, the performance with the affine-basedmethod is less competitive and gets worse than the baseline in some cases. Similar tendencies are observed on system B when random forgeries are
tested, in spite of the fact of exceptional improvements in the affine-based method with GPDS-300. However, the importance of our proposal is highlighted in the deliberate forgery test for both databases. In addition, some confusion seem to be introduced in the deliberate forgery test with the affinebased method, in some cases, since the performance is worse than the baseline. On Systems C and D our method outperforms in all cases except in a few where the affine proposal slightly improves the results. Thus, we can still claim that the intra-personal variability produced in the repetitions of signatures from the same writer has been successfully achieved by cognitive distortion. To conclude this section, we do not pretend to claim that the cognitive perturbations cover all unexpected real intra-personal variability. Although our proposal satisfactorily matches the signature variability, further distortions like the affine-based among others may be considered to be combined for further improvements.

6 CONCLUSION
This paper proposes an off-line signature duplicator based on the cognitively inspired principles of the equivalence model of human motor function. Although some initial
Fig. 11. Users arranged by EER difference improvement for the GPDS-300.
proposals have been published on on-line signatures, to the best of our knowledge this paper presents a novel method for cognitive duplication of off-line signatures.
The most relevant literature suggests that this model can be divided into the effector dependent and effector independent functions. Although they are considered separately, the duplicated signature image integrates the actions of each effector.
The duplication algorithm is based on threemain signature image modifications: First, intra-component modification which applies a sinusoidal distortion to the signature image. This includes both effector independent user cognitive spatial map variability and effector dependent motor variability which is interpreted as modification of the individual pen strokes: i.e., in the individual stroke amplitudes in the case of the on-line signature. Second, inter-component modifications which displace every unconnected component. This variability, besides effector dependent and independent variability, includes some pen-up end point trajectory variability. Finally, inclination modification that incorporates aspects such as different pose, sheet inclination, pen inclination, etc.
Our hypothesis relies on the idea that the duplicated signatures under a cognitive perspective are able to model better the intra-personal variability of a signer. This hypothesis is evaluated by studying the improvement in the performance of off-line signature recognition systems when duplicated specimens are provided to the training set. The results obtained in this work suggest that independently of the
number of real signatures we introduce, the performance of the system improves in all cases when the cognitive-based duplicator is used. As result, signatures from our duplicator consistently improve the performance of four generative classifiers, which were used with their original configuration without being adapted to any dataset. These automatic signature verifiers are completely different among themselves in the type of selected features and in the classifiers employed. Additionally, to generalize our conclusions, the experiments were repeated in two well-known publicly offline signature databases: GPDS-300 and MCYT-75.
The experiments confirm that by using duplicated signatures, alongside the genuine ones, to train the systems, we can improve the global performance of the systems. Moreover, we have examined the performance improvement per user. The results suggest that more than 75 percent of the users benefit from an improvement in performance when a duplicated signature technique is employed. The results suggest that our method retains the signer intra-personal variability, and improves the identification of the user by the classifier and is equivalent to enrolling three more real signatures, in average terms.
Consequently, it could be said that this method is simple, fast, efficient and useful for generative classifiers for effectively zero human effort and at only the cost of machine time. This novel duplicate generator has high potential in signature-based biometric applications, especially in resolving security problems or in cases where only a few
TABLE 6 Equal Error Rate (First) and Area Under Curve (Second) Results in % for Comparison between Affine and Cognitive Duplication Methods for GPDS-300 and MCYT-75 Databases
GPDS-300
Training Random Forgery Deliberate Forgery

R D/R System A System B System C System D System A System B System C System D
2 0 baseline 8.30–97.13 17.10–92.20 2.84–99.58 8.88–96.98 34.34–71.30 34.19–72.28 24.86–82.74 28.87–78.24
2 20 affine 7.57–97.24 5.85–98.74 2.51–99.69 4.17–99.15 33.12–72.57 33.10–73.15 23.22–84.40 25.09–82.94 cognitive 6.25–97.87 8.04–97.75 1.43–99.88 3.53–99.31 32.01–73.67 28.55–78.12 21.63–86.46 25.01–82.71 5 0 baseline 4.95–98.63 5.58–98.92 0.92–99.93 4.38–99.04 29.37–76.78 25.57–82.05 20.91–86.95 24.69–82.64
5 20 affine 5.67–98.42 1.50–99.86 0.89–99.94 2.21–99.67 29.99–75.95 28.69–77.72 19.76–88.13 21.34–86.72 cognitive 4.16–99.00 2.64–99.64 0.36–99.98 1.67–99.78 27.86–78.57 24.04–83.39 17.19–90.39 21.68–86.62 8 0 baseline 4.80–98.78 4.01–99.33 0.57–99.97 2.85–99.53 29.03–77.63 23.96–84.10 19.02–88.96 22.16–85.48 8 20 affine 5.04–98.77 1.41–99.89 0.62–99.96 1.54–99.81 28.28–78.74 28.03–78.72 17.42–90.51 19.11–88.76
cognitive 4.28–99.03 2.78–99.62 0.20–99.99 1.04–99.89 26.60–80.29 20.39–87.19 14.58–92.72 18.66–89.07
MCYT-75
Training Random Forgery Deliberate Forgery

R D/R System A System B System C System D System A System B System C System D
2 0 baseline 6.84–97.81 17.42–93.08 1.95–99.77 3.09–99.29 21.40–86.35 34.36–73.04 16.88–89.98 21.15–87.45
2 20 affine 5.15–98.31 1.25–99.92 0.87–98.50 1.51–99.73 21.71–85.42 25.14–81.65 16.71–90.28 18.27–89.99 cognitive 3.05–99.25 0.17–100.00 0.69–99.96 1.11–99.81 19.03–87.86 23.67–84.44 16.06–91.47 16.50–91.50 5 0 baseline 3.18–99.11 6.09–99.08 0.81–99.96 1.31–99.81 18.18–90.53 24.26–83.84 14.06–93.25 16.42–91.40
5 20 affine 3.69–99.09 0.38–100.00 0.25–99.40 0.38–99.95 17.58–89.51 21.01–85.94 12.34–94.46 13.94–93.52 cognitive 2.26–99.57 0.00–100.00 0.32–100.00 0.34–99.96 15.27–91.63 16.58–90.09 11.90–95.05 14.02–93.83 8 0 baseline 1.78–99.72 1.41–99.93 0.36–99.99 0.37–99.96 13.42–93.50 15.13–92.08 11.05–95.06 12.90–93.49
8 20 affine 2.18–99.60 0.00–100.00 0.27–99.75 0.16–99.98 15.54–91.87 18.62–88.93 9.45–96.06 12.76–94.54 cognitive 1.06–99.90 0.38–100.00 0.14–100.00 0.30–99.98 12.02–94.08 15.26–91.61 9.12–97.01 11.57–94.92
R means the real enrolled signatures and D/R means the duplicated per real enrolled signatures. In bold the cognitive duplicate method results extracted from Tables 3 and 4. The baselines are shaded in gray.
signatures are enrolled. These and other applications can be exploited by others since the duplicator is shared freely at www.gpds.ulpgc.es.
Although good results have been achieved here, there is more work to be done on the duplicator for off-line signatures in order to take advantage of its productivity. The duplicator can be adapted to different users to improve their individual performance. So, one way of exploiting the productivity of the duplicator may be to change its configuration for each user: the larger the intra-personal variability, the wider the limits will be. In this field, it may be worthy defining a more convenient strategy to duplicate signatures. As such, we will be keen to work on user-dependent parameter optimization to obtain better results. As a strategy, we plan to investigate an evolutionary algorithm whose objective function will be related to the Hellinger distance and thus to verifying the visual result of the duplication. Finally, further research on the pseudo-dynamic extraction of the off-line signature could be an important advance in simulating the effector dependent function.

ACKNOWLEDGMENTS
The authors would like to thank Elias N. Zois for providing them with the System D code. M. Diaz is supported by a PhD fellowship from the ULPGC.

References
[1]R. Plamondon,G. LoretteAutomatic signature verification and writer identification the state of the artPattern Recognit., vol. 22, no. 2, pp. 107–131, 1989.1989
[2]F. Leclerc,R. PlamondonAutomatic signature verification: The state of the art 1989-1993Int. J. Pattern Recog. Artif. Intell., vol. 8, no. 03, pp. 643–660, 1994.1994
[3]M. FairhurstSignature verification revisited: Promoting practical exploitation of biometric technologyElectron. Commun. Eng. J., vol. 9, no. 6, pp. 273–280, 1997.1997
[4]S.N.R. PlamondonSrihari,“On-line and off-line handwriting recognition: A comprehensive survey,IEEE Trans. Pattern Anal. Mach. Intell., vol. 22,2000
[5]J. Fierrez,J. Ortega-GarciaOn-Line Signature VerificationNew York, NY, USA: Springer,2008
[6]D. Impedovo,G. Pirlo,R. PlamondonHandwritten signature verification: New advancements and open issuesProc. Int. Conf. Frontiers Handwriting Recog., 2012, pp. 367–372.2012
[7]M. Diaz-Cabrera,A. Morales,M.A. FerrerEmerging issues for static handwritten signature biometricProc. Adv. Digit. Handwritten Signature Process. A Human Artefact for E-Soc., 2014, pp. 111–122.2014
[8]L.G. Hafemann,R. Sabourin,L.S. OliveiraOffline handwritten signature verification—literature reviewCoRR, vol. abs/1507.07909, 2015.2015
[9]M. Munich,P. PeronaVisual identification by signature trackingIEEE Trans. Pattern Anal. Mach. Intell., vol. 25, no. 2, pp. 200–217, Feb. 2003.2003
[10]E. Frias-Martinez,A. Sanchez,J. VelezSupport vector machines versus multi-layer perceptrons for efficient off-line signature recognitionEng. Appl. Artif. Intell., vol. 19, no. 6, pp. 693–704, 2006.2006
[11]C. Rabasse,R. Guest,M. FairhurstA new method for the synthesis of signature data with natural variabilityIEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 38, no. 3, pp. 691– 699, Jun. 2008.2008
[12]J. Galbally,J. Fierrez,M. Martinez-Diaz,J. Ortega-GarciaImproving the enrollment in dynamic signature verification with synthetic samplesProc. 10th Int. Conf. Document Anal. Recog., 2009, pp. 1295–1299.2009
[13]M. Song,Z. SunAn immune clonal selection algorithm for synthetic signature generationMath. Problems Eng., vol. 2014, pp. 1–12, 2014.2014
[14]M. Diaz,A. Fischer,R. Plamondon,M.A. FerrerTowards an automatic on-line signature verifier using only one reference per signerProc. IAPR Int. Conf. Document Anal. Recog., 2015, pp. 631–635.2015
[15]M.A. Ferrer,M. Diaz-Cabrera,A. Morales,J. Galbally,M. Gomez-BarreroRealistic synthetic off-line signature generation based on synthetic on-line dataProc. IEEE Int. Carnahan Conf. Security Technol., 2013, pp. 116–121.2013
[16]R. Guest,O. Hurtado,O. HennigerAssessment of methods for image recreation from signature time-series dataIET Biometrics, vol. 3, no. 3, pp. 159–166, 2014.2014
[17]M. Diaz-Cabrera,M. Gomez-Barrero,A. Morales,M.A. Ferrer,J. GalballyGeneration of enhanced synthetic off-line signatures based on real on-line dataProc. IAPR Int. Conf. Frontiers Handwriting Recog., 2014, pp. 482–487.2014
[18]J. Galbally,M. Diaz-Cabrera,M.A. Ferrer,M. Gomez-Barrero,A. Morales,J. FierrezOn-line signature recognition through the combination of real dynamic data and synthetically generated static dataPattern Recog., vol. 48, pp. 2921–2934, 2015.2015
[19]M. Diaz-Cabrera,M. Ferrer,A. MoralesCognitive inspired model to generate duplicated static signature imagesProc. Int. Conf. Frontiers Handwriting Recog., 2014, pp. 61–66.2014
[20]A.M. WingMotor control: Mechanisms of motor equivalence in handwritingCurrent Biol., vol. 10, no. 6, pp. R245–R248, 2000.2000
[21]K.S. LashleyBasic neural mechanisms in behaviorPsychological Rev., vol. 37, no. 1, pp. 1–24, 1930.1930
[22]D.O.HebbThe Organization of Behavior: ANeuropsychological TheoryNewYork, NY, USA:Wiley,1949
[23]N.A. BernsteinThe Co-Ordination and Regulation of MovementsOxford, U.K.: Pergamon,1967
[24]A. Marcelli,A. Parziale,R. SenatoreSome observations on handwriting from a motor learning perspectiveProc. 2nd Workshop Automat. Forensic Handwriting Anal., 2013, pp. 6–10.2013
[25]M. Ferrer,M. Diaz-Cabrera,A. MoralesStatic signature synthesis: A neuromotor inspired approach for biometricsIEEE Trans. Pattern Anal.Mach. Intell., vol. 37, no. 3, pp. 667–680,Mar. 2015.2015
[26]M. KawatoInternal models for motor control and trajectory planning,”CurrentOpinionNeurobiol., vol. 9,1999
[27]T. Hafting,M. Fyhn,S. Molden,M.-B. Moser,E.I. MoserMicrostructure of a spatial map in the entorhinal cortexNature, vol. 436, no. 7052, pp. 801–806, 2005.2005
[28]C. O’Reilly,R. PlamondonDevelopment of a sigma-lognormal representation for on-line signaturesPattern Recog., vol. 42, no. 12, pp. 3324–3337, 2009.2009
[29]A.O. Thomas,A. Rusu,V. GovindarajuSynthetic handwritten {CAPTCHAsPattern Recog., vol. 42, no. 12, pp. 3365–3373, 2009.2009
[30]V. Nguyen,M. BlumensteinTechniques for static handwriting trajectory recovery: A surveyProc. 9th IAPR Int. Workshop Document Anal. Syst., 2010, pp. 463–470.2010
[31]M. Liwicki,Y. Akira,S. Uchida,M. Iwamura,S. Omachi,K. KiseReliable online stroke recovery from offline data with the data-embedding penProc. Int. Conf. Document Anal. Recog., 2011, pp. 1384–1388.2011
[32]M. Liwicki,S. Uchida,A. Yoshida,M. Iwamura,S. Omachi,K. KiseMore than ink realization of a data-embedding penPattern Recog. Lett., vol. 35, no. 0, pp. 246–255, 2014.2014
[33]S. Lee,J. PanHandwritten numeral recognition based on hierarchically self-organizing learning networks with spatio-temporal pattern representationProc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recog., 1992, pp. 176–182.1992
[34]S. Lee,J. PanOffline tracing and representation of signaturesIEEE Trans. Syst., Man Cybern., vol. 22, no. 4, pp. 755–771, Jul./Aug. 1992.1992
[35]R. Plamondon,C. PriviteraThe segmentation of cursive handwriting: An approach based on off-line recovery of the motor-temporal informationIEEE Trans. Image Process., vol. 8, no. 1, pp. 80–91, Jan. 1999.1999
[36]D. Doermann,N. Intrator,E. Rivin,T. SteinherzHidden loop recovery for handwriting recognitionProc. 8th Int. Workshop Frontiers Handwriting Recog., 2002, pp. 375–380.2002
[37]H. Fu,S. Zhou,L. Liu,N. MitraAnimated construction of line drawings,”ACMTransGraph., vol2011
[38]N. OtsuA threshold selection method from gray-level histogramsIEEE Trans. Syst., Man Cybern., vol. 9, no. 1, pp. 62–66, Jan. 1979.1979
[39]M. Ferrer,J. Vargas,A. Morales,A. OrdonezRobustness of offline signature verification based on gray level featuresIEEE Trans. Inf. Forensics Security, vol. 7, no. 3, pp. 966–977, Jun. 2012.2012
[40]R.M. Haralick,L.G. ShapiroComputer and Robot Vision, 1st ed1992
[41]S. Kotz,S. NadarajahExtreme Value Distributions: Theory and Applications2000
[42]M. Diaz-Cabrera,M.A. Ferrer,A. MoralesModeling the lexical morphology of western handwritten signaturesPLoS ONE, vol. 10, no. 4, p. e0123254, 04 2015.2015
[43]M. Blumenstein,M. Ferrer,J. VargasThe 4nsigcomp2010 off-line signature verification competition: Scenario 2Proc. Int. Conf. Frontiers Handwriting Recog., 2010, pp. 721–726.2010
[44]J. Ortega-Garcia,J. Fierrez-Aguilar,D. Simon,J. Gonzalez,M. Faundez,V. Espinosa,A. Satue,I. Hernaez,J.J. Igarza,C. Vivaracho,D. Escudero,Q.I. MoroMCYT baseline corpus: A bimodal biometric databaseIEE Proc. Vis., Image Signal Process., vol. 150, no. 6, pp. 395–401, 2003.2003
[45]M. Ferrer,J. Alonso,C. TraviesoOffline geometric parameters for automatic signature verification using fixed-point arithmeticIEEE Trans. Pattern Anal. Mach. Intell., vol. 27, no. 6, pp. 993–997, Jun. 2005.2005
[46]G.S. Eskander,R. Sabourin,E. GrangerHybrid writerindependent-writer-dependent offline signature verification systemIET-Biometrics J., vol. 2, no. 4, pp. 169–181, 2013.2013
[47]E.N. Zois,L. Alewijnse,G. EconomouOffline signature verification and quality characterization using poset-oriented grid featuresPattern Recog., vol. 54, pp. 162–177, 2016.2016
[48]J. Fierrez-Aguilar,J. Ortega-Garcia,J. Gonzalez-RodriguezTarget dependent score normalization techniques and their application to signature verificationIEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 35, no. 3, pp. 418–425, Aug. 2005.2005
