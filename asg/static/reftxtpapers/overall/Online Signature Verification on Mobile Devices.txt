Online Signature Verification on Mobile Devices
Napa Sae-Bae,Nasir Memon
nsaeb01@students.poly.edu;,memon@poly.edu).

Abstract
This paper studies online signature verification on touch interface-based mobile devices. A simple and effective method for signature verification is developed. An online signature is represented with a discriminative feature vector derived from attributes of several histograms that can be computed in linear time. The resulting signature template is compact and requires constant space. The algorithm was first tested on the well-known MCYT-100 and SUSIG data sets. The results show that the performance of the proposed technique is comparable and often superior to state-of-the-art algorithms despite its simplicity and efficiency. In order to test the proposed method on finger drawn signatures on touch devices, a data set was collected from an uncontrolled environment and over multiple sessions. Experimental results on this data set confirm the effectiveness of the proposed algorithm in mobile settings. The results demonstrate the problem of within-user variation of signatures across multiple sessions and the effectiveness of cross session training strategies to alleviate these problems.

I. INTRODUCTION
AHANDWRITTEN signature is a socially and legallyaccepted biometric trait for authenticating an individual. Typically, there are two types of handwritten signature verification systems: off-line and online systems. In an off-line system, just an image of the user’s signature is acquired without additional attributes, whereas, in an online system, a sequence of x-y coordinates of the user’s signature, along with associated attributes like pressure, time, etc., are also acquired. As a result, an online signature verification system usually achieves better accuracy than an off-line system [1].
The increasing number of personal computing devices that come equipped with a touch sensitive interface and the difficulty of entering a password on such devices [2] have led to an interest in developing alternative authentication mechanisms on them [3], [4]. In this context, an online signature is a plausible candidate given the familiarity users have with the concept of using a signature for the purpose of authentication.
There has been much work on online signature verification systems [5]–[10]. However, none of this has been directed to the context of authentication on mobile devices. Previous work has addressed online signatures acquired from traditional digitizers in a controlled environment. These are different from those acquired from mobile devices in dynamic environments. First, on mobile devices, a user performs his signatures in various contexts, i.e., sitting or standing, mobile or immobile, and holding a device at different angles and orientations. Secondly, availability of computational resources may differ from one signature instance to another and it could result in greater variation of input resolution when compared to that of stand-alone acquisition devices. Last, signatures on mobile devices are often drawn using a finger instead of a stylus resulting in less precise signals. An example of finger drawn signatures acquired from mobile devices is depicted in Figure 1.
Consequently, verification performance derived from traditional datasets, collected using stylus-based devices in a controlled environment, may not carry over to online signature verification on mobile device setting [5]–[8]. In addition, other characteristics of the system, i.e., a template aging [11] and effectiveness of cross-sessions training, may be different when signatures are obtained from a mobile device.
This paper proposes an online signature verification algorithm that is suitable to deploy on mobile devices. It is a computationally and space efficient algorithm for enrolling and verifying signatures. In addition, a signature template is stored in an irreversible form thereby providing privacy protection to an original online signature. The proposed method was evaluated on public datasets as well as new dataset collected in in uncontrolled setting from user owned mobile devices. The verification performance obtained is promising. The key contributions made by this paper are as follows:
1) A method to extract a model-free non-invertible feature set from an online signature is proposed. The feature set comprises of sets of histograms that capture distributions of attributes generated from raw signature data sequences and their combinations. By evaluating the proposed method on public datasets, its verification performance is superior to several state of the art algorithms. 2) A new dataset was collected from 180 users in a mobile device verification environment. The signatures in this dataset were drawn with a fingertip, in an uncontrolled setting on user owned iOS devices and over six separate sessions with intervals ranging from 12 to 96 hours. 3) By applying the proposed method on the above dataset, the following aspects of online signature verification on mobile devices were investigated:
• impact of template aging on online signatures, • effectiveness of using cross-session samples, or
samples from multiple sessions, to train a classifier, and • security of the system against random forgery, or zero-effort attack, and its comparison to that of 4-digit PIN.
The rest of this paper is organized as follows. Section II presents a process of deriving a set of histograms from an online signature, gives details of the proposed online signature verification system, and analyzes its complexity. Section III provides experimental results on public datasets. In section IV, a method and apparatus for collecting a new dataset as well as experimental results and analysis on this dataset is presented. Lastly, in section V, conclusions and future work are discussed.

A. Previous Work
Typically, online signature verification techniques can be classified into two approaches, namely, function-based and feature-based [5]. The former refers to an approach where the matching process is done using, directly or indirectly, the original time series data points of a signature. The latter refers to an approach where the matching process is done using descriptive features of a signature. Examples of well-known function-based approaches include Dynamic Time Warping Algorithm (DTW) [6], [7], [12], and Hidden Markov Models (HMM) [8].
A function-based system typically yields better verification performance than a feature-based system [13]. However, during the matching process, a dynamic construction of the original signature is revealed resulting in a potential privacy problem if the matching has to be done remotely. Furthermore, the system is generally more complex and slower than featurebased systems [6]. Even worse, when a template protection approach is applied in order to provide biometric privacy and/or security, verification performance often deteriorates significantly. For instance, Maiorana et al [14] have proposed a convolution scheme to protect the original signature sequence of a user, that can be directly applied to any function based approach. The idea is to split the original input sequence into W subsequences. Each subsequence may have a different length based on random parameters. This technique has been applied with HMM and DTW based verification
systems [14]–[16]. In each case, verification rates were lower when compared to using the original versions of the signatures.
With a feature-based system, an online signature is represented by a feature vector. Therefore, the original biometric sample need not be stored or transmitted. Further, many known algorithms [17], [18] can be used to derive cryptographic keys from feature vectors. However, the main challenge for a feature-based approach is to derive a descriptive set of features that can be used to effectively and efficiently verify an online signature [5], [6], [12]. In the literature, there are many proposals to derive a set of features from an online signature. In 2005, Fierrez-Aguilar et al [19] proposed a set of 100 features, such as total duration of the signature, number of pen ups, sign changes of (dx/dt) and (dy/dt), etc. to represent a signature and applied a feature selection method to rank the proposed features. Based on this 100 feature set, Nanni [9] proposed a multi-matcher method to verify an online signature. In addition, Guru and Prakash [10] derived a symbolic representation of an online signature and introduced the concept of writer independent threshold in order to improve verification accuracy. Recently, Argones et al [20] have proposed a set of HMM model features from a universal background model. The best reported verification performance obtained by their system is promising. However, the system extracts 4800 features from tuning 16 different HMM models, which is a computationally expensive task. Moreover, the universal background model is trained from a pool of 2500 genuine and forged signatures from 50 users on the same device specification, where a user-specific classifier is trained from 10 signatures. These make it less feasible to be employed for mobile device authentication, where the embedded sensors are different from model to model. In addition, the HMM-based method is not robust to the well known templateaging problem resulting in significant deterioration of verification performance when verifying samples and enrollment samples are from different sessions [11].

II. ONLINE SIGNATURE VERIFICATION ALGORITHM
As illustrated in Figure 2, the proposed system comprises of three main components: a feature extractor, a template generator, and a matcher. First, an online signature is processed by the feature extractor in order to compute a set of histograms from which a feature vector is derived. Then, the template generator constructs a user-specific template using the feature sets derived from multiple enrolled signatures. This template is later used by the matcher to verify a test signature. The rest of this section describes these three components in detail and analyzes system complexity. (For more details, please refer to [21] for the earlier version of this work.)

A. Feature Extractor
In the proposed system, an online signature is represented by a set of histograms. These histogram features are designed to capture essential attributes of the signature as well as relationships between these attributes. It should be noted that histograms are widely used as a feature set to capture attribute statistics in many recognition tasks. For instance, in object
recognition [22] and off-line signature verification [23]. Using histograms for online signature verification was first suggested by Nelson et al [24]. They have also been used as part of the feature set in [1] and [19]. However, in [1] and [19], the use of histograms is limited only to angles derived from vectors connecting two consecutive points in an online signature. In fact, as is shown below, much more information can be used to derive histograms useful in online signature verification. These include x-y trajectories, speed, angles, pressure, and their derivatives.
The feature extraction process of the proposed system begins by converting the time-series data of a signature in to a sequence of cartesian vectors and attributes, as well as their derivatives. Then, each cartesian vector is also converted to a vector in the polar coordinate system. Finally, histograms from these vector sequences are derived. Details of the feature extraction process are as follows.
Let X = {x1, x2, . . . , xn}, Y = {y1, y2, . . . , yn}, and P = {p1, p2, . . . , pn} be the x and y co-ordinates and pressure attribute, respectively, of a signature with length n sampled at times T = {t1, t2, . . . , tn}. For datasets used in this first experiment, all signatures were sampled at a constant rate. Hence the time information is implicit and is ignored. Note that if time intervals are not a constant, a normalization process using information from T can be applied to the sequences X , Y , and P prior to being processed by the system.
To begin with, the vectors X1, Y 1, and P1 including their derivatives are computed as follows,
X1 = {x1i |x1i = xi+1 − xi }, (1a) Y 1 = {u1i |y1i = yi+1 − yi }, (1b) P1 = {pi }, (1c)
and
Xk = {xki |xki = xk−1i+1 − xk−1i }, (1d) Y k = {yki |yki = yk−1i+1 − yk−1i }, (1e) Pk = {pki |pki = pk−1i+1 − pk−1i }, (1f)
where k > 1 and i = 1, 2, . . . , n − k. Note that, by computing differences between each pair of successive points as above, the vectors X1 and Y 1 capture
positional invariant features of the signature. And by repeating this process of taking differences k times yields the kth order derivative, Xk and Y k , of the original X and Y sequences respectively.
Then, a sequence of vectors V = {v∗i |i = 1, 2, . . . , n}, is constructed where each vector element, v∗i = {v1i ‖ . . . ‖v ji } is the concatenation of vki which is a five-tuple consisting of the kth order derivative of the cartesian and polar coordinates and pressure attributes as follows:
vki = 〈xki , yki , rki , θ ki , pki 〉, (2) where θ ki = tan−1 ( yki /x k i ) , rki = √( xki )2 + (yki )2
, and i = 1, 2, . . . , n − k (see Figure 3 for illustration of the process of deriving θ distribution from an online signature).
A set of histograms is then derived from distributions of attributes of vectors v∗i in V . The detailed descriptions of these uniform width histograms are given in Table I. Specifically, there are two types of histograms:
1) One dimensional histograms – these capture distributions of individual attributes. For example, the histogram 1 captures the angle distribution of an online signature which reflects the similarity between two signature shapes. Similarly, 2 captures the distribution of the angles of the first derivative since it provides information about how these vectors are aligned, an aspect that is completely ignored in the histogram 1. R1 captures the speed distribution of an online signature which is one of the distinctive features that is unique among users and especially useful in combating skilled forgeries. 2) Two dimensional histograms – these capture distributions of relationship between pairs of attributes. For example, < 1, R1 >(1) and < 1, R1 >(2) captures the distribution of dependency between speed and angle of the first and the second halves of an online signature. Similarly, < 1, 1d(1,2) > captures the distribution of the relationship between three consecutive angular coordinates of an online signature sequence while providing warping flexibility when comparing two different signatures from the same user.
The histograms above are computed by splitting the range of attribute values (specified by Min and Max columns in Table I), into a number of equal width bin intervals (also given in Table I), and counting the number of elements that fall into each particular bin. For an angle attribute and its derivative, the range of its histogram is defined as [−π, π]. For an attribute that has no explicit boundary, an outlier process with cutoff at three standard deviations from its mean is applied prior to computing the mean and standard deviation of the attribute in order to derive its implicit range described in Table I. For example, the histogram 1 is derived from a sequence {θ i1; i = 1, . . . , n} by forming a 24 bin histogram with equal width bin intervals beginning from −π to π and counting the number of elements, {θ1i }, that fall into each of the 24 bins. It then results in a vector of 24 bin frequencies. As can be noted from Table I histograms comprise of two types of frequencies: 1) absolute frequency, an actual count of elements that fall into a particular bin, and 2) relative frequency, the absolute frequency normalized by the total number of elements in the histogram, or in other words the
length n of a signature. Using the absolute frequency results in more implicit importance given to the length of the signature whereas using the relative frequency ignores the length. Out of the 21 histograms listed in Table I, only 5 are described by absolute frequency. These are the speed and its first derivative histogram, the pressure histograms of the first and second half of a signature, and the < 1, 1d(1,2) > histogram. These five histograms were empirically chosen as they derive from the lowest order derivative of online signature attributes as well as they provide higher recognition rate when describe with absolute frequency.
After all these histogram are computed, they are concatenated and used as a signature’s feature vector as follows. Let Bi be a vector of bin frequencies of i th histogram. A feature vector F is defined as F = {B1‖B2‖ · · · ‖B j }, where j is the total number of histograms, and ‖ is the concatenation operator. Once the feature vector F is constructed, each of the elements is used independently as a feature component of an online signature. For the rest of the paper, F is treated as a feature vector without distinguishing which histogram each each individual feature element belongs to. In other words, an online signature is represented by a feature vector F = { fi ; i = 1, . . . , M} where M is the total number of histogram bins from all j histograms.

B. User Template Generator
A user template is generated during the enrollment process where multiple signatures are acquired from a user and a feature set is computed from each of the samples. Then, the variance of each feature component is computed and is used to construct a user-specific uniform quantizer for each feature element resulting in a quantization step size vector Qu that is used to quantize each of the feature vectors derived from the enrollment samples. Finally, the average of these quantized feature vectors is used as the template F̈u for that user. This feature vector along with the quantization step size vector are stored corresponding to the identity of the user.
During verification, a user claiming an identity u is asked to produce one instance of an online signature which is again represented by the set of features. Then the quantization step size vector, Qu corresponding to that identity is used to derive a quantized feature vector from the signature input. Next, the system compares this quantized feature vector against the stored feature vector template, F̈u . The signature is accepted if the Manhattan distance between these two vectors is less than a predefined threshold, otherwise it is rejected. The details on how to derive the quantization step size vector Qu and the template feature vector are given below.
Let S be the total number of enrolled samples and M be the total number of features for each sample. And let Fs j = { f s ji |i = 1, . . . , M} be a feature vector of the enrolled sample s j of the user u where j = 1, . . . , S. The quantization step size vector of the user u, Qu = {qui |i = 1, . . . , M}, is obtained by computing the standard deviations over all the enrolled samples for each feature and using a multiple of this as the
quantization step size. That is,
qui = β √√√ √ 1
S
S∑
j=1
( f
s j i − μ f (u)i
)2 , i = 1, . . . , M (3)
where μ f (u)i = 1S
∑S j=1 f s j i , β is experimentally fixed at 1.5.
Then, the quantized feature vector of each enrolled sample s of the user u, F̂(s j |u) = { f̂ s ji |i = 1, . . . , M} is derived from the quantization step sizes qui in Q
u (adding a small to prevent division by zero) as follows,
f̂ ( s j |u) i = [ f s j i
qui +
]
, i = 1, . . . , M (4)
where is at 0.002 and 0.8 for histograms with absolute and relative frequencies, respectively.
Lastly, the user-specific feature vector template, F̈u = { f̈ ui |i = 1, . . . , M}, is derived by averaging the quantized feature vectors of all the enrolled online signature samples from the user u.
f̈ ui = ⎡ ⎣ ∑S j=1 f̂ (s j |u) i
S
⎤
⎦, i = 1, . . . , M (5)
A pair ( Qu , F̈u ) comprising of the quantization step size vector and its associated feature vector template is then stored and later used to verify a claimed signature of the user u.
It should be noted that while the feature vector in this experiment was extracted from attributes of multiple histograms, it is possible to use other proposed methods, e.g., the one in [25], that can extract a fixed-size feature vector from an online signature with variable length. However, the method proposed in this paper to derive a quantization step size vector and a user-specific feature vector template is not robust to a feature with an extreme value, i.e., an outlier. This could possibly happen in certain features spaces, for example DCT coefficients in [25], but is rarely the case for histogram features. Such an occurrence could result in verification performance deterioration.

C. Matcher
During verification, given that t is claimed to be an online signature sample from user u, F̂ (t |u) is calculated using Qu . Then the system derives a dissimilarity score using manhattan distance between F̈u and F̂ (t |u) as,
Score = M∑
i=1 | f̂ (t |u)i − f̈ ui | (6)
The system then accepts the sample t if the dissimilarity score is less than a predefined threshold, otherwise it rejects.

D. Complexity
Given n as the length of an online signature, Xk , Y k , Rk , k , and Pk can be computed in time O (n). These vectors are then used to derive h histograms which requires O (h ∗ n) or O (n) time complexity for deriving a feature vector as h is a constant. For the classification process, a feature vector
is first computed and quantized in O (n) time and then used to construct or to compare against the feature vector template. Since the number of features is a constant, the time complexity is O (n). The space required to store a template is clearly a constant as it consists of two fixed-length vectors. As a result, the proposed method requires constant space to store a user’s template and linear time computational complexity for enrolling and verifying a signature.

III. EXPERIMENTS ON PUBLIC DATASETS
This section presents experimental results with the proposed technique and compares it to others published in the literature on common datasets. Experiments were performed on the two well known datasets: 1) MCYT [8], which consists of signatures from 100 individuals with 25 genuine samples and 25 skilled forgery samples, and 2) SUSIG [7], which consists of signatures from 94 individuals with 20 genuine samples from two separate sessions and 10 skilled forgery samples.
In terms of training samples, there have been two approaches taken in the literature. Some papers [10], [26] randomly select k samples as the training set and then they average over multiple such random selections to derive the final performance result. The reason is that such a training method captures within-user variation better. Other papers [7], [8], [14], [15], and [20] choose the first k samples, according to the original order in which the data was acquired, as the training set. For online signature verification, most studies have chosen this second approach since it mimicks what a verification application will actually do. In other words, the actual verification application will always acquire enrollment samples before verifying samples. The results from such an experimental protocol also captures the effect of the template aging problem [13], [26], [27], which is, in fact, one of the major causes for degradation of verification performance.
In this experiment, the second protocol was followed. That is, the first k samples of the set from a specific user were used to enroll a template, and the rest were used to evaluate
the False Rejection Rate (FRR) at different threshold levels. In the random forgery scenario or zero effort attack, i.e., an attacker simply attacks the system using his own signature, all samples from all other individuals were used to evaluate the False Acceptance Rate, namely FAR-RF. On the other hand, for the skilled forgery scenario, 25 skilled forgery samples from MCYT dataset and 10 skilled forgery samples from SUSIG dataset for each user were used to evaluate the False Acceptance Rate, namely FAR-SF. The Equal Error Rate (EER), the rate at which FAR and FRR are equal, was also used to compare the verification performance of different approaches.
Finally in this experiment, only the first and second derivative sequences of vectors v∗ = [v1i , v2i ], as described in Section 2.1, were used to compute the features of an online signature (i.e. k = 2). This resulted in a set of 440 features by concatenating the histograms described in Table I (See Appendix A for experiments where parameters in the table are varied.)

A. Effectiveness of 1-D Versus 2-D Histogram Features
As mentioned in section II-A, the proposed histogram features are derived from two types of histograms namely one dimensional histograms and two dimensional histograms. The plot of the receiver operator characteristic (ROC) curve obtained from MCYT-100 dataset when each of these histograms is used as well as when they are combined, using 10 enrollment samples, is depicted in Figure 4.
The results show that 2-D histograms are indeed a more effective feature set in terms of discrimination power against both skilled and random forgeries as compared to 1-D histograms provided that they are employed with larger bin widths. They also appear to work well with less information since pressure information was not included in the 2-D histograms we computed. The results also demonstrate that 1-D histogram features provide complementary information since the best result is observed when the two sets are combined.

EER OF THE PROPOSED SYSTEM DERIVED FROM MCYT-100 DATASET WHEN DIFFERENT NUMBER OF SAMPLES ARE USED FOR TRAINING
B. Verification Performance of the Proposed System
The performance of the proposed verification system derived from MCYT-100 dataset using different number of training samples per user is reported in Table II. The results demonstrate that the proposed system can effectively verify a user’s online signature even when only three samples are supplied during enrollment. However, verification performance at every operating point slightly improves as the number of training samples grows.

C. Comparison With Previous Work
This subsection provides a comparison of performance between the systems that are considered as the state of the art for feature and function based approaches and the proposed approach. Results reported on the proposed system as well as the other systems are derived from the same datasets. The function based approach considered here includes Dynamic Time Warping technique (DTW), Hidden Markov Model (HMM), and their template protection approach. The feature based approach considered include one utilizing Fourier descriptor features, and a 100-feature system in conjunction with three different classifiers.
Table III lists the verification performance of these different techniques on the MCYT-100 dataset. As seen, the proposed system outperforms other systems especially when a few training samples are supplied. These results emphasize the competitiveness of the proposed system despite its computational and space efficiency.
Table IV reports verification performance for the previous techniques listed above on the SUSIG dataset. As mentioned in [7] and [26], they choose to more heavily weigh the signing duration feature as they observed that a skilled forgery signature typically takes twice as long as a genuine one on the average. Hence their FAR-SF is lower than FAR-RF. However, as reported in [7] and [26], the EER for the skilled forgery case in this dataset is greatly influenced by the significance that a classifier gives to the length disparity between two given signatures. In the proposed system, less weightage is given to this length disparity since most of histogram features in the proposed set are attributed by their relative frequency in which the actual length of the signature is ignored. Only 112 histogram features or 25% in the set are attributed by absolute frequency, where the actual length of the signature gets reflected in the feature values. This results in lower FAR-RF but higher FAR-SF than the system in [7] and [26]. However, when more weight is given to the histograms with frequency attributes, the EER of skill forgery is reduced from 5.86 to 4.59 whereas that of random forgery remains unchanged. This implies that the verification performance
could potentially improve if there are more histograms created using absolute frequency and not relative frequency. It also demonstrates that the forger’s skill in these two datasets are very different.
We acknowledge that reported verification rate is not always the best justification for a system’s effectiveness, since each system might have been trained and tested differently as well as the difference in employing skilled forgery model. In addition, the system might apply different set of features to employ their classifiers. Nevertheless, the results show that the proposed system, at the very least, is comparable to others in terms of the verification performance.

IV. EXPERIMENTS ON MOBILE DEVICE DATASET
Performance comparison of online signature recognition algorithms has been traditionally done using public datasets. The two well-known public datasets, the SUSIG and MCYT-100 datasets, have been collected using a static stylustablet in a controlled and supervised setting. The previous section reported results of the proposed algorithm obtained on these two datasets. However, as mentioned in the introduction, online signature verification for user authentication on mobile devices has unique aspects that are not reflected in these datasets. It has been reported that performance obtained with algorithms on traditional digitizers in a static environment suffers significant deterioration when used on a mobile platform where users were holding the device instead of it being in a fixed position [29]. The performance may further degrade when online signatures are acquired without supervision as opposed to those in public datasets which were typically supervised. This section describes an experimental study to evaluate the performance of the proposed system while using a dataset comprising of signatures collected from user owned devices taken over a sufficient time window in an unsupervised, uncontrolled setting.

A. Data Collection Procedure
The process for data collection began by recruiting users from a departmental mailing list by sending a brief description of the experiment and offering a $10 dollar gift card to those who participate. Users who volunteered, were asked to create an online account with an email address, username and password on a webpage. The system then immediately took them to an introduction page that briefly described the purpose of the experiment and the procedure they would be expected to follow. An example signature was provided but no other instruction was given on the type of signature they should create. However, they were motivated to provide quality signatures by rewarding the top ten users with the most consistent samples over the entire experiment with an additional $40 gift card. Then the user was asked to create a signature and draw it five times on the screen. Visual feedback was provided so the user could see the signature they drew. All signatures were performed on the users’ personal devices.
An experimental protocol was designed to capture time variation effects in user signature input over the course of approximately seven days. After the first session, multiple
sessions of data collection were performed where a user entered his signature 5 times for each session. At the end of each session, the screen was locked and the user was instructed to wait for a time period after which a reminder to perform the next session would be sent to his email address. The minimum time interval between each of the sessions and its immediate successor was twelve hours for the first and second, the second and third, and the third and fourth sessions. The minimum time intervals imposed between the fourth and the fifth, and between the fifth and the last session were 96 hours and 24 hours respectively. The time intervals between sessions were chosen to introduce variation in times of the day when the signatures were performed and hence the context they would be performed under.
During the experiment, if a user forgot his signature, he was provided with two options. First, he could reset the account and redo the process from the beginning. Second, he could click the “forgotten” button and the system would show his previous signature on the screen. In this case, he would be prompted to clear the screen before he could enter his new signature. This was to prevent a user from tracing his own signature thereby increasing consistency artificially.
All of the signatures were collected via the HTML5 platform. The purpose of using the HTML5 framework was to allow the user to enter online signatures anytime and anywhere without supervision. As a result, intra-user variations caused by several factors that could happen while signing in a mobile
context, i.e., signing/device-holding pose, environmental condition, could potentially be captured. In addition, the HTML5 platform allowed users to participate without requiring them to install any application. While the application was running, the browser collected the touch input information and sent it back to the server and provided visual feedback to the user in the form of piecewise linear curve between the pair of drawing point in real time. For each signature, the data consisted of time-series of x-y coordinates and time-stamps.

B. Signature Characteristics
This subsection provides some characteristics of signatures that were collected. These characteristics included the length (number of points) and the number of strokes in the signature. A stroke in this study is defined as a sequence of touch points beginning from touch-down event to the next touch-up event. Figure 5 shows the distribution of signature lengths, the distribution of signature strokes and the distribution of the difference in the number of signature strokes within the same user. It is seen from Figure 5 that signature length varies significantly from user to user whereas the average length of a signature was 142.11 with a standard deviation of 85.67. Different signatures were also comprised of various numbers of strokes. Generally, the number of strokes can be influenced by the language and writing styles of users. In addition, it can also be caused by discontinuity of interaction between
the hardware sensor and the input device (fingertips in this case.) In this experiment, the users were recruited from the mailing list of a university where English is used as the first language. Nevertheless, the variation in the number of strokes from user to user is noticeable. On average, a signature had 3.38 strokes with a standard deviation of 2.28. In addition, we observed that the number of strokes were often not consistent even within the same user. On average, the number of strokes varied by 3.5 over the entire set of 30 samples taken from the same user. Only 20% of the users had a consistent number of strokes across all samples. Therefore it is important that an online signature verification system for mobile devices should be designed such that it is robust to signatures with varying number of strokes.

C. Signature Preprocessing
The variation in the number of strokes per signature and sampling rate introduced in the dataset can affect verification performance. Hence, all signatures were pre-processed by time normalization and stroke concatenation before extracting histogram features. Details of the time normalization and stroke concatenation steps used are as follows.
1) Time Normalization: When a signature is acquired from typical touch sensitive computing devices (iOS device in
this case), it is typically sampled with non-uniform rate. The rate depends on the availability of computational resources at a given time as well as the latency of network connection. Therefore, time normalization was used in order to derive a uniformly sampled signature. This helped to minimize the variation of signatures due to different sampling rates. The process used was as follows. Let S = {v1, v2, . . . , vN } be an online signature with a sequence of N strokes where each stroke v§i = {(xi1, yi1), . . . , (xiM , yiM )} is a sequence of touch points (x j , y j ) sampling at time T = {t i1, . . . , t iM }. The normalized stroke si was computed by interpolating the stroke vi at T = {t i1, t i1 + R, t i1 + 2R, . . . , t1i + t i M−t i1
R × R}. An example of a normalized stroke is depicted in Figure 6. After the process, all time-normalized signatures have a fixed sampling rate of 50 times per second, or 20 milliseconds apart.
2) Signature Stroke Concatenation: As shown in Figure 7b, most of the signatures in this dataset have multiple strokes. Signatures with multiple strokes may pose a challenge to verification algorithms by introducing positional variation for each of the strokes. This variation could become larger when the signatures are signed on touch devices using a fingertip since each touch point may not coincide with user’s intention [30]. In order to cope with this variation, signature strokes were concatenated before verification as follows.
Algorithm 1 Signature Stroke Concatenation s∗ := s1 for i:= 2:N do
si : (xij , yij )← (xij + xM ∗ −xi1, yij + yM ∗ −yi1) s∗ := {(x1∗, y1∗), . . . , (xM∗, yM∗), (xi1, yi1), . . . , (xiM , yiM )}
end for return S = {s∗}
Let S = {s1, s2, . . . , sN } be an online signature with a sequence of normalized strokes where each stroke si = {(xi1, yi1), . . . , (xiM , yiM )} is a sequence of touch points (x j , y j ) with length M . The immediately succeeding stroke is concatenated to the main stroke by translating the origin of the latter stroke to the end of the former stroke. The algorithm is as follows (see Figure 7 for illustration of the process),

D. Experimental Results
In this subsection we present experimental results using the data collection procedure and the pre-processing techniques described above. The algorithm used is the same as the one described in section 2, except two key differences. First, the histograms related to pressure information were discarded as they were not available in this dataset. Second, the additional histograms from Table V are empirically added as they provide higher recognition accuracy when incorporated.
1) Impact of Signature Aging and Effectiveness of Cross-Session Training Strategy: The objective of collecting the dataset over six separate sessions was to study template aging issues in online signatures, as well as to study whether training samples from multiple sessions can better represent within-user variation thereby enhancing verification performance. In this context, first the performance of online signature verification when training and test samples are drawn from the same session is reported in Table VI. Note that the results are the average performance from leave-one-out cross validation test. That is, the classifier is trained from all the samples from the same users but one, and each and every sample is used as a positive sample exactly once. The result shows that verification performance of the system when the training and test samples are from the same sessions is just slightly lower than that of public datasets given in section 3.

DESCRIPTIONS OF ADDITIONAL HISTOGRAMS THAT ARE USED
IN THE DATASET COLLECTED FROM MOBILE DEVICE
EXPERIMENT USING LEAVE-ONE-OUT CROSS VALIDATION
This is an encouraging result given that all signatures in this dataset were collected in an uncontrolled, unsupervised setting, without pressure information, and they were drawn using a fingertip, not a stylus.
However, biometric performance can be affected severely by the template aging problem as reported in many biometric modalities, namely, iris [31], [32], pericular [33], ECG signal [34], and speech [35]. To understand the aging problem of online signatures, the performance results, when a signature template is trained using samples from one session was used to verify samples from a different session, are reported in Table VII. It is seen that the performance when training and test samples are from different sessions noticeably deteriorates as compared to when they are from the same session. Specifically, with training samples from session 1 and test samples from session 2, the error rate in terms of EER

TEST SAMPLES ARE DRAWN FROM DIFFERENT SESSIONS
increases from 3.18% to 7.04% as compared to when training are from session 2.
It is also observed that the best performance in inter-session verification is obtained when the classifier is trained using samples from the preceding session. For example, the best verification performance of samples from session 6 is achieved when the training is from session 5. This suggests that a template updating mechanism should be in place in order to retain system reliability. Interestingly, for short-term effect, i.e., approximately one week, the time interval between the training and the test sessions seemed to have little influence on the performance. Specifically, the verification performance of the fifth session, which was at least four days apart from the previous session, did not deteriorate as compared to other sessions.
In terms of training strategies, previous work on ECG [34] and speaker verification [35] has shown that cross-session samples can be used to improve biometric performance. That is because they can accommodate within-user variation better than those from a single session. In order to evaluate the effectiveness of this training strategy on an online signature modality, a user’s online signature template was trained using samples from multiple sessions in stead of those from a single session. The results for multiple sessions training are given in Table VIII. In general, there is a significant improvement of verification performance when training samples are drawn from multiple sessions instead of a single session. Specifically, training a user’s signature template with samples from two sessions improves the EER to 3.27%, on an average, as compared to 5.76% when training samples are drawn from one session. Note that, while collecting enrolled samples from a user over multiple sessions is not a user-friendly option, one could possibly devise a procedure to collect samples with more realistic intra-user variation from a single session. One scenario involves interrupting users with a short interactive activity.

WHEN FALSE ACCEPTANCE RATE (FAR) IS FIXED FOR EACH USER
AT DIFFERENT LEVEL AND TRAINING SAMPLES ARE DRAWN FROM THE PRECEDING SESSION
WHEN FALSE ACCEPTANCE RATE (FAR) IS FIXED FOR EACH USER
AT DIFFERENT LEVEL AND TRAINING SAMPLES ARE DRAWN FROM THE TWO PRECEDING SESSIONS
Further effort in designing such enrollment procedure that better captures intra-user variation is left for future work.
2) Adaptive Thresholding: It is known that the score distribution of biometric samples differs from user to user. Consequently, the resulting FAR of different users with respect to the same threshold is different. This can be seen from Figure 8 which depicts FAR, FRR and HTER (Half Total Error Rate between FAR and FRR) of each individual when a global threshold that corresponds to the corresponding EER is applied. However, as far as security is concerned, FAR should be kept very low for each and every user. The performance in this case can be theoretically realized by adjusting the threshold for each user individually according to the desirable FRR. Tables IX and X report the system performance with

SUCCESSFUL ZERO-EFFORT IMPERSONATION RATE OF THE TOP THREE USERS WITH RESPECT TO DIFFERENT FAR LEVELS WHERE TRAINING SAMPLES ARE DRAWN FROM SESSIONS 1 AND 2
THE TOP THREE MOST POPULAR PINS AND THEIR FREQUENCIES [36]
such a threshold selection strategy in terms of the average FAR derived from the top n% of users with respect to different FRRs. The training samples in these two tables are from one and two preceding sessions respectively. Note that, in practical applications, this empirical decision threshold can be estimated by using the pool of signatures in the database where each signature is represented by a feature vector.
3) Security Against Zero-Effort Impersonations: This experiment was conducted in order to analyze the security of signatures against zero-effort impersonations and compare it against that of 4-digit PINs. For 4-digit PINs, if all users choose their 4-digit PINs at random, guessing a PIN of an unknown user with each and every PIN number would result in the same success rate at 0.01%. However, in practice, some PINs are chosen much more frequently than the others. In Table XII, the three most popular four-digit PIN and their frequencies are presented. An attacker could maximize the success rate of guessing a PIN of a random user by choosing the most popular one, i.e., ‘1234’.
Similarly, given that users can choose their signatures freely, some users might choose similar signatures. That is, their signatures may form a cluster in a specific feature space. Consequently, an attacker could maximize the chance of successful impersonation by mimicking a signature of the user that belongs to a cluster with a large number of users. To evaluate clustering characteristic of online signatures, we derive a success rate of zero-effort impersonation for each user when his signatures are used as impersonation samples against all other users.
Table XI presents the top three users with the highest success rate for zero-effort impersonation in different FAR levels. While the success rate of guessing user’s 4-digit PINs with ‘1234’ is at 10.71%; the success rate of impersonating other users by signatures from the user with the highest potential is lower at 4.66% for 1% FAR. The rate is lower at 2.38% and 0.48% for 0.5% and 0.1% FAR, respectively. That is, online signatures are distributed more evenly than fourdigit PINs. As a result, they can better protect users against guessing attack as compared to four-digit PINs when there is no password blacklist policy enforced against common pins.
4) Authentication Effort and Performance: Verification performance is one of the key factors that influence the usability of an authentication system. In particular, false rejection can lead to either an increase in the number of authentication attempts or user rejection and temporary lockout. While both cause usability issues, the recovery effort of the latter is more time-consuming than the former. Assuming that three failed attempts are allowed before rejecting and temporarily locking out users, rejections of genuine signatures are classified into two categories. These are failed attempts and user rejections. The first type leads to an increase in average number of attempts for successful authentication while the second one leads to an increase in user rejection rate. That is, the attempt rate is defined as,
Attempt Rate (AR) = # Total Attempts # Successful logins
(7)
and the user rejection rate is defined as,
Rejection Rate (RR)
= # Authen. Failures # Authen. Failures + # Successful logins (8)
Table XIII reports an average number of attempts as well as user rejection rates at different FAR levels. Note that, in this experiment, the signatures are verified in a circular and timely order. If a signature is rejected for the first time, at most two consecutive failures can be made before the attempt is counted as a user rejection. Also, if the last signature is rejected, two more chances are given to the next two samples in a circular order. On the other hand, if a signature is accepted, the attempt is counted as successful and the number of trials before succeeding is recorded. The results show that the rejection rate, or authentication failure, is greatly reduced from the FRR reported earlier in Table X. That is because, in many cases, the users can recover from failed attempts within the next two attempts. However, similarly to any other traditional authentication system, authentication failures are inevitable and the system should always have a secure and proper backup authentication mechanism in place.

V. CONCLUSION AND FUTURE WORK
This paper proposes a simple and effective online signature verification system that is suitable for user authentication on a mobile device. The benefits of the proposed algorithm are as follows. First, a histogram based feature set for representing
an online signature can be derived in linear time and the system requires a small and fixed-size space to store the signature template. In addition, since the feature set represents only statistics about distribution of original online signature attributes, the transformation is non-invertible. As a result, the privacy of the original biometric data is well-protected. Second, a user-specific classifier comprising of a user-specific quantization step size vector and its associated quantized feature vector can be trained using only enrollment samples from that user without requiring a training set from a large number of users. Several experiments performed on MCYT and SUSIG datasets demonstrate effectiveness of the proposed method in terms of verification performance as compared to existing algorithms.
A new dataset was collected for evaluating system performance of user authentication on a mobile device. Signatures in this dataset were drawn using a fingertip in an uncontrolled setting on user owned iOS devices over six separate sessions. Experimental results on this dataset provide similar performance as older dataset on stylus based devices and controlled environments. This shows that finger drawn signatures are plausible candidates for user authentication on mobile devices. The experiments also indicated that the well know template aging problem of online signatures is very relevant to the context of user authentication. That is, it was observed that the older the training samples as compared to the test samples, the lower the verification performance of the online signature classifier. This suggests that template updating mechanism is needed in order to stabilize the performance. Also, a significant inter-session verification performance improvement when a classifier is trained using cross-session samples, as compared to the one trained from a single-session samples, implied that
samples from multiple session can reflect a more accurate intra-user variation. Last but not least, security analysis of online signature verification system as compared to that of 4-digits PIN, and two usability metrics is also presented.
One interesting area for future work is the design of an enrollment protocol that can capture a intra-user variation effectively within a single session. In addition, it is currently possible to match different signature templates generated from the same online signature samples and thereby learn that two leaked biometric templates belong to the same user. Further investigation includes the use of other biometric key binding approaches, like fuzzy commitment, in order to strengthen security of the system, even when stored templates, helper data etc., are compromised, while preserving verification performance. Lastly, it is possible to derive a fusion approach by combining the proposed method with other existing approaches, e.g., DTW, HMM-based, etc., in order to improve verification performance, especially for applications where privacy of the signature traits is less critical.

APPENDIX DEPENDENCY OF VERIFICATION PERFORMANCE
ON HISTOGRAM PARAMETERS
The histogram feature configuration in Table I is parameterized by several key factors and their modification could impact the verification performance of the system. These include the number of bins for each histogram and the inclusion of each histogram in the feature set. In order to elaborate the effect of these parameters towards verification performance, the performance result when modifying the parameters is presented in Table XIV. First, to analyze the contribution of each histogram
towards verification performance, an experiment to iteratively remove the histogram with the least contribution is performed and the results are reported. In this case, the initial set of features consists of all attributes from all histograms described in Table I, and the performance in this case is reported as a baseline. In addition, the performance when each of the histogram is solely applied as a feature set is also reported. These histograms are derived at three different resolutions: 1) the one described in Table I, 2) 50% decrease from 1), and 3) 50% increase from 1).
According to the result, verification performance of skill and random forgery gradually degrades when attributes of each histogram are iteratively removed from the feature set. It implies that these histograms, when applied with the proposed verification approach, provide complimentary information that are useful for online signature verification. In addition, the degradation rate at the higher performance is noticeably lower than the one at the lower performance. This implicates the challenge of improving the system with very high performance. With respect to histogram resolution, i.e., numbers of histogram bins, the result shows that, when all the histograms are applied, verification performance of the system with the current histogram resolutions and the one with the resolutions at 50% higher are comparable. In addition, verification performance of individual histogram at the current configuration is slightly lower than the one when the resolution increases by 50%, where it is higher than the one when the resolution decreases by 50%. These infer the robustness of the proposed approach under different configurations. However, adjusting those parameters can sometimes cause disagreement between performance of random forgery and skill forgery. For example, when increasing the number of bins of X2, EER of skill forgery increases but that of random forgery decreases.
Future work to examine a method that can select those parameters holistically and optimally for both skill forgery and random forgery cases is warranted. Noting that, in this work, these parameters are defined experimentally on MCYT dataset and are used as an example of working configurations to demonstrate effectiveness of histogram features for online signature verification application against other datasets.

References
[1]A. Fallah,M. Jamaati,A. SoleamaniA new online signature verification system based on combining Mellin transform, MFCC and neural networkDigital Signal Process., vol. 21, no. 2, pp. 404–416, 2011.2011
[2]L. Findlater,J.O. Wobbrock,D. WigdorTyping on flat glass: Examining ten-finger expert typing patterns on touch surfacesProc. Annu. Conf. Human Factors Comput. Syst., New York, NY, USA, 2011, pp. 2453–2462.2011
[3]N. Sae-Bae,K. Ahmed,K. Isbister,N. MemonBiometric-rich gestures: A novel approach to authentication on multi-touch devicesProc. CHI, 2012, pp. 977–986.2012
[4]N. Sae-Bae,N. Memon,K. Isbister,K. AhmedMultitouch gesturebased authenticationIEEE Trans. Inf. Forensics Security, vol. 9, no. 4, pp. 568–582, Apr. 2014.2014
[5]L.G. Plamondon,R. PlamondonAutomatic signature verification and writer identification—The state of the artPattern Recognit., vol. 22, no. 2, pp. 107–131, 1989.1989
[6]H. Feng,C.C. WahOnline signature verification using a new extreme points warping techniquePattern Recognit. Lett., vol. 24, no. 16, pp. 2943–2951, 2003.2003
[7]A. Kholmatov,B. YanikogluSUSIG: An on-line signature database, associated protocols and benchmark resultsPattern Anal. Appl., vol. 12, no. 3, pp. 227–236, 2008.2008
[8]J. Ortega-GarciaMCYT baseline corpus: A bimodal biometric databaseIEE Proc. Vis. Image Signal Process., vol. 150, no. 6, pp. 395–401, Dec. 2003.2003
[9]L. NanniAn advanced multi-matcher method for on-line signature verification featuring global features and tokenised random numbersNeurocomputing, vol. 69, nos. 16–18, pp. 2402–2406, 2006.2006
[10]D. Guru,H. PrakashOnline signature verification and recognition: An approach based on symbolic representationIEEE Trans. Pattern Anal. Mach. Intell., vol. 31, no. 6, pp. 1059–1073, Jun. 2009.2009
[11]J. Galbally,M. Martinez-Diaz,J. FierrezAging in biometrics: An experimental analysis on on-line signaturePLOS ONE, vol. 8, no. 7, p. e69897, 2013.2013
[12]M. Faundez-ZanuyOn-line signature recognition based on VQ-DTWPattern Recognit., vol. 40, no. 3, pp. 981–992, 2007.2007
[13]J. Fierrez,J. Ortega-Garcia,D. Ramos,J. Gonzalez-RodriguezHMM-based on-line signature verification: Feature extraction and signature modelingPattern Recognit. Lett., vol. 28, pp. 2325–2334, Dec. 2007.2007
[14]E. Maiorana,P. Campisi,J. Fierrez,J. Ortega-Garcia,A. NeriCancelable templates for sequence-based biometrics with application to on-line signature recognitionIEEE Trans. Syst., Man, Cybern. A, Syst., Humans, vol. 40, no. 3, pp. 525–538, May 2010.2010
[15]E. Maiorana,P. Campisi,A. NeriTemplate protection for dynamic time warping based biometric signature authenticationProc. 16th Int. Conf. Digital Signal Process., Jul. 2009, pp. 1–6.2009
[16]L. Nanni,E. Maiorana,A. Lumini,P. CampisiCombining local, regional and global matchers for a template protected on-line signature verification systemExpert Syst. Appl., vol. 37, pp. 3676–3684, May 2010.2010
[17]M.-H. Lim,A.B.J. Teoh,K.-A. TohAn efficient dynamic reliability-dependent bit allocation for biometric discretizationPattern Recognit., vol. 45, no. 5, pp. 1960–1971, 2012.1960
[18]Y.-J. Chang,W. Zhang,T. ChenBiometrics-based cryptographic key generationProc. IEEE ICME, vol. 3. Jun. 2004, pp. 2203–2206.2004
[19]J. Fierrez-Aguilar,L. Nanni,J. Lopez-Peñalba,J. Ortega-Garcia,D. MaltoniAn on-line signature verification system based on fusion of local and global informationAudio- and Video-Based Biometric Person Authentication (Lecture Notes in Computer Science), vol. 3546. Berlin, Germany: Springer-Verlag, 2005, pp. 627–656.2005
[20]E. Argones Rua,E. Maiorana,J. Alba Castro,P. CampisiBiometric template protection using universal background models: An application to online signatureIEEE Trans. Inf. Forensics Security, vol. 7, no. 1, pp. 269–282, Feb. 2012.2012
[21]N. Sae-Bae,N. MemonA simple and effective method for online signature verificationProc. Int. Conf. BIOSIG, 2013, pp. 1–12.2013
[22]B. Schiele,J. CrowleyObject recognition using multidimensional receptive field histogramsProc. ECCV, 1996, pp. 610–619.1996
[23]Y. Qiao,J. Liu,X. TangOffline signature verification using online handwriting registrationProc. IEEE Conf. CVPR, Jun. 2007, pp. 1–8.2007
[24]W. Nelson,W. Turin,T. HastieStatistical methods for on-line signature verificationInt. J. Pattern Recognit. Artif. Intell., vol. 8, no. 3, pp. 749–770, 1994.1994
[25]L. Nanni,A. LuminiA novel local on-line signature verification systemPattern Recognit. Lett., vol. 29, no. 5, pp. 559–568, 2008.2008
[26]B. Yanikoglu,A. KholmatovOnline signature verification using Fourier descriptorsEURASIP J. Adv. Signal Process., vol. 1, p. 260516, Jan. 2009.2009
[27]U. Uludag,A. Ross,A. JainBiometric template selection and update: A case study in fingerprintsPattern Recognit., vol. 37, no. 7, pp. 1533–1542, 2004.2004
[28]A. Kholmatov,B. YanikogluIdentity authentication using improved online signature verification methodPattern Recognit. Lett., vol. 26, pp. 2400–2408, Nov. 2005. SAE-BAE AND MEMON: ONLINE SIGNATURE VERIFICATION ON MOBILE DEVICES 9472005
[29]N. Houmani,S. Garcia-Salicetti,B. Dorizzi,M. El-YacoubiOn-line signature verification on a mobile platformMobile Computing, Applications, and Services (Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering), vol. 76, M. Gris and G. Yang, Eds. Berlin, Germany: Springer-Verlag, 2012, pp. 396–400.2012
[30]P. Song,W.B. Goh,C.-W. Fu,Q. Meng,P.-A. HengWYSIWYF: Exploring and annotating volume data with a tangible handheld deviceProc. SIGCHI Conf. Human Factors Comput. Syst., 2011, pp. 1333–1342.2011
[31]P. Tome-Gonzalez,F. Alonso-Fernandez,J. Ortega-GarciaOn the effects of time variability in IRIS recognitionProc. 2nd IEEE Int. Conf. BTAS, Oct. 2008, pp. 1–6.2008
[32]D. Rankin,B.W. Scotney,P.J. Morrow,B. PierscionekIris recognition failure over time: The effects of texturePattern Recognit., vol. 45, no. 1, pp. 145–150, 2012.2012
[33]U. Park,R.R. Jillela,A. Ross,A.K. JainPeriocular biometrics in the visible spectrumIEEE Trans. Inf. Forensics Security, vol. 6, no. 1, pp. 96–106, Mar. 2011.2011
[34]I. Odinaka,P. Lai,A. Kaplan,J. O’Sullivan,E. Sirevaag,J. RohrbaughECG biometric recognition: A comparative analysisIEEE Trans. Inf. Forensics Security, vol. 7, no. 6, pp. 1812–1824, Dec. 2012.1812
[35]R. Vogt,S. SridharanExplicit modelling of session variability for speaker verificationComput. Speech Lang., vol. 22, no. 1, pp. 17–38, 2008.2008
