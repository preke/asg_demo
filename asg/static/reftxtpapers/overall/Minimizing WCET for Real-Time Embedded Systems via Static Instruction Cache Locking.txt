Minimizing WCET for Real-Time Embedded Systems via Static Instruction Cache Locking
Tiantian Liu,Minming Li,Chun Jason Xue


I. INTRODUCTION
The gap between processor and memory speed is increasing with the advance of semiconductor technology. To reduce this gap, a memory hierarchy with cache is often designed. Caches are small and fast memories which contain the most recently referenced memory blocks. These blocks are likely to be accessed again by CPU in the near future based on the temporal and spatial locality of programs. With the utilization of cache, the average-case execution times (ACETs) of programs are improved dramatically.
However, the performance evaluation of a real-time application often depends on its worst-case execution time (WCET). With cache in the processors, the program’s instructions can be cached in an instruction cache (I-Cache). The estimation of
This work is partially supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China [Project No. CityU 116907] and a grant from City University of Hong Kong [Project No. 7200106].
a program’s WCET becomes difficult and imprecise because of the dynamic miss/hit behavior of cache. WCET is most likely to be overestimated, which leads to an unnecessary increased hardware cost of real-time systems to compensate this overestimation. This problem casts a dilemma to the realtime system designers. Some of them are more apt to use processors without cache.
One of the solutions to remedy the unpredictability is to apply cache locking technique. Cache locking is to select and lock some content of a program or data in a cache. For WCET estimation, cache locking technique can effectively guarantee the precision of some cache hit/miss behaviors. Thus a tighter WCET bound could be obtained. Cache locking is supported by a wide selection of modern processors. For example, MPIS32 series [1] and Intel XScale series [2] have cache locking operations. MPC603E, MCF5249 [3] and RC64574 [4] have lock/freeze bits in their cache control registers, which can lock any single cache line content. ARM9 processor series [5], such as ARM940T and ARM920T, use a tricky way to perform the cache locking function. The cache content is allowed to be locked by setting the victim point, the replacement point of cache, to one address higher than the cache address just locked. Then, the cache replacement will not occur in the locked address. Two schemes of cache locking are possible: static and dynamic. In static locking scheme, cache contents are loaded at application start-up and remain unchanged until the application completes execution. In dynamic locking scheme, locked cache contents can change at specific reload points according to the runtime information.
This paper studies the static I-Cache locking selection problem to minimize WCET for real-time embedded systems. The application to be analyzed is denoted by an Execution Flow Tree (EFT ) with its nodes and edges representing the functions and control flows in the program respectively. The WCET of a program is the longest execution time along any path in its EFT from the starting node to an ending node. The I-Cache locking selection problem is to analyze the program during its compilation time and select a set of functions to be locked in the I-Cache. We formulate the static I-Cache locking problem to be a linear programming problem. The goal is to optimize the cache unitization with a minimized WCET for the given real-time application.
A subset of this problem with certain well-defined properties is first considered in this paper. The three properties under discussion are: no reusing, functions having the same size and nodes having the same time saving. We propose corresponding
1080-1812/09 $25.00 © 2009 IEEE DOI 10.1109/RTAS.2009.11
35
polynomial algorithms to obtain their optimal solutions. We prove that the general problem is an NP-Hard problem. Within the scope of the general problem, we identify a subset of programs with certain patterns that can be solved optimally within polynomial time. An algorithm to check whether a program fits in these patterns is presented. A polynomial time algorithm is also proposed to compute the optimal solutions for this subset. The issue that the selected functions/instructions may conflict in the cache is ignored by almost all of the related research works on I-Cache locking. We take this problem into consideration and adopt a compiler optimization technique, code placement, to eliminate the possible cache conflicts.
The experiments are conducted using carefully analyzed benchmarks under different cache sizes. The algorithms in [6] and [7] are compared with the polynomial time optimal algorithms proposed in this paper. The heuristic algorithm proposed in [7] performs close to our optimal solutions. We can also see from the results that cache size has great impact on WCET of a program.
The remainder of this paper is organized as follows. Section II presents some related work of the I-Cache locking selection problem. Section III gives the Execution Flow Tree(EFT ) model of programs and the formulation of I-Cache locking selection problem. In Section IV, we consider a subset of problems with special properties and propose polynomial time optimal algorithms for them. In Section V, we prove that the general problem is NP-Hard and also identify a subset of the general problem that can be solved in polynomial time. We consider the possibility of cache conflicts of the selected locking blocks in Section VI and utilize a code placement method to solve this problem. Section VII shows experimental results compared with some previous works. Finally we conclude this paper and point out the directions for the future work in Section VIII.

II. RELATED WORK
A lot of works have been done regarding the predictability and performance issues of caches in real-time embedded systems. Some of them consider the I-Cache locking problem.
Puaut et al. have done a series of studies about I-Cache locking. In [8], they propose two polynomial greedy algorithms to select instruction locking contents. These two algorithms have different metrics in selecting tasks and program lines. One aims at minimizing the worst-case CPU utilization, while the other aims at minimizing the interferences between tasks. Experiments show that their algorithms improve these two metrics compared with a static cache analysis method [6]. Their candidates are selected in a single set of tasks, which are the tasks along the worst-cast execution path without using cache. In [9], they compared their reference-based algorithm in [8] with a genetic algorithm for cache contents selection in [10]. Experiments show that both algorithms perform closely with respect to worst-case system utilization. The genetic algorithm performs slightly better than the reference-based algorithm with respect to the average slack time of tasks, while it has a higher time complexity.
The genetic algorithm mentioned above is proposed by Campoy et al. in [10]. This genetic idea is inspired by Darwin’s
theory of evolution and is adopted by many researchers to solve optimization problems in a variety of research fields. They initially operate on a population of potential solutions, which are individual function/instruction blocks in the ICache locking problem. At each generation, a new set of approximations is created by selecting individuals according to their levels of fitness in the problem domain and breeding them together using cross-over operators borrowed from natural genetics. In the I-Cache locking selection problem, the fitness level is weighted by the average response time of all tasks and the cross-over operators are done by randomly selecting/reducing/increasing/modifying the locked program lines. This process leads to evolutions of individuals that are better suited to their environment than their ancestors. Finally an approximately optimal solution is achieved. This method is noted for its high time complexity. Also the cross-over operators need to be further discussed.
Falk et al. point out in [7] that Puaut et al.’s algorithms do not consider the changing of worst-case path (WC-Path) after a function node is selected to be locked in I-Cache. Falk et al. take the changing of WC-Path into account during each step of the optimization procedure. They use an Execution Flow Graph (EFG) to model a program, where its nodes represent the function blocks and edges represent the control flows. They propose an algorithm for WC-Path construction with a complexity of O((|V |+ |E|) log |V |) and adopt greedy strategy to choose a node x with a maximal g(x) in each step. Here, g(x) is defined as g(x) = wx−w ′ x
sx ∗w(∗,x), where wx is
the WCET of x if x is placed in memory, w′x is the WCET of x if x is in the I-Cache, sx is the size of x in bytes, and w(∗,x) is the execution frequency of x over all contexts on the current WC-Path. This greedy algorithm can not guarantee the optimal solutions.
Asaduzzaman et al. [11] also aim at minimizing the WCET. They believe WCET has direct connection with cache miss rate. So they propose a greedy algorithm which picks the function node with the maximal miss rate in each selecting step. However, the relation between WCET and miss rate is vague and has not been proved by persuasive statement.
Previous works have not given a formal formulation of I-Cache locking selection problem. No previous work has analyzed whether there exist polynomial algorithms to obtain the optimal solutions. Most of the previous proposed heuristic algorithms use greedy strategy. Also, they ignore the problem that the selected functions may conflict when they are filled into cache according to the cache mapping strategies. In this paper, we explicitly formulate the I-Cache locking selection problem and propose polynomial algorithms to obtain optimal solutions for a subset of the programs with certain properties. We prove the general problem is NP-Hard and also identify that a subset of the general problems which exhibit special patterns can be solved optimally in polynomial time. The algorithms in [6] and [7] are compared with the optimal algorithms proposed in this paper. The experimental results show that the proposed algorithms can reduce WCETs further for real-time applications effectively under different cache sizes.

III. PROBLEM FORMULATION
A. Execution Flow Tree
An Execution Flow Tree (EFT ) is used for modeling a real-time program.
Definition 1: An EFT is a weighted tree EFT = (V, E), where V represents the set of nodes and E represents the set of edges. Let F be the set of functions in the program. Each f ∈ F is a context-specific executable code block with three attributes: w(f) is the processing time when function f is not in the cache, w′(f) is the processing time when function f is in the cache and s(f) is the size of function f . Node v ∈ V represents the real code block of the program and associates with a function f of F . Each node v has two attributes: name(v) = f where f ∈ F and count(v) representing the upper bound of how many times f is executed in the current context. Edge e(v, u) denotes a program control flow from node v to node u. It can be a sequential flow, a loop flow or a branch flow.
An example of EFT is shown in Figure 1. A function f ∈ F is a code block in a program. It has three attributes: w(f), w′(f) and s(f). The tree structure maintains the program’s control flow. A node on the tree has two attributes: name(v) ∈ F and count(v).
EFT is similar to the EFG proposed by [7]. The difference between the two is that an EFT is explicitly defined as a tree with attributes and weights only on its nodes. We can see further from the EFT ’s definition that each node v has another important attribute which can be computed using w(name(v)) · count(v) or w′(name(v)) · count(v). This is the time needed to execute the function in node v in its current context. In this paper, we use the attributes W (v) = w(name(v))·count(v) and W ′(v) = w′(name(v))·count(v) to evaluate the execution time of node v depending on whether name(v) is put in the cache. Algorithm 1 is proposed to construct an EFT from an executable program code.
In Algorithm 1, an EFT is initialized with a virtual node vroot. Then the code lines are scanned and different control flows are processed accordingly. The sequential codes are the simplest and are just treated one function within the context. For the branches, loops and calls, we recursively use Algorithm 1 to process their bodies and attach the EFTsub obtained to the main EFT . The procedures New A Function(program line(s), F ) and New A Node(f , count) respectively construct a new function f and a new node v for the EFT . New A Function(program line(s), F ) first checks whether there is already a function with the same content as the current
Algorithm 1 EFT CON(Program Code) Require: An executable program code. Ensure: An EFT (V, E) and A function set F .
V = vroot; set vroot to be active; E = ∅; F = ∅; while program line = NULL do
while program line is a sequential line do program lines∪ = program line; end while f = New A Function(program lines, F ); v = New A Node(f , 1); Add v to V as a son of V ’s current active leaves; if program line = “if” then
f = New A Function(program line, F ); v = New A Node(f , 1); Add v to V as a son of V ’s current active leaves; EFTif = EFT CON(if branch); Add EFTif as a son of v and set its active leaves to be hold; EFTelse = EFT CON(else branch) ; Add EFTelse as a son of v and set its active leaves to be hold; Set all hold leaves of v’s subtrees to be active;
end if if program line = “switch” then
f = New A Function(program line, F ); v = New A Node(f , 1); Add v to V as a son of V ’s current active leaves; for each case do
EFTcase = EFT CON(case); Add EFTcase as a son of v and set its active leaves to be hold;
end for Set all hold leaves of v’s subtrees to be active;
end if if program line = “while/for” then
f = New A Function(program line, F ); v = New A Node(f , the number of loops); Add v to V as a son of V ’s current active leaves; EFTloop = EFT CON(while/for body); Add EFTloop as a son of v;
end if if program line = “call” then
EFTcall = EFT CON(call body); Add EFTcall as a son of V ’s current active leaves;
end if if program line = “exit/halt” then
f = New A Function(program line, F ); v = New A Node(f , 1); Add v to V as a son of V ’s current active leaves; Set v to be inactive;
end if end while Remove vroot;
while there is a node v, where indegree(v) ≥ 2 do Call Duplicate(EFT , v); end while
program line(s). If so, it simply returns the current function name to the algorithm without constructing a new function. Otherwise, it constructs a new function f and assigns its w(f), w′(f) and s(f) values using the profile information. New A Node(f , count) always creates a new node v for the EFT with name(v) = f , count(v) = count, W (v) = w(name(v))·count(v) and W ′(v) = w′(name(v))·count(v) and sets this node v to be active. For “exit/halt” lines, we also use these two procedures to construct a function and a node, and add this node to EFT ’s current active leaves. We set this “exit” node to be inactive to stop this path. Then no more nodes will be attached to it afterwards. We use the flag hold to hold one of the branch paths, which should be active regarding the whole control flow but not in the current context. When all of the branches from a single starting node finish, the hold leaves of these branches will be restored to be active. Note that we use “the current active leaves” but not “the current active leaf”, because branches can lead to several different paths to be followed with. If these paths finally merge into a single common node, we introduce the duplicated nodes in [6] to further process this merging node. If a node v has an in-degree idv at least 2, we call the Duplicate(EFT , v) procedure to instantiate the substructure starting from v by idv times in the EFT . Each duplicating node represents an invocation of the associated functions.
Figure 2(a) is a segment of a benchmark “Audio beam former” [12] and Figure 2(b) is its corresponding EFT . For simplicity, the EFT ’s call functions are not processed recursively.

B. Problem Formulation of Static I-Cache Locking
The WCET optimization problem we investigate can be defined as follows. Given an I-Cache with size S and an
EFT representing a given program, we aim to put some functions into the cache so that the total size of the chosen functions does not exceed S and the length of the longest root-leaf path in EFT is minimized. Here, the length of a root-leaf path Pi = (pi0pi1 . . . pi num(Pi)) is defined as the summation of the weights of the nodes on the path, where pi0, pi1, . . . , pi num(Pi) ∈ V and num(Pi) is the number of edges on this path. The length of Pi represents the execution time needed if this path is chosen to execute in runtime. This summation is calculated as ∑num(Pi) j=0 (1 − δ(name(pij))) · W (pij) + δ(name(pij)) · W ′(pij), where δ(name(pij)) = 1 if name(pij) is put in the I-Cache and δ(name(pij)) = 0 otherwise.
We formulate the I-Cache locking problem as an integer linear programming instance as follows.
min L
s.t. ⎧⎪⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎪⎩ L − ∑num(Pi)j=0 {(1 − δ(name(pij))) · W (pij)+ δ(name(pij)) · W ′(pij)} ≥ 0 ∀ root-leaf path Pi = pi0, pi1, . . . , pi num(Pi) in EFT ∑ f∈F s(f) · δ(f) ≤ S
δ(f) ∈ {0, 1} Now what we need to decide is δ(f) for each f ∈ F to
minimize the WCET for the EFT .
IV. CONSTRAINED PROBLEM
Because the general problem is NP-Hard (It will be proved in Section V), most of the previous works focus on heuristic methods to solve the I-Cache locking selection problem. We observe that if an EFT exhibits certain properties, we can solve it optimally in polynomial time. The three properties under discussion in this section are: (1) each function can only appear once in an EFT , that means name(v) = name(u), if v = u, (2) each function has the same size and (3) each node has the same time saving when in cache. With constraint (1), different nodes represent different functions in an EFT , so we can simply use the node name as the function name for that node. In this section, we study three cases of constrained problems. First, we study the subset of problems with all these three constraints. Next, we study the problem with the first two constraints. Finally, we study the problem with constraint (1) only.

A. Each Function Has the Same Size and Each Node Has the Same Time Saving
Without loss of generality, we assume the size of each function is 1. If the time saving W (v) − W ′(v) is also the same for each node, we propose a greedy algorithm to obtain the optimal solution in this case.
The greedy algorithm is shown in Algorithm 2. It takes an EFT as input and in every step chooses the root of the current longest root-leaf path to put into the cache. WCET for each node v in the longest root-leaf path is kept using cv and
Algorithm 2 GAEFT: Greedy Algorithm for an EFT Require: An EFT (V, E), cache size S. Ensure: A set Vs of nodes in EFT to put into the cache.
i = 0; Vs = ∅; cv = W (v) for each node v in EFT ; while i < S do
Vs = Vs ∪ {v} where v is the root of a longest root-leaf path in EFT ; EFT = EFT − {v} − {(v, u)| v is u’s parent}; for every child u of v do
cu = cu + cv − (W (v) − W ′(v)); end for i = i + 1;
end while
updated in each step. We prove that this greedy algorithm can output the optimal solution.
Lemma 1: The greedy algorithm outputs the optimal solution.
Proof: Suppose the optimal solution agrees with the greedy solution in the first k steps but doesn’t agree with the greedy solution from the k + 1th step on. Suppose in the k + 1th step, the greedy algorithm chooses node v to put into the cache. If in the optimal solution, at least one of v’s descendants is chosen to put into the cache, then swapping this node out and swapping v in will not make the solution worse, while in this way the optimal solution and the greedy solution have one more match. Otherwise none of v’s descendants is chosen, then the longest root-leaf path in the subtree EFTv together with the path from the root to v will be the longest root-leaf path in the optimal solution. According to the rule we use to choose v, we can swap a node chosen by the optimal algorithm but not by the greedy algorithm out and swap v in without increasing the length of the longest root-leaf path in the solution. In this way, we can gradually change the optimal solution to the greedy solution without increasing the length of the longest root-leaf path. This finishes the proof.

B. Each Function Has the Same Size
When each node has different time saving, the greedy algorithm presented in Algorithm 2 can not output the optimal solution. A dynamic programming method is used to compute the optimal solution in polynomial time in this case.
First, the standard method is used to transform a general tree EFT into a binary tree BEFT , where first child becomes left child and next sibling becomes right child. We use EFTv to denote the subtree of EFT rooted at v. Similar symbols are used for the binary tree BEFT . The subproblems of the WCET optimization problem are defined on each subtree BEFTv of BEFT as: given cache size i (0 ≤ i ≤ S, S is the size of cache), determine the selection of nodes to put into the cache so that the maximum length of the root-leaf paths in the subtree BEFTv is minimized. Because there are in total |V | subtrees in BEFT , we know that there are |V |(S +1) subproblems. Next, we study how to
compute the optimal solution OPT (v, i) for each subproblem. Here v is the root of the subtree BEFTv we are investigating and i is the cache size allocated to this subtree. In fact, each subtree BEFTv in BEFT corresponds to a set of subtrees in EFT whose roots are subsequent siblings of v and v itself. Therefore, for subtree BEFTv, there exist the following recursive relations for a non-leaf node:
OPT (v, i) = min α(v)=0/1 { min 0≤j≤i−α(v) {max{OPT (vl, j)+ (1 − α(v)) · W (v) + α(v) · W ′(v), OPT (vr, i − α(v) − j)}}}
, where vl and vr are the left child and right child of v respectively, and α(v) = 1 if v is put in the cache and α(v) = 0 otherwise.
To see this equation more clearly, we can replace α(v) with 0 and 1 respectively to get the following equation for a non-leaf node: OPT (v, i) = minα(v)=0/1{min0≤j≤i{max{OPT (vl, j) + W (v), OPT (vr, i − j)}}, min0≤j≤i−1{max{OPT (vl, j) + W ′(v), OPT (vr , i−1−j)}}}. Here we first consider whether or not node v is selected into the cache. Then in each case, we try to assign a cache size of j (0 ≤ j ≤ i or 0 ≤ j ≤ i−1) to v’s left child and the remaining size i − j or i − 1 − j to its right child. Finally we choose the best solution among them. We can also see from its calculation that OPT (v, i) is not just the optimal solution of EFTv with cache size i, but the optimal solution for EFTv and the subtrees rooted at v’s subsequent siblings as discussed above. For example, if a node v is the first child of node u in the EFT , then the set of subtrees involved will be all the subtrees attached to u.
Based on the above analysis, a dynamic programming algorithm is presented in Algorithm 3 which can compute the optimal solution in polynomial time. Some boundary values are defined as follows.
OPT (v, i) = 0 if v does not exist; OPT (v, i) = OPT (v, 1) = W ′(v) if v is a leaf and i > 0; OPT (v, 0) = W (v) if v is a leaf. In Algorithm 3, the choice we make under each circumstance is kept using a structure array OPT [|V |][S + 1]. Each OPT [v][i] keeps the optimal solution of the subproblem OPT (v, i) we defined above by three variables: OPT V alue, Cachable and Left Get, which respectively represent the minimized WCET of this subtree, whether or not node v is selected to the cache and the cache size allocated to its left child for this subproblem. When all of the OPT [v][i] are obtained, we use procedure GetTrack() to find the final solution and record it in the final solution array δ[|V |].
Lemma 2: The dynamic programming algorithm outputs the optimal solution in O(|V |S2) time.
Proof: For a leaf node v, we use the initialization OPT (v, 0) = W (v) and OPT (v, i) = OPT (v, 1) = W ′(v) when i > 0, which is the optimal solution for subtree EFTv.
For internal nodes, we use the recursive equation OPT (v, i) = minα(v)=0/1{min0≤j≤i{max{OPT (vl, j) + W (v), OPT (vr, i − j)}}, min0≤j≤i−1{max{OPT (vl, j) + W ′(v), OPT (vr , i− 1 − j)}}} and try to assign any allowed cache size j (0 ≤ j ≤ i or 0 ≤ j ≤ i− 1) to v’s left child and
Algorithm 3 ISEFT: I-Cache Selection for an EFT Require: An EFT (V, E), cache size S. Ensure: A set of nodes in EFT to put into the cache.
BEFT =Transform(EFT ); Initialize OPT [|V |][S + 1].OPT V alue = −1; Call OptimizeIt(BEFT.root, S, OPT ); Call GetTrack(OPT , BEFT.root, S, S, δ[|V |]);
procedure OptimizeIt(v, i, OPT ) if OPT [v][i].OPT V alue = −1 then
OPT [v][i].OPT V alue = min α(v)=0/1 { min 0≤j≤i−α(v) {max{ OptimizeIt(vl, j, OPT ) + (1 − α(v)) · W (v) + α(v) · W ′(v), OptimizeIt(vr, i − α(v) − j, OPT )}}};
OPT [v][i].Cachable = argα(v) min α(v)=0/1 { min 0≤j≤i−α(v) {max {OptimizeIt(vl, j, OPT ) + (1 − α(v)) · W (v) + α(v) · W ′(v), OptimizeIt(vr, i − α(v) − j, OPT )}}};
OPT [v][i].Left Get = argj min α(v)=0/1 { min 0≤j≤i−α(v) {max{ OptimizeIt(vl, j, OPT ) + (1 − α(v)) · W (v) + α(v) · W ′(v), OptimizeIt(vr, i − α(v) − j, OPT )}}};
end if return OPT [v][i].OPT V alue; end procedure
procedure GetTrack(OPT , v, i, S available, δ[|V |]) if S available ≤ 0||i ≤ 0||v = NULL then
return; end if if OPT [v][i].Cachable = 1 then
δ[v] = 1; S available−−;
end if GetTrack(OPT , vl, OPT [v][i].Left Get, S available, δ[|V |]); GetTrack(OPT , vr, i − OPT [v][i].Cachable − OPT [v][i].Left Get, S available, δ[|V |]); end procedure
the remaining size i−j or i−1−j to its right child. Since we enumerate all the possible cache allocation schemes for node v and its left and right children, and under each scheme we utilize the optimal solutions of its left and right children, we can guarantee the minimum OPT (v, i). That is the optimal solution for node v under cache size i.
Because each subproblem can be solved in O(S) time, by enumerating all the 2S − 1 possible cache allocation decisions, we conclude that the running time of Algorithm 3 is O(|V |S2).
C. Functions Have Different Sizes
When function size can be different (but must be integers), and the cache size is a constant integer S, the above dynamic programming algorithm with a minor modification on the recursive relation can still obtain an optimal solution.
OPT (v, i) = min α(v)=0/1 { min 0≤j≤i−α(v)·s(v) {max{OPT (vl, j)+ (1 − α(v)) · W (v) + α(v) · W ′(v), OPT (vr, i − α(v) · s(v) − j)}}}
The procedure GetTrack() also needs to be modified accordingly. The modified dynamic programming algorithm can compute the optimal solution in O(|V |S2) time.
V. GENERAL PROBLEM
A. NP-Hard
We investigate the general problem in this section. For the general problem, one function could be called by different nodes in an EFT . In other words, name(u) could be equal to name(v) even when u = v. This scenario is denoted as reusing in this paper. If we put a function f in the cache, then for every node v satisfying name(v) = f , their real execution time will be W ′(v). We prove that this problem is NP-Hard by a reduction from the set cover problem.
Given an instance of set cover problem with the universe {e1, e2, . . . , en} and a set of subsets {S1, S2, . . . , Sm}, we are required to find whether there are k subsets that can cover all the elements. We construct an instance of our problem as follows. The tree T consists of n root-leaf paths of length m which only overlap at the root (each path pi = v0vi1vi2 . . . vim represents an element ei). We define the name function to be name(vij) = Sj if ei ∈ Sj and name(vij) = vij otherwise. Furthermore name(v0) = S0. We let w(Sj) be equal and w′(Sj) be 0 for 0 ≤ j ≤ m. Then, we let s(Sj) = 1 for 0 ≤ j ≤ m and s(vij) = k if ei /∈ Sj . Finally the size of cache is k + 1.
We can see that having a size k set cover solution is equivalent to having a solution of the constructed I-Cache locking selection problem with the longest path length at most (m − 1)w(S0).
An example of the construction is shown in Figure 3 for the following set cover problem:
The universe: {e1, e2, e3, e4, e5}. The subsets: {S1, S2, S3, S4, S5, S6}, where S1 = {e1, e2, e3}, S2 = {e3, e4}, S3 = {e1, e4, e5}, S4 =
{e2}, S5 = {e3}.
B. A Subset of General Problem
Note that the reusing can be classified into two different types. One is a real reusing when a function is called in different places of a program, while the other is the consequence of the duplicating method in Algorithm 1 applied to a merging node in an EFT . Although the duplicating method makes EFT a tree, it introduces reusing nodes which make optimal solutions hard to find. However, when we go back to the original control graph without duplicating process, we find some interesting patterns, shown in Figure 4, which also have branch-and-merge properties but can be solved using a dynamic programming method.
Let’s call the directed graph produced by Algorithm 1 without the duplicating process an Execution Flow Graph (EFG). This EFG is different from EFG in [7], where there are values associated with edges. It is similar to CCG in [13]. The main difference is that in our problem domain, one function can only appear once in the graph. Therefore, we will use node name as its function name in this section. Figure 4(a) and (b) show parts of EFGs. Node D, node 6 and node 7 have more than one parents and will be duplicated under the EFT model. These patterns have some characteristics that enable the problem to be solved in polynomial time using a bottom up dynamic programming method. As shown in this example, each branch-and-merge has very regular structures. Paths from a branch node will merge into and only merge into a single merging node. Meanwhile the merging node has and only has paths incoming from the same branch node.
First, we propose an algorithm, PCEFG, to check whether an EFG exhibits this special pattern. Algorithm PCEFG is presented in Algorithm 4.
Algorithm 4 PCEFG: Pattern Checking for an EFG Require: An EFG(V, E). Ensure: Whether or not this EFG exhibits the special pat-
tern. while EFG is not a tree do
Vsingle = {v ∈ V |indegree(v) = outdegree(v) = 1}; Psingle = EFG|Vsingle ; (In other words, Psingle is the set of paths in the EFG so that each node on the paths is in Vsingle .) Let Pv = {p ∈ Psingle|(v, startp) ∈ E}; (startp is the first node in the directed path p.) Let P ′u = {p ∈ Psingle|(endp, u) ∈ E}; (endp is the last node in the directed path p.) if for some u and v, Pv = P ′u and |Pv| > 1 then
Let the nodes contained in Pv be Vv; In EFG, Replace EFG|Vv∪{u,v} with a new node vnew;
else Return FALSE;
end if end while Return TRUE;
Algorithm PCEFG checks an EFG for branch-and-merge pattern in different levels. When we find an elemental pattern as shown in Figure 4(a), we merge these nodes into a new node and add it to the original EFG. Finally, if we can merge each branch-and-merge pattern and finally get a tree, we say that this EFG fits in the special pattern.
When we check an EFG, we can also keep track of each branch-and-merge part of the EFG, from the simplest ones to the nested ones. We can keep those patterns in a queue and compute their optimal solutions in the order specified by the queue. Note that these optimal solutions are the minimum WCET for these patterns only, not for the whole EFG. In this way, whenever we are computing the optimal solution for a big pattern, we can guarantee that the optimal solutions for the smaller subproblems needed in the computation have already been computed.
Now we look at a specific elemental pattern to see how to compute its optimal solution with a cache size of i. Suppose that the elemental pattern starts with node v and ends at node u. Every node in this pattern can further be a merged node computed by Algorithm 4. The elemental pattern can be transformed into an EFT with root v and every root-leaf path ending at a duplicate of u. For the function u, we can either put it in the cache or not. For both of these two cases, we can use a modified ISEFT algorithm to compute an optimal solution for the choice of other nodes in the pattern given a cache size i (u is not put in the cache) or i − s(u) (u is put in the cache). The smaller of these two optimal solutions plus the corresponding u’s time will be the optimal solution for this elemental pattern. The recursive equation in Algorithm ISEFT
is modified as:
OPT (v, i) = min 0≤p≤i { min 0≤j≤i−p {max{OPT (vl, j) + Weightv[p] , OPT (vr, i − p − j)}}}
, where p and j represent how many cache size is allocated to node v and its left child vl respectively. Because each node v can be a merged node which actually represents a small elemental pattern nested in the current one, we replace (1 − α(v)) · W (v) + α(v) · W ′(v) with Weightv[p], which is the optimal WCET for the pattern represented by a merged node v with cache size p. Weightv[p] is obtained before this iteration of computation.
With the method to compute the optimal solution for each elemental pattern, we can solve the WCET minimization problem on an EFG that exhibits the special pattern using Algorithm 5.
Algorithm 5 ISEFG: I-Cache Selection for an EFG Require: An EFG(V, E), cache size S. Ensure: A set of nodes in EFG to put into the cache.
Initialize OPT [|V |][S + 1].OPT V alue = −1; Initialize Weight[|V |][S + 1] = −1; Initialize EFT = EFG; EFT = GMergeIt(EFG, Weight); BEFT = Transform(EFT ); Call GOptimizeIt(BEFT.root, S, OPT );
procedure GOptimizeIt(v, i, OPT ) if OPT [v][i].OPT V alue = −1 then
OPT [v][i].OPT V alue = min 0≤p≤i { min 0≤j≤i−p {max{ GOptimizeIt(vl, j, OPT ) + Weight[v][p], GOptimizeIt(vr, i − p − j, OPT )}}};
OPT [v][i].OPT Cachable = argp min 0≤p≤i { min 0≤j≤i−p {max{ GOptimizeIt(vl, j, OPT ) + Weight[v][p], GOptimizeIt(vr, i − p − j, OPT )}}};
OPT [v][i].OPT LeftGet = argj min 0≤p≤i { min 0≤j≤i−p {max{ GOptimizeIt(vl, j, OPT ) + Weight[v][p], GOptimizeIt(vr, i − p − j, OPT )}}};
end if return OPT [v][i].OPT V alue; end procedure
The GMergeIt(EFG, Weight) procedure in Algorithm 5 first checks whether the input EFG fits in the patterns using Algorithm 4, and then computes WCET of each pattern in the EFG. It also merges the pattern into a new node and adds the new node back to the pattern’s place in the EFG according to
the order in Algorithm 4. It will return an EFT when all of the patterns are computed and merged. Then the following part is similar with Algorithm ISEFT with only small modifications of the recursive equations. Because each node v can be a merged node, the recursive relation of Algorithm 5 is modified as OPT (v, i) = min0≤p≤i{min0≤j≤i−p{max{OPT (vl, j) + Weightv[p], OPT (vr, i−p−j)}}}, where Weightv[p] is the optimal WCET with cache size p for this merged node and has already been calculated by GMergeIt() procedure. In this way, the optimal solutions for the subset of general problem can be computed. The complexity of Algorithm 5 is O(|V |S2).
VI. CACHE CONFLICT
Little care has been given to cache models in our discussion so far. Our algorithms are carried out during compilation time and before the program execution. When applying the cache locking techniques we discussed in Section I to lock the selected functions into an I-Cache, we will encounter another problem, cache conflicts, no matter what the cache architecture is. For example, in Figure 2, if we choose function v1 and v5 to be locked into cache, this may not be viable because v1 and v5 may be mapped to the same cache block based on the underlying cache mapping strategy.
Some researches [14] [15] [16] have been conducted to solve the cache conflict problem, but they are geared toward different goals compared with the problem we are solving. Their goal is to minimize the conflict rate for a program by carefully selecting functions into cache or repositioning part of the programs. In our problem, we already decide which part of the program to fill into the cache and we also know where the conflict might take place.
Two techniques are often utilized to solve the cache conflict problem: code reordering and code placement/relayout. Code reordering requires to reorder the source code’s blocks/lines to get a more suitable code order for the cache, while the code placement/relayout does not need to modify the source code but only repositions the code blocks/lines in the physical memory. Code reordering is not suitable for our problem, because modifying the source code will lead to modifications of an EFT which will make our original selection invalid. We can apply the code placement technique proposed in [15] for our problem. This code placement technique is based on the assumption that the I-Cache is direct-mapped, but can also make sense for set-associative caches. It has two phrases: cache placement and memory placement. Cache placement phase assigns cache addresses to minimize cache conflicts. It can decide a placement for each function in the cache. Then the memory placement phase assigns final memory address under the cache placement constraints. In our problem setting, we utilize memory placement algorithm proposed in [15] to find better positions for the functions of a program. The STRING-MERGE algorithm [15] can avoid cache conflicts as well as minimize the total code size in memory.
VII. EXPERIMENTAL RESULTS
This section presents the experimental results to illustrate the effectiveness of the algorithms proposed in this paper.
The benchmarks used in our experiments are presented in Table I. This group of benchmarks are used in previous studies by various research groups (SNU [17], MRTC [18]). The SPEC benchmarks, realistic I/O applications or internet applications are not suitable for WCET analysis because they contain too many unbounded loops, recursion, indirect calls or I/O operations, which will make the WCET prediction impossible[16].
We group the benchmarks into two sets. SET1 includes those benchmarks without function duplicating and reusing. This property allows us to apply the algorithm in Section IV-C to obtain their optimal solutions. The algorithm discussed in Section IV-C applies to EFT s with functions of different sizes. It is denoted as Algorithm ISEFTD in this experiment section. SET2 consists of benchmarks with function duplicating but without reusing. These benchmarks exhibit the patterns we discussed in Section V-B. We use Algorithm 5: ISEFG to calculate their optimal solutions.
Experiments are conducted on these benchmarks under different conditions. The results are compared with the static WCET analysis proposed in [6] and Falk et al.’s greedy algorithm proposed in [7].
A. WCET under Different Cache Sizes
Algorithm ISEFTD and Algorithm ISEFG are executed on SET1 and SET2 respectively under different cache sizes. In Figure 5 and Figure 6, Y-axis represents the normalized WCET time, and X-axis represents the given I-Cache size. The base of comparison is the corresponding static WCET analysis results [6]. Their analysis did not utilize cache locking technique but gave each function a reliable prediction of cache miss/hit rate.
As can be seen from Figure 5 and 6, our I-Cache locking selection algorithm can achieve significant WCET reduction for all cache sizes. Even when the cache size is only 64 bytes, the algorithms can still select some small but WCETcritical functions to be locked in the I-Cache. With the increase of cache size, the WCET reduction of different benchmarks increases in different slopes. Some curves improve relatively smoothly. For example, FIR1 in SET1 and Binary Search in SET2. This is because there are small functions lying on the WCET-critical path. In some cases, some curves fall steeply. For example, the curve between cache size 2048 bytes and 4096 bytes of Fibonacci in SET1. This is due to the sharp increase of cache size. When the cache size is greater than the
program size, the locking selection will be the whole function set of the program and the minimum WCET is achieved. For example, minimum WCET for Matrices Multiply and Searching Matrix are 29% and 24% of the static analysis results respectively.
B. Comparison with Falk et al.’s Greedy Algorithm [7]
We also compare our work with the current best known heuristic algorithm by Falk et al. [7]. Though we only compare our approach to Falk et al.’s greedy algorithm, Falk et al have previously shown that their algorithm is superior to the algorithms proposed by Puaut et al.. The results are presented in Figure 7 and Figure 8. The static analysis results are still our comparison base. The results of both algorithms are presented as percentages of the static analysis results. We fix the cache size to be 1024 bytes so that the differences can be shown clearly.
We can see from Figure 7 and 8 that for some benchmarks, the greedy algorithm proposed by Falk et al. [7] obtains the same results as the optimal solutions calculated by our algorithms. That is because the heuristic algorithm [7] considers the cost saving and function size at the same time and it can achieve optimal solutions for some applications. Our algorithms can be used as a reference to see how good the previous heuristic solutions perform.
VIII. CONCLUSION
This paper studies the static I-Cache locking problem to minimize WCET for real-time embedded system applications.
We propose an EFT to model a real-time application and formulate the I-Cache locking selection problem as a linear programming problem. Several polynomial time optimal algorithms are proposed to solve problems with certain welldefined properties. The general problem is proved to be an NPHard problem. We also identify a subset of the general problem with some regular patterns that can be solved optimally within polynomial time, and present the corresponding polynomial time algorithm. We take the cache conflict problem into consideration and adopt a code placement method to resolve it. The experiments comparing with previous algorithms show that our algorithms can reduce WCET effectively.
In the future, we will study the dynamic I-Cache locking problem during program’s execution time. Data cache locking problem is also our interest. Our goal will focus on the WCET reduction for real-time embedded applications.
REFERENCES
[1] MIPS: http://www.mips.com/. [2] Intel: http://www.intel.com/design/intelxscale. [3] Motorola: http://www.motorola.com/. [4] IDT (Integrated Device Technology): http://www.idt.com/ [5] ARM: http://www.arm.com/ [6] F. Mueller, Timing analysis for instruction caches. Real-Time Systems,
18(2): 217-247, 2000. [7] Heiko Falk, Sascha Plazar, Henrik Theiling, Compile-Time Decided In-
struction Cache Locking Using Worst-Case Execution Paths. In Proceedings of the 5th IEEE/ACM international conference on Hardware/software codesign and system synthesis: 143-148, 2007. [8] Isabelle Puaut, David Decotigny, Low-Complexity Algorithms for Static Cache Locking in Multitasking Hard Real-time Systems. In Proceedings of the 23rd IEEE Real-Time Systems Symposium (RTSS’02): 114-123, 2002.
[9] Antonio Marti Campoy, Isabelle Puaut, Angel Perles Ivars, Joes Vicente Busquets Mataix,Cache contents selection for statically-locked instruction caches: an algorithm compparision. In Proceedings of the 17th Euromicro Conference on Real-Time Systems (ECRTS’05): 49-56, 2005. [10] A.M. Campoy, A. P. Ivars, and J. V. Busquets-Mataix, Using genetic algorithms in content selection for locking-caches. In Proceedings of the IASTED International Symposium on Applied Informatics: 271-276, 2001. [11] Abu Asaduzzaman, Niranjan Limbachiya, Imad MahgoubFadi N. Sibai, Evaluation of I-Cache Locking Technique for Real-Time Embedded Systems. Innovations in Information Technology 2007: 342-346, 2007. [12] StreamIt: http://www.cag.lcs.mit.edu/streamit/shtml/benchmarks.shtml [13] AbsInt Angewandte Informatik GmbH, Worst-Case Execution Time
Analyzer aiT for ARM. 2006. [14] Ann Gordon-Ross, Frank Vahid, Nikil Dutt, A first look at the interplay
of code reordering and configurable caches. In Proceedings of the 15th ACM Great Lakes symposium on VLSI: 416-421, 2005. [15] Christophe Guillon, Fabrice Rastello, Thierry Bidault,Florent Bouchez, Procedure Placement using Temporal-Ordering Information: dealing with Code Size Expansion. Journal of Embedded Computing, 1(4): 437-459, 2005. [16] Christophe Guillon, Fabrice Rastello, Thierry Bidault,Florent Bouchez, Improving WCET by Applying a WC Code-Positioning Optimization. ACM Transactions on Architecture and Code Optimization, 2(4): 335-365, 2005. [17] SNU(Seoul National University): http://www.useoul.edu/ [18] MRTC: http://www.mrtc.mdh.se/projects/wcet/home.html

References
[1]F. MuellerTiming analysis for instruction cachesReal-Time Systems, 18(2): 217-2472000
[2]Heiko Falk,Sascha Plazar,Henrik TheilingCompile-Time Decided Instruction Cache Locking Using Worst-Case Execution PathsIn Proceedings of the 5th IEEE/ACM international conference on Hardware/software codesign and system synthesis:2007
[3]Antonio Marti Campoy,Isabelle Puaut,Angel Perles Ivars,Joes Vicente BusquetsMataix,Cache contents selection for statically-locked instruction caches: an algorithm compparisionIn Proceedings of the 17th Euromicro Conference on Real-Time Systems2005
[4]A.M. Campoy,A.P. Ivars,J.V. Busquets-MataixUsing genetic algorithms in content selection for locking-cachesProceedings of the IASTED International Symposium on Applied Informatics: 271-2762001
[5]Abu Asaduzzaman,Niranjan Limbachiya,Imad MahgoubFadi N. SibaiEvaluation of I-Cache Locking Technique for Real-Time Embedded Systems. Innovations in Information Technology2007
[6]Ann Gordon-Ross,Frank Vahid,Nikil DuttA first look at the interplay of code reordering and configurable cachesIn Proceedings of the 15th ACM Great Lakes symposium on VLSI:2005
[7]Christophe Guillon,Fabrice Rastello,Thierry Bidault,Florent BouchezProcedure Placement using Temporal-Ordering Information: dealing with Code Size ExpansionJournal of Embedded Computing,2005
[8]Christophe Guillon,Fabrice Rastello,Thierry Bidault,Florent BouchezImproving WCET by Applying a WC Code-Positioning OptimizationACM Transactions on Architecture and Code Optimization,2005
