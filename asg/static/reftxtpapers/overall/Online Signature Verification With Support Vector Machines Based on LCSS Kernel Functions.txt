Online Signature Verification With Support Vector Machines Based on LCSS Kernel Functions
Christian Gruber,Thiemo Gruber,Sebastian Krinninger
sick@fim.uni-

Abstract
In this paper, a new technique for online signature verification or identification is proposed. The technique integrates a longest common subsequences (LCSS) detection algorithm which measures the similarity of signature time series into a kernel function for support vector machines (SVM). LCSS offers the possibility to consider the local variability of signals such as the time series of pen-tip coordinates on a graphic tablet, forces on a pen, or inclination angles of a pen measured during a signing process. Consequently, the similarity of two signature time series can be determined in a more reliable way than with other measures. A proprietary database with signatures of 153 test persons and the SVC 2004 benchmark database are used to show the properties of the new SVM-LCSS. We investigate its parameterization and compare it to SVM with other kernel functions such as dynamic time warping (DTW). Our experiments show that SVM with the LCSS kernel authenticate persons very reliably and with a performance which is significantly better than that of the best comparing technique, SVM with DTW kernel.

I. INTRODUCTION
AUTHENTICATION of a person’s identity is a needin many social and commercial interactions. It can be achieved in various ways, for example, using a birth certificate, a passport, or the knowledge of a personal identification number. Very often, signatures are used for authentication. In most cases, a given signature is compared to a single reference signature with the naked eye. Thus, this method is prone to impostors. Electronic image-based techniques (so-called offline signature verification) can also be outsmarted quite easily. However, as authentication by signature is widely accepted compared to other techniques such as fingerprint or iris scan, there is a need for a signature verification technique that ensures a high level of security. Biometric signature verification techniques based on the dynamics of a person’s signature, i.e., time series of pen-tip coordinates, writing forces, or inclination angles of a pen, are, in principle, able to provide a reliable authentication (so-called online signature verification). However, in contrast to many other biometric authentication techniques, signatures of a person may be very variable. This makes the verification process—which can basically be seen as a twoclass classification problem (a given signature belongs to a certain person or not)—quite difficult. Signature verification is closely related to signature identification, where the identity of a person must be determined by comparing a signature sample to all reference samples or models in a database, for instance.
Support vector machines (SVM) are widely used to solve classification and regression problems. As they provide very good results in various pattern recognition fields, they also seem to be a good choice for online signature verification. Compared to other classifier paradigms, such as neural networks, fuzzy classifiers, or decision trees, SVM—which are based on the principle of structural risk minimization—have major advantages, such as a convex objective function with efficient training algorithms and good generalization properties. SVM use kernel functions to measure the similarity of two data objects, in our case, time series. However, standard kernel functions such as Gaussian or polynomial kernels are not well suited for timeseries processing. The key contribution of this paper is the definition of a new kernel function for SVM based on an LCSSs detection for time series that even outperforms kernels based on hidden Markov models (HMM) and dynamic time warping (DTW) in the particular application field. An LCSSbased similarity measure is tailored to deal with the specific variability of online signature data, and it could be used in various online signature verification or identification systems.
The remainder of this paper is organized as follows: First, we will discuss some specific characteristics of time series that describe the dynamics of handwriting (online signature data) in Section II. In Section III, related work in the application field and in the field of time-series classification with SVM is presented. Section IV describes the new LCSS-based kernel function for online signature verification. In Section V, this method is evaluated in a number of experiments and also compared to other methods. Finally, Section VI summarizes the major findings.

II. CHARACTERISTICS OF ONLINE SIGNATURE DATA
In this section, we describe some characteristics of online signature data. For online verification, the dynamics of a person’s signature are captured by means of some special recording device (e.g., a graphic tablet or a special pen equipped with sensors). Typically, the signature is represented by a multivariate time series consisting of, e.g., the pen-tip coordinates on a tablet, writing forces, or inclination angles. Different signatures of a person are typically more or less similar, but not identical.
1083-4419/$26.00 © 2009 IEEE
The differences are, however, usually not global in the sense that an overall linear transformation of the various dimensions of the multivariate time series to a common domain and/or range would help to compare different signatures in order to state whether they can be attributed to the same person. Rather, these differences—examples will be given below—occur locally. This local variability constitutes the particular challenge of online signature verification.
In a signature of a person, sometimes whole characters are skipped or added, yielding missing or additional subsequences (i.e., “outlier” subsequences) in the recorded time series. Furthermore, the order in which strokes of a “t” or dots on an “i” are written may vary or they could be even left out. Fig. 1 shows two signatures of the first author with corresponding force signals. It can be seen that the number of loops within this signature varies. Here, the forces on the refill (cf., Section V-A) are measured in two directions that are orthogonal to each other and orthogonal to the refill. Similar observations, however, can be made in time series of pen-tip coordinates or inclination angles, for instance.
Different physical or mental conditions of a person typically have a more or less noticeable effect on the recorded time series as well. We investigated the influence of temperature, physical strain, and alcohol on handwriting in [1]. Although, for example, the movements of the hand and the arm are basically the same if a person is ill, tired, or not affected in any way, the amplitude of the writing force and the writing speed may differ significantly. If a person is stressed, for instance, the signature may be carried out faster and less accurately.
As shown in Fig. 2, influences—with typically unknown causes—may even have different effects on different parts of a
signature. This figure shows the force signals (only direction x) of two signatures. It can be seen that they locally differ in their amplitudes. Local variability also occurs in the time domain, of course.
Figs. 1 and 2 also show that a linear rescaling on the time axis to a certain length or a normalization of all signal values would not be appropriate if the similarity of two signatures must be measured numerically.
Sensor noise, transmission errors, and the like may have additional influences. Single sensor measurements, for example, may be distorted noticeably.
In addition, signature verification is a field where a classifier typically has to be trained with a relatively low number of genuine signatures, i.e., signatures of the person that have to be recognized (e.g., between five and ten).
Altogether, the following challenges must be mastered: 1) local variability in the time domain; 2) local variability in the range (codomain); 3) hardware errors; 4) low number of training samples for one of the two classes. The last point will be addressed by an appropriate classifier paradigm. Basically, SVM are able to cope with this problem. The other points will be addressed by a new similarity measure for time series which is tailored to measure the similarity of online signature time series. This measure (LCSS) will be used as kernel function of an SVM. However, it could also be used in combination with other classifier paradigms.

III. RELATED WORK
In this section, we will first summarize some related work in the application field of online signature verification before we discuss the state-of-the-art in the field of time-series classification with SVM.

A. Online Signature Verification
Overviews of techniques for off- or online signature verification can be found in [2]–[6], for instance. Most publications in the field of online signature verification use standard graphic tablets (e.g., [7]–[11]). These devices offer the advantage to be reliable and robust as they are commercially available since a long time. However, the resolutions of the sensors and the sampling rates vary significantly. Pens that are independent from a specific writing surface (e.g., a tablet) are utilized in [12]–[14], for example. The specific characteristics of online signature data (cf., Section II) occur in any case, i.e., independent from a specific kind of input device.
In many publications, the (preprocessed) sensor signals are classified with neural networks such as multilayer perceptrons, radial basis function neural networks, time-delay neural networks, or self-organizing maps (e.g., in [9], [15], [16]). HMM or other models with probabilistic background are taken in [8], [17]–[21], for instance. In addition, DTW or similar techniques based on dynamic programming are often applied, e.g., in [7], [10], [22]–[25]. Other classifier paradigms such as k-nearest neighbor methods or SVM are investigated in [8], [11]–[14], [26]. Multistage techniques or classifier ensembles such as mixture of experts or competing experts are taken in [8], [18], [27]–[29]. Altogether, we can state that it is well recognized that local variability must be taken into account. It is common to all approaches that they must measure the similarity of signature time series to come to a classification decision.
Regarding the verification accuracy, it can be noticed that a comparison of related work is extremely difficult. Not only the writing devices and the classifier paradigms are very different but also the data sets and evaluation techniques. In [5], we cited and evaluated more than 100 publications in the field of online signature verification. We stated that researchers published equal error rates (EER) between 0.25% and 11% for so-called random forgeries (signatures of randomly selected other persons) and between 0.00% and 24% for skilled forgeries (signatures of trained “impostors”). The number of persons, which a database comprises, varies between 1 and 330, the number of available skilled forgeries varies between 0 and 7000, and, finally, the number of genuine signatures utilized to train a classifier varies between 3 and 200. In this paper, we found that it is quite easy to get very good results with a number of genuine signatures higher than about ten. In addition, almost arbitrarily good results can be obtained with a data set comprising only a few persons, e.g., less than 25. Data sets with 90 or more test persons are used in a few publications only (see, e.g., [7]–[11], [30]). Public benchmark databases for online signature verification are MCYT [31] and SVC 2004 [32], [33], which will also be considered in one experiment in this paper. The supply of really skilled forgeries for testing purposes, i.e., forgeries that are provided by trained, motivated persons, is also a major problem in the context of signature verification (cf., e.g., [34]).
We want to emphasize that we focus on a new classification technique that is based on a novel time series similarity measure tailored to online signature data and its specific characteristics. Therefore, we must investigate the properties of this approach by comparing it to other time series similarity measures used in the application field.

B. Time-Series Classification With SVM
In this section, we discuss some related work in the field of time-series classification with SVM.
In general, time-series classification can be realized with many machine learning or data mining paradigms such as decision trees or neural networks. We will focus on SVM here because of their excellent generalization abilities which are due to the principle of structural risk minimization (see, e.g., [35]–[37]).
Basically, SVM use a hyperplane to separate two classes [38]. For classification problems that cannot be linearly sepa-
rated in the input space, SVM find a solution using a nonlinear mapping from the original input space into a high-dimensional so-called feature space, where an optimally separating hyperplane is searched. A hyperplane that has a maximal margin is called optimal, whereas the term “margin” refers to the distance between the separating hyperplane and the closest (mapped) input samples, the support vectors. The transformation is usually realized by a nonlinear kernel function. Basically, a kernel function measures the similarity between an input of the SVM and a support vector. Often, Gaussian or polynomial kernels are used. C-SVM or ν-SVM allow, but also minimize misclassification. The parameters C and ν control the penalization of misclassification during training. In our case, the input samples of an SVM as well as the support vectors are multivariate time series or any characteristic attributes extracted from that time series.
An overview and comparison of methods for time-series classification with SVM can be found in [39] or [40], for instance. One common method for classifying time series with SVM is to use one of the standard kernel functions (i.e., polynomial or Gaussian kernels). For speaker verification [41], phonetic classification [42], or instrument classification [43], this has successfully been done. A big disadvantage of this approach is that these kernels are unable to deal with time series of different lengths. Therefore, it is necessary to rescale the time series to a common length or to extract a fixed number of attributes before these kernels can be applied. It is obvious that this rescaling is not optimally suited to deal with time series of variable length if linear scaling functions are not applicable which is the case here (cf., Section II). The reduction to a set of attributes, on the other hand, fails if these attributes do not contain all the information that is essential for the classification. Another approach is to use methods that directly compare the data points of two time series in a more flexible way, for example, with tangent distance [44], time alignment [45]–[47], or DTW kernels [48]. A discrete version of the LCSSs algorithm is used in [49] to determine the tendency similarity of two time series. Combined with a so-called local similarity measure this information is used in a kernel function for online signature verification with SVM. In addition, probabilistic models, such as HMM and Gaussian mixture models (GMM), that are trained on the time-series data, can be used in conjunction with SVM. The so-called Fisher kernels have been widely used, e.g., for the classification of DNA fragments [50] or proteins [51], [52], speech recognition [53], [54], speaker identification [55]–[57], or web audio classification [58]. In [59] and [60], another similarity measure applicable to GMM, the Kullback–Leibler divergence, is used for speaker identification and verification as well as image classification.
Existing techniques for time-series classification with SVM such as DTW kernels consider local variability of online signature data (cf., Section II) quite well, but we think that improvements are still possible. Thus, we introduce a new kernel function.

IV. KERNEL FUNCTION FOR SVM BASED
ON AN LCSSs DETECTION
In this section, we will first introduce a basic similarity measure for time series and discuss how it must be modified to meet our requirements for signature verification. Then, we propose an algorithm that measures the similarity of two multivariate
signature signals by determining the length of so-called LCSSs. Finally, we show how this measure can be used as a kernel function for SVM.

A. Basic Similarity Measure for Time Series
We are given two univariate time series (sequences) S = (s1, . . . , s|S|) and T = (t1, . . . , t|T |) with si, tj ∈ R and lengths |S| and |T |, respectively. Without loss of generality we assume that |S| ≤ |T |. The values within a sequence origin from equidistant points in time, which is common in many applications. Thus, we do not need explicit time stamps.
For given values of two parameters γ, ∈ R+ with γ ≤ 1, the two sequences S and T are called (γ, )-similar, if two temporally ordered, but not necessarily connected subsequences S ′ = (si1 , . . . , si γ·|S| ) and T
′ = (tj1 , . . . , tj γ·|S| ) with ik < ik+1 and jk < jk+1 (for k = 1, . . . , γ · |S| − 1) exist, such that with an appropriate distance measure d the following predicate holds for all k = 1, . . . , γ · |S| :
d (sik , tjk) ≤ . (1) Typically, d is the Euclidean distance. While describes the required similarity of the two sequences, γ is the relative length of the so-called common subsequence of S and T for a given .
For a given , there are typically many such common subsequences and we are interested in those (there may also be several) with maximal length. Such a subsequence, which is called LCSS, may be used to describe what we call the -similarity of the two sequences:
Sim (S, T ) = 2 · |S| · max {γ|S, T are (γ, )-similar}
|S| + |T | . (2)
An example for the correspondence of the values of two sequences is set out in Fig. 3. Here, two (artificial) sequences are drawn which have for = 0.2 an LCSS with length seven. The length of the shorter subsequence is ten, i.e., Sim0.2(S, T ) = 2/3. The figure also shows the corresponding values of the two sequences.
Multivariate Time Series: Multivariate time series must be processed in signature verification and many other application fields, i.e., we are given S = (s1, . . . , s|S|) and T = (t1, . . . , t|T|) with si, tj ∈ RN (N ∈ N). One possibility to determine the similarity of two multivariate sequences, which is adopted here, it to compute the similarity in each dimension separately and to average the results: For each dimension
n = 1, . . . , N , we compute Sim (Sn, Tn) for the univariate sequences S ′n and Tn. Then
Sim (S,T) = 1 N N∑ n=1 Sim (Sn, Tn). (3)
Alternatively, it would be possible to consider the maximum or minimum of the similarities of the univariate time series, to extend (1), e.g., by introducing individual thresholds for the various dimensions, etc.
Normalization: If two univariate sequences are both normalized—i.e., rescaled to the unit interval [0, 1]—before their similarity is measured, the parameter ∈ [0, 1] may be interpreted as the required degree of similarity. In this case, we write Sim N (S, T ), whereas the index N indicates the normalization. In the multivariate case—yielding Sim N (S,T)—each dimension is normalized individually, i.e., with possibly different scaling factors. As a consequence, it becomes possible to get along with only one value for in all dimensions. Another advantage of this normalization will become clear in the following sections, when different subsequences of a time series are normalized with possibly different scaling factors.

B. Some Remarks on Local Variability
In Section II, it became clear that a measure, which is suitable to evaluate the similarity of online signature signals numerically, must consider various specific properties of such signals.
1) It must be possible to neglect certain subsequences which exist due to, e.g., additional loops or only sometimes drawn dots on an “i,” or the like. 2) Very short “outlier” subsequences due to sensor or transmission errors, for instance, must be accepted. 3) It is necessary to account for locally different amplitudes of the signals which occur, for example, as a consequence of slightly varying forces during a signing process.
While remark 1 will be considered by an algorithm that determines LCSSs in the sense of Section IV-A, we must modify our notion of LCSSs to take remarks 2 and 3 into account. The algorithm introduced in the following section determines the length of an LCSS approximately. It considers remarks 2 and 3 by counting the length of very short nonmatching sequences and allowing locally different scaling factors for the normalization, respectively.

C. Algorithm for LCSS Computation
With the following algorithm, it becomes possible to determine the similarity of two multivariate signature signals S and T. Originally, the idea of LCSS has been developed for pattern recognition in time-series databases [61], but we modify it significantly here to account for the specific requirements of our application field. The algorithm consists of four steps.
1) Step 1: Determination of all short, similar pairs of subsequences of S and T having a certain length. This step leads to a set of so-called atomic matchings. 2) Step 2: Fusion of atomic matchings considering some side conditions. This step leads to so-called connected matchings of S and T.
3) Step 3: Computation of a not necessarily connected longest matching (LCSS) from the set of connected matchings by concatenating connected matchings. 4) Step 4: Evaluation of the similarity of S and T by determining the length of an LCSS of the two signals.
These steps will now be explained in more detail. Step 1—Atomic Matchings: We are given two multivariate sequences S and T and two parameters ω ∈ N with ω min{|S|, |T|} and ∈ [0, 1]. A pair (Si,Tj) consisting of connected subsequences Si = (si, . . . , si+ω−1) from S and Tj = (tj , . . . , tj+ω−1) from T, both having length ω, is called an atomic matching, if, according to (3)
Sim N (Si,Tj) = 1. (4)
If a pair (Si,Tj) is an atomic matching, we denote that case with (Satomici ,T atomic j ).
In a brute force approach, the existence of an atomic matching would be checked for all pairs of connected subsequences from S and T having length ω. As there are |S| − ω + 1 possible subsequences in S and |T| − ω + 1 in T, altogether (|S| − ω + 1) · (|T| − ω + 1) pairs would have to be checked. However, for signature verification, this number can be reduced substantially. As we want to determine the similarity of the overall sequences, it is not necessary, for example, to compare a subsequence at the beginning of one sequence to a subsequence near the end of the other sequence. If the two sequences origin from signatures of the same person, it is very likely that similar subsequences occur at similar positions. Therefore, we introduce a window technique: For a subsequence Si, the search for atomic matchings is restricted to all subsequences Tj with j ∈ [ i/|S| · |T| − δ, i/|S| · |T| + δ] (cf., Fig. 4). The parameter δ should depend on the length of the sequences, e.g., δ = 0.05 · |T|.
Step 2—Connected Matchings: The result of step 1 is a set Aatomic of all atomic matchings. As we want to determine the length of the LCSSs, we determine longer, but still connected matchings in step 2. This is done by fusing atomic matchings that fulfill some conditions. For that purpose, we have to examine certain subsets of Aatomic: Let Ãatomic be a subset of Aatomic containing an arbitrary number M of atomic matchings. Ãatomic = {(Satomici1 ,Tatomicj1 ), . . . , (SatomiciM ,TatomicjM )} must be a totally ordered set in the sense that im−1 < im and jm−1 < jm for all m = 2, . . . , M . The atomic matchings within Ãatomic are fused to a connected matching if one of the following two conditions is fulfilled for all im and jm.
• Condition 1: The atomic matchings (Satomicim−1 ,T atomic jm−1 )
and (Satomicim ,T atomic jm ) do not overlap in S and T and
their distance in S as well as in T is smaller than a given threshold ρ ∈ N (cf., Fig. 5). In other words
0 ≤ (im) − (im−1 + ω) ≤ ρ (5) 0 ≤ (jm) − (jm−1 + ω) ≤ ρ. (6)
• Condition 2: The atomic matchings (Satomicim−1 ,T atomic jm−1 )
and (Satomicim ,T atomic jm ) do overlap in S as well as T with the same overlapping length (ϑ ∈ N in Fig. 6). In other words
(im−1 + ω) − im = (jm−1 + ω) − jm. (7)
Fusing the atomic matchings in Ãatomic yields a connected matching (Sconni1 ,T conn j1
) with Sconni1 = (si1 , . . . , siM+ω−1), which is a connected subsequence of S, and Tconnj1 = (tj1 , . . . , tjM+ω−1), which is a connected subsequence of T.
Condition 1 considers very short nonmatching sequences as mentioned in remark 2 on local variability (cf., Section IV-B). As the length of these sequences will still be considered in the following steps, they are still contained in the connected subsequences. These nonmatching sequences may have different lengths in S and T. As a consequence, Sconni1 and T conn j1
may have different lengths, too. To determine a subset of atomic matchings to be fused in this step, the subsequences of length ω are all rescaled to the unit interval (i.e., normalized), but with possibly different scaling factors. Thus, it is possible to consider slightly varying amplitudes of the signals according to remark 3 on local variability (cf., Section IV-B).
Step 3—Longest Matchings (LCSSs): The result of step 2 is a set Cconn of all connected matchings. In step 3, we now determine the longest, but not necessarily connected matchings. This is done by concatenating connected matchings that fulfill a certain condition. For that purpose, we have to examine certain subsets of Cconn: Let C̃conn =
{(Sconni1 ,Tconnj1 ), . . . , (SconniK ,TconnjK )} be a subset of Cconn containing an arbitrary number K of connected matchings. This subset C̃conn must be a totally ordered set in the following sense (which is different from the meaning of a totally ordered set utilized in step 2): For all k = 2, . . . , K
ik−1 + ∣∣∣Sconnik−1 ∣∣∣ ≤ ik (8) jk−1 + ∣∣∣Tconnjk−1 ∣∣∣ ≤ jk. (9)
In other words, the last points in time of Sconnik−1 and T conn jk−1
must precede the initial points in time of Sconnik and T conn jk , respectively (no overlapping is allowed). The connected matchings in C̃conn are concatenated to an LCSS, also referred to as longest matching, if the following condition is fulfilled:
• Condition 3: C̃conn has maximum length K∑
k=1
∣∣Sconnik ∣∣ + ∣∣Tconnjk ∣∣ (10)
among all totally ordered subsets of Cconn. Basically, there could be several subsequences for which condition 3 holds, but as we are only interested in their length (cf., step 4), only one of them must be determined. This LCSS will be denoted by (Slongesti ,T longest j ).
Slongesti and T longest j may be unconnected subsequences of S and T with gaps of arbitrary length. Due to these gaps, certain subsequences (outlier subsequences) may be neglected for the similarity measurement according to remark 1 on local variability (cf., Section IV-B).
Step 4—Similarity Measurement: With an LCSS (Slongest, Tlongest), it is possible to measure the similarity of two sequences S and T in the following way:
SimLCSS(S,T) = |Slongest| + |Tlongest|
|S| + |T| . (11)
We call SimLCSS ∈ [0, 1] a similarity measure as it yields low values for very different time series and high values otherwise. It is not a distance measure in a strong sense as it is not induced by a metric.

D. LCSS as Kernel Function for SVM
A kernel function can be regarded as a measure for the similarity of two patterns (cf., Section III-B). In our case, patterns are the multivariate time series S and T. With the similarity measure defined in (11), we immediately get a kernel function KLCSS with
KLCSS(S,T) = SimLCSS(S,T). (12)
SVM with the LCSS kernel will be called SVM-LCSS in the following.
The kernel function defined in (12) does not fulfill the Mercer condition [62] completely. While the kernel matrix is symmetric, it cannot be guaranteed that it is positive definite. We could observe in our experiments that a slight violation of this condition sometimes occurs. However, with the efficient and numerically stable optimization (training) technique sequential
minimal optimization (SMO, cf., [63]) and a small extension for kernels which are not positive definite (cf., [64]) it can be guaranteed that the value of the objective function can be improved in each step. This ensures convergence, but possibly in a local optimum. The libsvm library [65], which we adapted for this paper, uses this SMO extension. More information about so-called non-Mercer or non-PSD (positive semidefinite) kernels can be found in [66]–[68], for instance.
The similarity measurement with LCSS is time and memory extensive. For two sequences S and T with lengths |S| and |T|—without loss of generality, we assume that |S| ≤ |T|—the time and the memory complexity are both O(|T|4). This complexities mainly result from step 1 and 3. In step 1, the similarities of O(|T|2) subsequences of S and T have to be computed yielding O(|T|2) atomic matchings in the worst case. In addition, in a worst case scenario, if no connected matchings can be determined in step 2, the computation of the LCSS using topological sorting is performed on a graph with O(|T|2) vertices and O(|T|4) edges. The actual temporal effort for signature verification will be evaluated in the following section.

V. EXPERIMENTS
In this section, we aim at answering the following questions:
• How must the LCSS kernel be parameterized and is it robust with respect to minor variations of the parameter values? • How does it perform in comparison to various other kernels, e.g., a kernel based on DTW? • Can it be used for different kinds of online signature data (e.g., data obtained with special pens or graphic tablets)? • How many genuine signatures are needed to train a reliable SVM-LCSS classifier?
We first shortly describe the hardware used for our experiments, the benchmark data set we have collected, and the preprocessing steps. Then, we set out the experimental conditions and evaluation criteria and discuss the results of a number of experiments which will answer the questions above. Finally, we briefly discuss some questions that arise when an SVM-LCSS would be integrated into a real signature verification system.

A. Writing Device, Benchmark Data Set, and Preprocessing
The Biometric Smart Pen (BiSP) is a novel ballpoint pen for the acquisition of biometric features based on handwriting dynamics [12], [29]. The device is equipped with a diversity of sensors to measure the dynamics of forces transferred in three dimensions from the refill to the force sensors and to measure the hand movements by means of two inclination angles. The forces resulting from handwriting are monitored in two orthogonal directions x and y by strain gauges placed close to the front part of the refill. In a third orthogonal direction (z), defined by the axis of the refill, the dynamics of the force are measured by a piezoelectric sensor located at the end of the refill. The signals from these sensors are digitized with a 10-b A/D converter at a sampling frequency of 500 Hz. The movement of the hand holding the pen is also characterized by the inclination angles α and β measured with tilt sensors. The sampling rate is 125 Hz and the signals are digitized by a 10-b A/D converter, too. Altogether, the BiSP provides a 5-D time
series consisting of forces x and y, force changes z, as well as inclination angles α and β (cf., Fig. 7 for an example).
With the BiSP, we collected the benchmark data for our experiments from 153 persons. About 80% were students with an age between 20 and 30, about 20% were female, and about 16% were left handed, i.e., genuine signatures are available for 153 persons. These persons attended either one session (53 persons) or two sessions at different days (100 persons) and provided six signature samples in each session. Ten of those 100 test persons provided another six signature samples in a third session.
For our experiments, the data were preprocessed with the following steps as described in [5]: Cutting (parts of the time series before and after a signature are deleted), offset removal (a constant offset is subtracted from the signal values), and resampling (to a fifth of the original length). As the measured forces and inclination angles of the BiSP depend on its rotation along the axis of the refill (z), an additional coordinate system transformation was done to compensate this influence, i.e., the forces in x- and y-directions and the inclination angles are transformed (detailed formulas can be found in [5]).

B. Experimental Results
Basically, we used and extended the C-SVM implementation of the libsvm library [65] for our experiments. The parameter C has been set as suggested in [69]. In order to obtain reliable results for independent test data, we conducted and evaluated five repetitions of each experiment with disjoint training and test data sets. If not stated otherwise, classifiers for each person were trained by means of six randomly selected genuine signatures and 35 random forgeries, i.e., randomly selected signatures of other persons, i.e., we train two-class classifiers that must separate genuine signatures for a specific person from any other signatures. Tests were carried out with the remaining genuine signatures of that person and random forgeries of other persons. To assess the experiments, we determined false acceptance rates (FAR), false rejection rates (FRR), EER, receiver operating characteristic (ROC) curves, and run times. The results were obtained using a PC with an Intel Core 2 Duo processor running at 2.13 GHz and 4-GB main memory. More details on the experimental conditions and some more results can be found in [5].
Parameterization of the LCSS Kernel Function: In a first set of experiments, we want to investigate the influence of the most important parameters of the new LCSS kernel function, namely,
Basically, we conducted experiments with almost all combinations of ω ∈ {10, 20, 30, 40}, ∈ {0.05, 0.1, 0.15, 0.2, 0.25}, and ρ ∈ {0, 2, 5, 10, 15, 20}. Only for ω = 10 and ≥ 0.15 the run-times turned out to be very high. Parameters were optimized with respect to 50 of the 153 persons of the overall data set. We could state that if two of the parameters are fixed, we get an approximately convex curve for the third. Thus, it is quite easy to find an appropriate parameterization of this kernel function. Fig. 8 shows, as an example, one of the curves for . Table I gives the EER for various values of ω and ρ in combination with either = 0.25 (top), = 0.20 (middle) or = 0.05 (bottom). The values = 0.2, ω = 20, and ρ = 10 are used for the following experiments.
It is not surprising that really bad EER can be obtained for low values of in combination with high values of ω, i.e., when the required similarity is high and the length of atomic subsequences is high. The influence of ρ (maximum overlapping length) is much lower. Figs. 9 and 10 show the ROC curves for = 0.2 while either ω or ρ are varied.
The results presented so far—with the best EER being 0.41% on independent test data—have been obtained without applying any window technique. The preprocessed time series of signatures have a length of between 133 and 1813 for the 153 persons in our database. Thus, we conducted experiments with δ ∈ {10, 25, 50, 100, 250} for a comparison to δ = ∞ (no window). As set out in Fig. 11, there is a tradeoff between the time which is necessary for the verification, i.e., the application of a trained classifier, and the EER. A value of δ = 100 seems to be a suitable compromise, as the EER is only about 0.03%
higher than for δ = ∞. However, in the following experiments, we keep the initial value δ = ∞.
It must be emphasized that in the following the parameter values of , ω, ρ, and δ are kept fixed. This means, in particular, that they are identical for all persons.
Comparison to Other Kernel Functions: In a second set of experiments, we will compare various kernel functions that realize similarity measures for signature time series in order to investigate whether the LCSS kernel is able to outperform other kernel functions.
We trained classifiers for those 100 persons for which data from two sessions are available and tested with data of all 153 persons. Parameters of the kernel functions are optimized as described in [5], but we use the same parameterization for all persons. The following classifier paradigms were chosen.
• SVM-CONV are standard SVM with Gaussian kernels [62], [70]. In this conventional approach, we use input attributes selected from a large set of possible attributes with the sequential forward generation algorithm based on the information gain measure. The set of possible attributes comprises attributes such as the length of the signature, the pen-up time, skew, kurtosis, coefficients of a Fourier transform, etc., extracted either for the overall time series or segments of the time series. • SVM-EUCLID are again SVM with Gaussian kernels, but here, the Euclidean distance within the kernel does not measure the similarity of attribute vectors but the similarity of the time series themselves. For that purpose, all time series have to be resampled to a common length. In a very exhaustive set of time-series experiments including a comparison of 12 (dis-)similarity measures for time series published in [71], the Euclidean distance turned out—quite surprisingly—to be one of the best. • SVM-HMM are SVM with the Fisher kernel as described in [50]. A person-specific segmentation technique [5] is used to preprocess the time series. The HMM are trained with the Baum–Welch algorithm, and they have an LR topology. HMM, but not in combination with SVM, are frequently used in related work on online signature verification (cf., Section III-A). • SVM-DTW are SVM that are based on the DTW algorithm. This kernel function (cf., [48], [72]) supports local variability on the time axes very well. DTW, although not in combination with SVM, is also frequently used in related work on online signature verification (cf., Section III-A). • SVM-LCSS is the SVM with the LCSS kernel as described in the previous section. We use the parameterization found in the first set of experiments.
SVM-CONV and SVM-EUCLID were chosen as they can be regarded as a kind of “baseline” methods. We claim that any classifier which is based on similarity measures tailored to the specific needs of online signature data should perform better than these. SVM-HMM and SVM-DTW were chosen as they employ time series similarity measures that are widely used in the field of online signature verification or identification. As we use all time series similarity measures as kernel functions of SVM, this allows for a fair comparison of these different measures.
EER, FAR, and FRR (with the corresponding variances σ2FAR and σ2FRR) are set out in Table II. Due to the large number of persons for which classifiers were trained (100), the number of five repetitions of each experiment, and the large number of test signatures for each trained classifier (310), the numbers given in the table are based on an evaluation of 155 000 test signatures each. For the computation of FAR and FRR, the standard thresholds of the classifiers were not modified, i.e., the decision boundary was not relocated. It was relocated to determine the EER.
Comparing the two “baseline” techniques SVM-CONV and SVM-EUCLID, it can be noticed that SVM-CONV yields significantly better overall results. This is not surprising in view of the fact that the computationally trivial approach SVMEUCLID does not consider local variability at all. Even more unexpected may be the observation that SVM-HMM does not
outperform the first two classifiers. This might be due to the fact that—in contrast to related work where HMM typically perform better—we do not use x- and y-coordinate signals of a graphic tablet which are much easier to segment. We should also mention that the parameterization of SVM-HMM turned out to be quite difficult. The performance of all three classifiers is far from being good enough for practical applications. This changes significantly with the use of DTW as a kernel function. With SVM-DTW, the values of the performance criteria EER, FAR, and FRR can be reduced substantially. DTW considers the local variability of online signature much better than the first three classifiers. An additional advantage of this approach is that appropriate parameter values can be found more easily. Nevertheless, with the new SVM-LCSS, these results can be improved further. For this paradigm, which considers all aspects of local variability, all criteria given in Table II have the lowest values. It can be stated that the new approach is actually well suited for online signature verification concerning its classification performance.
Fig. 12 shows the ROC curves for the two best paradigms: SVM-DTW and SVM-LCSS.
The run times for the training of a classifier as well as for its application (i.e., the verification of one person) are evaluated in Tables III and IV, respectively. It can be stated that the run time of SVM-LCSS is not as bad as we could expect from the theoretical analysis (cf., Section IV-D) but it actually is the highest of all paradigms in our comparison. However, verification times of about 1.5 s would be acceptable for many practical applications. It should be mentioned again that this time could be reduced substantially with the window technique (see above) which was not applied here. The training of a classifier needs typically not be done under harsh timing conditions.
Utilization of Another Input Device: In a third set of experiments, we apply SVM with three different kernel functions
to a data set which is based on another kind of input device, a graphic tablet. We will investigate whether our conclusions concerning SVM-LCSS also hold for another kind of online signature data. Therefore, we compare SVM-LCSS to the best comparing method from above (SVM-DTW) and the trivial “baseline” method SVM-EUCLID.
We applied the three paradigms to the SVC 2004 signature verification benchmark data set (see [32] and [33] for more details). This data set contains signature data of a graphic tablet (Wacom Intuos) with 20 genuine signatures and 20 skilled forgeries per person of which ten of the genuine signatures are reserved for training purposes. Our experiments were conducted according to the competition rules and the testing protocol for signature verification (task 2 of the publicly available training subset of 40 users which was also tested in the competition). First, five reference signatures for every person were randomly picked from the set of genuine training signatures. In the training phase, classifiers were built for every person taking the five reference signatures as positive and 35 random forgeries taken from other persons’ reference signatures as negative examples. These classifiers were afterward tested against 10 genuine signatures and 20 random or skilled forgeries, respectively. Training and tests were repeated ten times using a different set of randomly selected reference signatures in each trial. On the basis of the test performance of every single classifier, the mean and the standard deviation of the EER were determined.
Results of the experiments can be found in Table V. First, it can be noticed that SVM-EUCLID leads to better EER for skilled and random forgeries than SVM-DTW. Second, SVMLCSS—which allows outlier subsequences with data points that are not assigned at all—outperforms the two other measures again. Both, EER and standard deviations are significantly lower. One reason for this behavior could be the following weakness of the DTW similarity measure for two time series
(cf., Section VI): Every data point of one time series must be assigned to a data point of the other time series. It should be emphasized that the optimal parameter values for the LCSS kernel (regarding the EER) are nearly identical to the ones used for the BiSP data set. The main reason for differences is a different sampling rate of the graphic tablet used for the SVC data. Altogether, these results show that SVM-LCSS can be used for data measured with other input devices as well.
A comparison of the aforementioned results to results of the competition for which the SVC data set was provided would not be fair insofar as we did not yet exploit many optimization possibilities for our approach (see the discussion below). However, we want to mention some results of other approaches: The competition results summarized in [33] range between 6.90% and 21.89% average EER for skilled forgeries and between 3.02% and 8.75% average EER for random forgeries, respectively. The following results obtained with the SVC data set were published later: [73] (using DTW and HMM) reports average EER of 6.91% and 0.15% for skilled/random forgeries, respectively, and [20] obtains 4.83% for a proprietary experimental setup with skilled and random forgeries (using HMM). This is remarkable for two reasons: First, the trivial and extremely fast approach SVM-EUCLID outperforms many of the solutions published so far. Second, SVM-LCSS competes with the best results published so far even if it is not yet fine tuned.
Number of Genuine Signatures Needed for Training: In a final set of experiments, we will investigate how many genuine signatures are required for a reliable verification with SVM-LCSS.
The number of genuine signatures necessary to train a classifier is quite important in a real application. In the following experiments, we trained classifiers for those ten persons for which genuine signatures from three sessions are available (and tested again with samples drawn from the overall data set of 153 persons). The number of genuine signatures used is between three and ten. The curves of FAR and FRR shown in Fig. 13 show that the FRR can be reduced substantially with ten instead of six genuine signatures which is the number we used in all experiments so far. With ten genuine signatures, the FRR is only 0.75%, whereas the FAR% is 0.00%.
Certainly, the number of genuine signatures that can be expected from a user depends on the specific application. In some safety-critical applications, it might be reasonable to reduce the FAR at the cost of an increase of the FRR. In this case, it would make sense to allow a second or even a third try in the case of a rejection. If a signature gets accepted—and is not revoked or withdrawn within a certain time (e.g., several days)—it could
be used to improve a reference model incrementally. Thus, it would be possible to start with a small number of genuine signatures expected from a user (about three or four) and to have a subsequent “customization phase” when second or third tries are sometimes necessary.
Discussion of Some Applicability Issues: The main goal of this section was to show that the LCSS similarity measure is well suited to capture the specific characteristics of online signature data. If a paradigm such as SVM-LCSS is utilized, for example, in a real access control system, some additional optimization aspects may be considered to improve the performance of this system.
1) For each person that registers with the system, optimal LCSS parameter values could be determined. This would only affect the run time for training but not for application of a trained classifier. Such a “personalization” or “individualization” is common in verification systems. In addition, parameters such as the cost parameter C of the C-SVM or the decision threshold may be individually optimized. 2) The “quality” of a signature could be checked during the registration process and persons could be asked to sign with first and last name instead of only using the last name, for instance. This could help to reduce problems with very short signature time series or, more generally, with low-quality data (cf., [21]). 3) When a signature is accepted by the system, it could later be used to train the classifier of that person incrementally. Thus, long-term changes of handwriting could be considered appropriately. The idea to synthesize training signature data from available genuine signatures (cf., e.g., [74]) may also help to improve the classification performance in a “customization” phase (start-up phase). 4) Several classifiers may be combined in form of ensembles to reduce the variance of training results (cf., e.g., [75]). In [5], we have shown that results can be improved by combining SVM-DTW and SVM-LCSS, for instance. 5) It might be difficult for some users to accept that their signature is somehow stored—in our case in a preprocessed form as support vectors. Certain privacy protection policies might explicitly prohibit the storage of signature even in a preprocessed, abstract form. Therefore, we suggest to use handwritten passwords—which also reflect the individuality of handwriting—instead of signatures. In contrast to signatures, a user is able to change a password at any time she or he wants (cf., the concept known as “cancelable biometrics” [76], [77]). As the variability of passwords is lower, this might also improve the performance of the system (cf., [5]).
To assess the performance of a verification system, it is also necessary to conduct tests with skilled forgeries (cf., [5] for the BiSP data set).

VI. CONCLUSION AND OUTLOOK
In this paper, a new kernel function for SVM has been proposed and applied to online signature verification. This kernel function measures the similarity of two time series by determining the length of an LCSS. In order to obtain meaningful results, we used a data set with more than 100 test persons,
applied some other classifier paradigms on the same training and test data, used a realistic number of genuine signatures to train a reference model, and evaluated several performance criteria. The experiments showed that the new technique, SVMLCSS, is able to authenticate persons very reliably even if only six genuine signatures are used for training. It turned out that the LCSS-based similarity assessment of online signature data is even superior to DTW-based techniques. The main reason is that SVM-LCSS is specifically designed to account for the local variability of the dynamics of handwriting. Thus, we can master the various challenges set out in Section II. One main difference of LCSS and DTW is shown in Fig. 14: DTW requires that for every value of one time series a corresponding point of the other time series must be found. LCSS allows that values are not assigned at all. Thus, outlier sequences can be considered.
Currently, we use the BiSP also in medical applications (see, e.g., [78] and [79]), for example, to detect side effects of drugs. With new fast time-series segmentation techniques [80], we aim at reducing the run time of the LCSS algorithm significantly, which is very important for signature identification, for instance. Furthermore, we will apply the SVM-LCSS to other time-series classification tasks with similar properties.
ACKNOWLEDGMENT
The authors would like to thank the members of the BiSP team of the University of Applied Sciences, Regensburg (Germany). C. Hook, J. Kempf, G. Scharfenberg, and G. Schickhuber provided us with the BiSP and their ongoing support; A. Berl who implemented parts of the framework for our experiments; and M. Bauer who conducted one of the experiments. The authors would like also to thank the suggestions of the anonymous reviewers who helped us to improve the quality of this paper.
REFERENCES
[1] C. Gruber and B. Sick, “Comparison of biometric writing systems for the analysis of human fine motor skills,” in Proc. IEEE Three Rivers Workshop Soft Comput. Ind. Appl., 2007, pp. 49–54. [2] A. McCabe, “Implementation and analysis of a handwritten signature verification technique,” Ph.D. dissertation, James Cook Univ. North Queensland, Townsville, Australia, 1997. [3] R. Plamondon and S. Srihari, “Online and off-line handwriting recognition: A comprehensive survey,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 1, pp. 63–84, Jan. 2000.
[4] G. Dimauro, S. Impedovo, M. Lucchese, R. Modugno, and G. Pirlo, “Recent advancements in automatic signature verification,” in Proc. 9th IWFHR, 2004, pp. 179–184. [5] C. Gruber, “Online-Unterschriftenverifikation Basierend auf Methoden des Maschinellen Lernens,” Ph.D. dissertation, Univ. Passau, Passau, Germany, 2009. [6] D. Impedovo and G. Pirlo, “Automatic signature verification: The state of the art,” IEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 38, no. 5, pp. 609–635, Sep. 2008. [7] A. Kholmatov and B. Yanikoglu, “Biometric authentication using online signatures,” in Proc. ISCIS, vol. 3280, LNCS, C. Aykanat, T. Dayar, and I. Körpeolu, Eds., Berlin, Germany, 2004, pp. 373–380. [8] J. Fierrez-Aguilar, N. Loris, J. Lopez-Penalba, J. Ortega-Garcia, and D. Maltoni, “An on-line signature verification system based on fusion of local and global information,” in Proc. AVBPA, vol. 3546, LNCS, T. Kanade, A. K. Jain, and N. Ratha, Eds., Berlin, Germany, 2005, pp. 523–532. [9] H. Lv and W. Wang, “On-line signature verification based on dynamic Bayesian network,” in Proc. ICNC, vol. 4221, LNCS, L. Jiao, L. Wang, X. Gao, J. Liu, and F. Wu, Eds., Berlin, Germany, 2006, pp. 507–510. [10] D. Muramatsu, M. Kondo, M. Sasaki, S. Tachibana, and T. Matsumoto, “A Markov chain Monte Carlo algorithm for Bayesian dynamic signature verification,” IEEE Trans. Inf. Forensics Security, vol. 1, no. 1, pp. 22–34, Mar. 2006. [11] Z.-H. Quan, D.-S. Huang, X.-L. Xia, M. Lyu, and T.-M. Lok, “Spectrum analysis based on windows with variable widths for online signature verification,” in Proc. 18th ICPR, 2006, vol. 2, pp. 1122–1125. [12] C. Hook, J. Kempf, and G. Scharfenberg, “A novel digitizing pen for the analysis of pen pressure and inclination in handwriting biometrics,” in Proc. BioAW, vol. 3087, LNCS, D. Maltoni and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 283–294. [13] C. Gruber, T. Gruber, and B. Sick, “Online signature verification with new time series kernels for support vector machines,” in Proc. ICB, vol. 3832, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2006, pp. 500–508. [14] C. Gruber, M. Coduro, and B. Sick, “Signature verification with dynamic RBF networks and time series motifs,” in Proc. 10th IWFHR, 2006, pp. 455–460. [15] P. Mautner, V. Matousek, T. Marsalek, and O. Rohlik, “Comparison of ART-2 and SOFM based neural network verifiers,” in Proc. 1st ANNs: Data Preparation Tech. Appl. Develop., 2004, pp. 43–50. [16] N.-N. Liu and Y.-H. Wang, “Fusion of global and local information for an on-line signature verification system,” in Proc. 7th ICMLC, 2008, pp. 57–61. [17] J. J. Igarza, L. Gomez, I. Hernaez, and I. Goirizelja, “Searching for an optimal reference system for on-line signature verification based on (x, y)-alignment,” in Proc. ICBA, vol. 3072, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 519–525. [18] B. Ly Van, S. Garcia-Salicetti, and B. Dorizzi, “Fusion of HMM’s likelihood and Viterbi path for on-line signature verification,” in Proc. BioAW, vol. 3087, LNCS, D. Maltoni and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 318–331. [19] J. Wen, B. Fang, Y. Y. Tang, and T. Zhang, “Model-based signature verification with rotation invariant features,” Pattern Recognit., vol. 42, no. 7, pp. 1458–1466, Jul. 2009. [20] B.-L. Van, S. Garcia-Salicatti, and B. Dorizzi, “On using the Viterbi path along with HMM likelihood information for online signature verification,” IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1237–1247, Oct. 2007. [21] J. Fàbregas and M. Faundez-Zanuy, “On-line signature verification system with failure to enrol management,” Pattern Recognit., vol. 42, no. 9, pp. 2117–2126, Sep. 2009. [22] P. Fang, Z. Wu, F. Shen, Y. Ge, and B. Fang, “Improved DTW algorithm for online signature verification based on writing forces,” in Proc. ICIC—Part I, vol. 3844, LNCS, D.-S. Huang, X.-P. Zhang, and G.-B. Huang, Eds., Berlin, Germany, 2005, pp. 631–640. [23] Z. Wu, P. Fang, and F. Shen, “Online signature verification based on global feature writing forces,” in Proc. ICB, vol. 3832, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2006, pp. 516–522. [24] C. Vivaracho-Pascual, M. Faundez-Zanuyy, and J. M. Pascual, “An efficient low cost approach for on-line signature recognition based on length normalization and fractional distances,” Pattern Recognit., vol. 42, no. 1, pp. 183–193, Jan. 2009. [25] W.-D. Chang and J. Shin, “DPW approach for random forgery problem in online handwritten signature verification,” in Proc. 4th NCM, 2008, pp. 347–352.
[26] S. Sayee, R. Besar, and N. Kamel, “Dynamic signature verification using sensor based data glove,” in Proc. 8th ICSP, 2006, vol. 2, pp. 2387–2390. [27] B. Kar, P. K. Dutta, T. K. Basu, C. Vielhauer, and J. Dittmann, “DTW based verification scheme of biometric signatures,” in Proc. IEEE ICIT , 2006, pp. 381–386. [28] L. Wan, B. Wan, and Z.-C. Lin, “On-line signature verification with two stage statistical models,” in Proc. 8th ICDAR, 2005, vol. 1, pp. 282–286. [29] C. Gruber, C. Hook, J. Kempf, G. Scharfenberg, and B. Sick, “A flexible architecture for online signature verification based on a novel biometric pen,” in Proc. IEEE SMCals, 2006, pp. 110–115. [30] A. K. Jain, F. D. Griess, and S. D. Connell, “On-line signature verification,” Pattern Recognit., vol. 35, no. 12, pp. 2963–2972, Dec. 2002. [31] J. Ortega-Garcia, J. Fierrez-Aguilar, D. Simon, J. Gonzalez, M. Faundez-Zanuy, V. Espinosa, A. Satue, I. Hernaez, J.-J. Igarza, C. Vivaracho, D. Escudero, and Q.-I. Moro, “MCYT baseline corpus: A bimodal biometric database,” in Proc. Inst. Elect. Eng.—Vis., Image Signal Process., Dec. 2003, vol. 150, no. 6, pp. 395–401. [32] D. Yeung, H. Chang, Y. Xiong, S. George, R. Kashi, T. Matsumoto, and G. Rigoll, “SVC 2004: First international signature verification competition,” in Proc. ICBA, vol. 3072, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 16–22. [33] D. Yeung, H. Chang, Y. Xiong, S. George, R. Kashi, T. Matsumoto, and G. Rigoll, SVC 2004: First International Signature Verification Competition, 2004. [Online]. Available: http://www.cse.ust.hk/svc2004/ results.html [34] F. M. L. Ballard and D. Lopresti, “Forgery quality and its implications for behavioral biometric security,” IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1107–1118, Oct. 2007. [35] V. N. Vapnik, “An overview of statistical learning theory,” IEEE Trans. Neural Netw., vol. 10, no. 5, pp. 988–999, Sep. 1999. [36] B. Schölkopf, C. J. C. Burges, and A. J. Smola, Advances in Kernel Methods. Cambridge, MA: MIT Press, 1998. [37] P.-H. Chen, C.-J. Lin, and B. Schölkopf, “A tutorial on ν-support vector machines,” Appl. Stochastical Syst. Business Ind., vol. 21, no. 2, pp. 111– 136, 2003. [38] C. J. C. Burges, “A tutorial on support vector machines for pattern recognition,” Data Mining Knowl. Discovery, vol. 2, no. 2, pp. 121–167, Jun. 1998. [39] V. Wan and S. Renals, “Evaluation of kernel methods for speaker verification and identification,” in Proc. IEEE Int. Conf. Acoust., Speech Signal Process., 2002, pp. 669–672. [40] S. Rueping, “SVM kernels for time series analysis,” in LLWA— Tagungsband der GI-Workshop-Woche Lernen—Lehren—Wissen— Adaptivität, 2001, pp. 43–50. [41] V. Wan and W. M. Campbell, “Support vector machines for speaker verification and identification,” in Proc. IEEE Int. Workshop Neural Netw. Signal Process., 2000, pp. 775–784. [42] P. Clarkson and P. J. Moreno, “On the use of support vector machines for phonetic classification,” in Proc. Int. Conf. Acoust., Speech Signal Process., 1999, pp. 585–588. [43] J. Marques and P. J. Moreno, “A study of musical instrument classification using Gaussian mixture models and support vector machines,” HP Labs, Palo Alto, CA, HP Labs, Tech. Rep. CRL-99-4, 1999. [44] B. Haasdonk and D. Keysers, “Tangent distance kernels for support vector machines,” in Proc. 16th ICPR, 2002, vol. 2, pp. 864–868. [45] S. Chakrabartty and Y. Deng, “Dynamic Time Alignment in Support Vector Machines for Recognition Systems,” Johns Hopkins Univ., Baltimore, MD, 2001. [46] H. Shimodaira, K.-I. Noma, M. Nakai, and S. Sagayama, “Dynamic time-alignment kernel in support vector machine,” in Proc. NIPS, 2001, pp. 921–928. [47] H. Shimodaira, K.-I. Noma, M. Nakai, and S. Sagayama, “Support vector machine with dynamic time-alignment kernel for speech recognition,” in Proc. Eurospeech, 2001, vol. 3, pp. 1841–1844. [48] C. Bahlmann, B. Haasdonk, and H. Burkhardt, “On-line handwriting recognition with support vector machines—A kernel approach,” in Proc. 8th IWFHR, 2002, pp. 49–54. [49] D.-H. Qiu, C.-B. Chen, and X.-J. Jin, “Signature verification by support vector machine with ALCSL & LS kernel,” J. FuDan Univ. (Nat. Sci.), vol. 43, no. 5, pp. 805–809, 2004. [50] T. Jaakkola and D. Haussler, “Exploiting generative models in discriminative classifiers,” in Proc. Adv. Neural Inf. Process. Syst., 1999, vol. 11, pp. 487–493. [51] T. Jaakkola, M. Diekhans, and D. Haussler, “Using the Fisher kernel method to detect remote protein homologies,” in Proc. 7th Int. Conf. Intell. Syst. Molecular Biol., 1999, pp. 149–158. [52] T. Jaakkola, M. Diekhans, and D. Haussler, “A discriminative framework for detecting remote protein homologies,” J. Comput. Biol., vol. 7, no. 1/2, pp. 95–114, Feb.–Apr. 2000. [53] N. Smith and M. Niranjan, “Data-dependent kernels in SVM classification of speech patterns,” in Proc. 6th Int. Conf. Spoken Language Process., 2000, pp. 297–300. [54] N. Smith and M. Gales, “Speech recognition using SVMs,” in Proc. NIPS, 2001, pp. 1197–1204. [55] S. Fine, J. Navratil, and R. A. Gopinath, “A hybrid GMM/SVM approach to speaker identification,” in Proc. ICASSP, 2001, pp. 417–420. [56] V. Wan and S. Renals, “Speaker verification using sequence discriminant support vector machines,” IEEE Trans. Speech Audio Process., vol. 13, no. 2, pp. 203–210, Mar. 2005. [57] V. Wan and S. Renals, “SVMSVM: Support vector machine speaker verification methodology,” in Proc. IEEE Int. Conf. Acoust., Speech Signal Process., 2003, vol. 2, pp. 221–224. [58] P. J. Moreno and R. Rifkin, “Using the Fisher kernel method for web audio classification,” in Proc. IEEE Int. Conf. Acoust., Speech Signal Process., 2000, vol. 4, pp. 2417–2420. [59] P. J. Moreno and P. P. Ho, “A new SVM approach to speaker identification and verification using probabilistic distance kernels,” HP Lab., Cambridge, MA, Tech. Rep. HPL-2004-7, Jan. 2004. [60] P. J. Moreno, P. P. Ho, and N. Vasconcelos, “A Kullback–Leibler divergence based kernel for SVM classification in multimedia applications,” HP Lab., Cambridge, MA, Tech. Rep. HPL-2004-4, Jan. 2004. [61] R. Agrawal, K.-I. Lin, H. S. Sawhney, and K. Shim, “Fast similarity search in the presence of noise, scaling, and translation in time-series databases,” in Proc. 21st VLDB, 1995, pp. 490–501. [62] N. Cristianini and J. Shawe-Taylor, An Introduction to Support Vector Machines. Cambridge, U.K.: Cambridge Univ. Press, 2000. [63] J. C. Platt, “Sequential minimal optimization: A fast algorithm for training support vector machines,” Microsoft Res., Redmond, WA, Tech. Rep. MSR-TR-98-14, 1998. [64] P.-H. Chen, R.-E. Fan, and C.-J. Lin, “A study on SMO-type decomposition methods for support vector machines,” IEEE Trans. Neural Netw., vol. 17, no. 4, pp. 893–908, Jul. 2006. [65] C.-C. Chang and C.-J. Lin, LIBSVM—A Library for Support Vector Machines, 2007. [Online]. Available: http://www.csie.ntu.edu.tw/~cjlin/ libsvm/ [66] H. T. Lin and C. J. Lin, “A study on sigmoid kernels for SVM and the training of non-PSD kernels by SMO-type methods,” Dept. Comput. Sci. Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan, 2003. [67] B. Haasdonk and C. Bahlmann, “Learning with distance substitution kernels,” in Proc. Pattern Recog., 26th DAGM Symp., vol. 3175, LNCS, C. E. Rasmussen, H. H. Bülthoff, and B. Schölkopf, Eds., Berlin, Germany, 2004, pp. 220–227. [68] C. S. Ong, X. M. S. Canu, and A. J. Smola, “Learning with non-positive kernels,” in Proc. 21st ICML, 2004, pp. 81–88. [69] M. J. Embrechts, “Direct kernel least-squares support vector machines with heuristic regularization,” in Proc. IEEE IJCNN, 2004, vol. 1, pp. 687–692. [70] N. Cristianini and J. Shawe-Taylor, Kernel Methods for Pattern Analysis. Cambridge, U.K.: Cambridge Univ. Press, 2004. [71] E. Keogh and S. Kasetty, “On the need for time series data mining benchmarks: A survey and empirical demonstration,” Data Mining Knowl. Discovery, vol. 7, no. 4, pp. 349–371, Oct. 2003. [72] T. Rath and R. Manmatha, “Lower-bounding of dynamic time warping distances for multivariate time series,” Center Intell. Inf. Retrieval, Univ. Massachusetts, Amherst, MA, Tech. Rep. MM-40, 2002. [73] J. Fierrez-Aguilar, S. Krawczyk, J. Ortega-Garcia, and A. Jain, “Fusion of local and regional approaches for on-line signature verification,” in Advances in Biometric Person Authentication, vol. 3781, LNCS, S. Z. Li, Z. Sun, T. Tan, S. Pankanti, G. Chollet, and D. Zhang, Eds., Berlin, Germany: Springer-Verlag, 2005, pp. 188–196. [74] C. Rabasse, R. M. Guest, and M. C. Fairhurst, “A new method for the synthesis of signature data with natural variability,” IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 38, no. 3, pp. 691–699, Jun. 2008. [75] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classification, 2nd ed. New York: Wiley-Interscience, 2001. [76] N. Ratha, J. Conell, and R. Bolle, “Enhancing security and privacy in biometrics-based authentication systems,” IBM Syst. J., vol. 40, no. 3, pp. 614–634, Mar. 2001. [77] A. B. J. Teoh and C. T. Yuang, “Cancelable biometrics realization with multispace random projections,” IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1096–1106, Oct. 2007. [78] J. Hofer, C. Gruber, and B. Sick, “Biometric analysis of handwriting dynamics using a script generator model,” in Proc. IEEE SMCals, 2006, pp. 36–41.
[79] M. Dose, C. Gruber, A. Grunz, C. Hook, J. Kempf, G. Scharfenberg, and B. Sick, “Towards an automated analysis of neuroleptic’s impact on human hand motor skills,” in Proc. IEEE CIBCB, 2007, pp. 494–501. [80] E. Fuchs, T. Gruber, J. Nitschke, and B. Sick, “On-line segmentation of time series based on polynomial least-squares approximations,” IEEE Trans. Pattern Anal. Mach. Intell., to be published.
Christian Gruber received the Diploma and Ph.D. degrees in computer science from the University of Passau, Passau, Germany, in 2002 and 2009, respectively.
Up to November 2007, he was with the Faculty of Computer Science and Mathematics, University of Passau, where he was conducting research and development in the areas of machine learning, online signature verification and identification as well as medical applications of biometric writing systems. Since December 2007, he has been with Elektrobit
Corporation, Branch Office Munich, Munich, Germany. He authored several peer-reviewed publications.
Dr. Gruber received the Fresenius Awards 2006 Inventor’s Prize for his results in the field of model-based interpretation of human hand motor skills.
Thiemo Gruber received the Diploma degree in computer science from the University of Passau, Passau, Germany, in 2007, where he is currently working toward the Ph.D. degree in the Faculty of Computer Science and Mathematics.
There, he is conducting research and development in the areas of machine learning (in particular, timeseries analysis) with applications in gesture spotting and activity recognition, online signature verification and identification as well as medical applications of biometric writing systems.
Sebastian Krinninger received the B.S. degree in computer science from the University of Passau, Passau, Germany, in 2008. He is currently working toward the M.S. degree in computer science at Vienna University of Technology, Vienna, Austria.
As a Student Assistant, he supported research in the area of biometric writing systems.
Mr. Krinninger is a member of the German National Merit Foundation (Studienstiftung des deutschen Volkes).
Bernhard Sick (M’02) received the Diploma and Ph.D. degrees in computer science from the University of Passau, Passau, Germany, in 1992 and 1999, respectively.
Currently, he is an Assistant Professor (Privatdozent) with the Faculty of Computer Science and Mathematics, University of Passau. There, he is conducting research and development in the areas of theory and application of soft-computing techniques, organic computing, collaborative data mining, intrusion detection, and biometrics. He authored more
than 80 peer-reviewed publications in these areas. Dr. Sick is a member of Systems, Man, and Cybernetics Society, Computer Society, and Computational Intelligence Society and GI (Gesellschaft fuer Informatik). Bernhard Sick is Associate Editor of the IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS—PART B; he is the holder of one patent and received several thesis, best paper, teaching, and inventor awards.

References
[1]C. Gruber,B. SickComparison of biometric writing systems for the analysis of human fine motor skillsProc. IEEE Three Rivers Workshop Soft Comput. Ind. Appl., 2007, pp. 49–54.2007
[2]A. McCabeImplementation and analysis of a handwritten signature verification techniquePh.D. dissertation, James Cook Univ. North Queensland, Townsville, Australia, 1997.1997
[3]R. Plamondon,S. SrihariOnline and off-line handwriting recognition: A comprehensive surveyIEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 1, pp. 63–84, Jan. 2000.2000
[4]G. Dimauro,S. Impedovo,M. Lucchese,R. Modugno,G. PirloRecent advancements in automatic signature verificationProc. 9th IWFHR, 2004, pp. 179–184.2004
[5]C. GruberOnline-Unterschriftenverifikation Basierend auf Methoden des Maschinellen LernensPh.D. dissertation, Univ. Passau, Passau, Germany, 2009.2009
[6]D. Impedovo,G. PirloAutomatic signature verification: The state of the artIEEE Trans. Syst., Man, Cybern. C, Appl. Rev., vol. 38, no. 5, pp. 609–635, Sep. 2008.2008
[7]A. Kholmatov,B. YanikogluBiometric authentication using online signaturesProc. ISCIS, vol. 3280, LNCS, C. Aykanat, T. Dayar, and I. Körpeolu, Eds., Berlin, Germany, 2004, pp. 373–380.2004
[8]J. Fierrez-Aguilar,N. Loris,J. Lopez-Penalba,J. Ortega-Garcia,D. MaltoniAn on-line signature verification system based on fusion of local and global informationProc. AVBPA, vol. 3546, LNCS, T. Kanade, A. K. Jain, and N. Ratha, Eds., Berlin, Germany, 2005, pp. 523–532.2005
[9]H. Lv,W. WangOn-line signature verification based on dynamic Bayesian networkProc. ICNC, vol. 4221, LNCS, L. Jiao, L. Wang, X. Gao, J. Liu, and F. Wu, Eds., Berlin, Germany, 2006, pp. 507–510.2006
[10]D. Muramatsu,M. Kondo,M. Sasaki,S. Tachibana,T. MatsumotoA Markov chain Monte Carlo algorithm for Bayesian dynamic signature verificationIEEE Trans. Inf. Forensics Security, vol. 1, no. 1, pp. 22–34, Mar. 2006.2006
[11]Z.-H. Quan,D.-S. Huang,X.-L. Xia,M. Lyu,T.-M. LokSpectrum analysis based on windows with variable widths for online signature verificationProc. 18th ICPR, 2006, vol. 2, pp. 1122–1125.2006
[12]C. Hook,J. Kempf,G. ScharfenbergA novel digitizing pen for the analysis of pen pressure and inclination in handwriting biometricsProc. BioAW, vol. 3087, LNCS, D. Maltoni and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 283–294.2004
[13]C. Gruber,T. Gruber,B. SickOnline signature verification with new time series kernels for support vector machinesProc. ICB, vol. 3832, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2006, pp. 500–508.2006
[14]C. Gruber,M. Coduro,B. SickSignature verification with dynamic RBF networks and time series motifsProc. 10th IWFHR, 2006, pp. 455–460.2006
[15]P. Mautner,V. Matousek,T. Marsalek,O. RohlikComparison of ART-2 and SOFM based neural network verifiersProc. 1st ANNs: Data Preparation Tech. Appl. Develop., 2004, pp. 43–50.2004
[16]N.-N. Liu,Y.-H. WangFusion of global and local information for an on-line signature verification systemProc. 7th ICMLC, 2008, pp. 57–61.2008
[17]J.J. Igarza,L. Gomez,I. Hernaez,I. GoirizeljaSearching for an optimal reference system for on-line signature verification based on (x, y)-alignmentProc. ICBA, vol. 3072, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 519–525.2004
[18]B. Ly Van,S. Garcia-Salicetti,B. DorizziFusion of HMM’s likelihood and Viterbi path for on-line signature verificationProc. BioAW, vol. 3087, LNCS, D. Maltoni and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 318–331.2004
[19]J. Wen,B. Fang,Y.Y. Tang,T. ZhangModel-based signature verification with rotation invariant featuresPattern Recognit., vol. 42, no. 7, pp. 1458–1466, Jul. 2009.2009
[20]B.-L. Van,S. Garcia-Salicatti,B. DorizziOn using the Viterbi path along with HMM likelihood information for online signature verificationIEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1237–1247, Oct. 2007.2007
[21]J. Fàbregas,M. Faundez-ZanuyOn-line signature verification system with failure to enrol managementPattern Recognit., vol. 42, no. 9, pp. 2117–2126, Sep. 2009.2009
[22]P. Fang,Z. Wu,F. Shen,Y. Ge,B. FangImproved DTW algorithm for online signature verification based on writing forcesProc. ICIC—Part I, vol. 3844, LNCS, D.-S. Huang, X.-P. Zhang, and G.-B. Huang, Eds., Berlin, Germany, 2005, pp. 631–640.2005
[23]Z. Wu,P. Fang,F. ShenOnline signature verification based on global feature writing forcesProc. ICB, vol. 3832, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2006, pp. 516–522.2006
[24]C. Vivaracho-Pascual,M. Faundez-Zanuyy,J.M. PascualAn efficient low cost approach for on-line signature recognition based on length normalization and fractional distancesPattern Recognit., vol. 42, no. 1, pp. 183–193, Jan. 2009.2009
[25]W.-D. Chang,J. ShinDPW approach for random forgery problem in online handwritten signature verificationProc. 4th NCM, 2008, pp. 347–352. GRUBER et al.: ONLINE SIGNATURE VERIFICATION WITH SVM BASED ON LCSS KERNEL FUNCTIONS 10992008
[26]S. Sayee,R. Besar,N. KamelDynamic signature verification using sensor based data gloveProc. 8th ICSP, 2006, vol. 2, pp. 2387–2390.2006
[27]B. Kar,P.K. Dutta,T.K. Basu,C. Vielhauer,J. DittmannDTW based verification scheme of biometric signaturesProc. IEEE ICIT , 2006, pp. 381–386.2006
[28]L. Wan,B. Wan,Z.-C. LinOn-line signature verification with two stage statistical modelsProc. 8th ICDAR, 2005, vol. 1, pp. 282–286.2005
[29]C. Gruber,C. Hook,J. Kempf,G. Scharfenberg,B. SickA flexible architecture for online signature verification based on a novel biometric penProc. IEEE SMCals, 2006, pp. 110–115.2006
[30]A.K. Jain,F.D. Griess,S.D. ConnellOn-line signature verificationPattern Recognit., vol. 35, no. 12, pp. 2963–2972, Dec. 2002.2002
[31]J. Ortega-Garcia,J. Fierrez-Aguilar,D. Simon,J. Gonzalez,M. Faundez-Zanuy,V. Espinosa,A. Satue,I. Hernaez,J.-J. Igarza,C. Vivaracho,D. Escudero,Q.-I. MoroMCYT baseline corpus: A bimodal biometric databaseProc. Inst. Elect. Eng.—Vis., Image Signal Process., Dec. 2003, vol. 150, no. 6, pp. 395–401.2003
[32]D. Yeung,H. Chang,Y. Xiong,S. George,R. Kashi,T. Matsumoto,G. RigollSVC 2004: First international signature verification competitionProc. ICBA, vol. 3072, LNCS, D. Zhang and A. K. Jain, Eds., Berlin, Germany, 2004, pp. 16–22.2004
[33]F.M.L. Ballard,D. LoprestiForgery quality and its implications for behavioral biometric securityIEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1107–1118, Oct. 2007.2007
[34]V.N. VapnikAn overview of statistical learning theoryIEEE Trans. Neural Netw., vol. 10, no. 5, pp. 988–999, Sep. 1999.1999
[35]P.-H. Chen,C.-J. Lin,B. SchölkopfA tutorial on ν-support vector machinesAppl. Stochastical Syst. Business Ind., vol. 21, no. 2, pp. 111– 136, 2003.2003
[36]C.J.C. BurgesA tutorial on support vector machines for pattern recognitionData Mining Knowl. Discovery, vol. 2, no. 2, pp. 121–167, Jun. 1998.1998
[37]V. Wan,S. RenalsEvaluation of kernel methods for speaker verification and identificationProc. IEEE Int. Conf. Acoust., Speech Signal Process., 2002, pp. 669–672.2002
[38]S. RuepingSVM kernels for time series analysisLLWA— Tagungsband der GI-Workshop-Woche Lernen—Lehren—Wissen— Adaptivität, 2001, pp. 43–50.2001
[39]V. Wan,W.M. CampbellSupport vector machines for speaker verification and identificationProc. IEEE Int. Workshop Neural Netw. Signal Process., 2000, pp. 775–784.2000
[40]P. Clarkson,P.J. MorenoOn the use of support vector machines for phonetic classificationProc. Int. Conf. Acoust., Speech Signal Process., 1999, pp. 585–588.1999
[41]J. Marques,P.J. MorenoA study of musical instrument classification using Gaussian mixture models and support vector machinesHP Labs, Palo Alto, CA, HP Labs, Tech. Rep. CRL-99-4, 1999.1999
[42]B. Haasdonk,D. KeysersTangent distance kernels for support vector machinesProc. 16th ICPR, 2002, vol. 2, pp. 864–868.2002
[43]S. Chakrabartty,Y. DengDynamic Time Alignment in Support Vector Machines for Recognition SystemsJohns Hopkins Univ., Baltimore, MD, 2001.2001
[44]H. Shimodaira,K.-I. Noma,M. Nakai,S. SagayamaDynamic time-alignment kernel in support vector machineProc. NIPS, 2001, pp. 921–928.2001
[45]H. Shimodaira,K.-I. Noma,M. Nakai,S. SagayamaSupport vector machine with dynamic time-alignment kernel for speech recognitionProc. Eurospeech, 2001, vol. 3, pp. 1841–1844.2001
[46]C. Bahlmann,B. Haasdonk,H. BurkhardtOn-line handwriting recognition with support vector machines—A kernel approachProc. 8th IWFHR, 2002, pp. 49–54.2002
[47]D.-H. Qiu,C.-B. Chen,X.-J. JinSignature verification by support vector machine with ALCSL & LS kernelJ. FuDan Univ. (Nat. Sci.), vol. 43, no. 5, pp. 805–809, 2004.2004
[48]T. Jaakkola,D. HausslerExploiting generative models in discriminative classifiersProc. Adv. Neural Inf. Process. Syst., 1999, vol. 11, pp. 487–493.1999
[49]T. Jaakkola,M. Diekhans,D. HausslerUsing the Fisher kernel method to detect remote protein homologiesProc. 7th Int. Conf. Intell. Syst. Molecular Biol., 1999, pp. 149–158.1999
[50]T. Jaakkola,M. Diekhans,D. HausslerA discriminative framework for detecting remote protein homologiesJ. Comput. Biol., vol. 7, no. 1/2, pp. 95–114, Feb.–Apr. 2000.2000
[51]N. Smith,M. NiranjanData-dependent kernels in SVM classification of speech patternsProc. 6th Int. Conf. Spoken Language Process., 2000, pp. 297–300.2000
[52]N. Smith,M. GalesSpeech recognition using SVMsProc. NIPS, 2001, pp. 1197–1204.2001
[53]S. Fine,J. Navratil,R.A. GopinathA hybrid GMM/SVM approach to speaker identificationProc. ICASSP, 2001, pp. 417–420.2001
[54]V. Wan,S. RenalsSpeaker verification using sequence discriminant support vector machinesIEEE Trans. Speech Audio Process., vol. 13, no. 2, pp. 203–210, Mar. 2005.2005
[55]V. Wan,S. RenalsSVMSVM: Support vector machine speaker verification methodologyProc. IEEE Int. Conf. Acoust., Speech Signal Process., 2003, vol. 2, pp. 221–224.2003
[56]P.J. Moreno,R. RifkinUsing the Fisher kernel method for web audio classificationProc. IEEE Int. Conf. Acoust., Speech Signal Process., 2000, vol. 4, pp. 2417–2420.2000
[57]P.J. Moreno,P.P. HoA new SVM approach to speaker identification and verification using probabilistic distance kernelsHP Lab., Cambridge, MA, Tech. Rep. HPL-2004-7, Jan. 2004.2004
[58]P.J. Moreno,P.P. Ho,N. VasconcelosA Kullback–Leibler divergence based kernel for SVM classification in multimedia applicationsHP Lab., Cambridge, MA, Tech. Rep. HPL-2004-4, Jan. 2004.2004
[59]R. Agrawal,K.-I. Lin,H.S. Sawhney,K. ShimFast similarity search in the presence of noise, scaling, and translation in time-series databasesProc. 21st VLDB, 1995, pp. 490–501.1995
[60]N. Cristianini,J. Shawe-TaylorAn Introduction to Support Vector Machines2000
[61]J.C. PlattSequential minimal optimization: A fast algorithm for training support vector machinesMicrosoft Res., Redmond, WA, Tech. Rep. MSR-TR-98-14, 1998.1998
[62]P.-H. Chen,R.-E. Fan,C.-J. LinA study on SMO-type decomposition methods for support vector machinesIEEE Trans. Neural Netw., vol. 17, no. 4, pp. 893–908, Jul. 2006.2006
[63]C.-C. Chang,C.-J. LinLIBSVM—A Library for SupportVector Machines,2007
[64]H.T. Lin,C.J. LinA study on sigmoid kernels for SVM and the training of non-PSD kernels by SMO-type methodsDept. Comput. Sci. Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan, 2003.2003
[65]B. Haasdonk,C. BahlmannLearning with distance substitution kernelsProc. Pattern Recog., 26th DAGM Symp., vol. 3175, LNCS, C. E. Rasmussen, H. H. Bülthoff, and B. Schölkopf, Eds., Berlin, Germany, 2004, pp. 220–227.2004
[66]C.S. Ong,X.M.S. Canu,A.J. SmolaLearning with non-positive kernelsProc. 21st ICML, 2004, pp. 81–88.2004
[67]M.J. EmbrechtsDirect kernel least-squares support vector machines with heuristic regularizationProc. IEEE IJCNN, 2004, vol. 1, pp. 687–692.2004
[68]N. Cristianini,J. Shawe-TaylorKernel Methods for Pattern Analysis2004
[69]E. Keogh,S. KasettyOn the need for time series data mining benchmarks: A survey and empirical demonstrationData Mining Knowl. Discovery, vol. 7, no. 4, pp. 349–371, Oct. 2003.2003
[70]T. Rath,R. ManmathaLower-bounding of dynamic time warping distances for multivariate time seriesCenter Intell. Inf. Retrieval, Univ. Massachusetts, Amherst, MA, Tech. Rep. MM-40, 2002.2002
[71]J. Fierrez-Aguilar,S. Krawczyk,J. Ortega-Garcia,A. JainFusion of local and regional approaches for on-line signature verificationAdvances in Biometric Person Authentication, vol. 3781, LNCS, S. Z. Li, Z. Sun, T. Tan, S. Pankanti, G. Chollet, and D. Zhang, Eds., Berlin, Germany: Springer-Verlag, 2005, pp. 188–196.2005
[72]C. Rabasse,R.M. Guest,M.C. FairhurstA new method for the synthesis of signature data with natural variabilityIEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 38, no. 3, pp. 691–699, Jun. 2008.2008
[73]N. Ratha,J. Conell,R. BolleEnhancing security and privacy in biometrics-based authentication systemsIBM Syst. J., vol. 40, no. 3, pp. 614–634, Mar. 2001.2001
[74]A.B.J. Teoh,C.T. YuangCancelable biometrics realization with multispace random projectionsIEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 37, no. 5, pp. 1096–1106, Oct. 2007.2007
[75]J. Hofer,C. Gruber,B. SickBiometric analysis of handwriting dynamics using a script generator modelProc. IEEE SMCals, 2006, pp. 36–41. 1100 IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS—PART B: CYBERNETICS, VOL. 40, NO. 4, AUGUST 20102006
[76]M. Dose,C. Gruber,A. Grunz,C. Hook,J. Kempf,G. Scharfenberg,B. SickTowards an automated analysis of neuroleptic’s impact on human hand motor skillsProc. IEEE CIBCB, 2007, pp. 494–501.2007
