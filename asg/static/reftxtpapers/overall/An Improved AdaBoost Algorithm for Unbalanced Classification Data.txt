An Improved AdaBoost Algorithm for Unbalanced Classification Data
Jie Song,Xiaoling Lu,Xizhi Wu
littlesongjie@163.com,,xl_lu2002@yahoo.com.cn,,xzwu2003@yahoo.com.cn

Keywords- AdaBoost; within group error; unbalanced data; multiclass; classification
I. INTRODUCTION Classification is a hot research topic in statistics and machine learning community. Usually it builds a predictor with learning dataset and then applies it to the new dataset in order to get high accuracy, i.e., low overall prediction error. Taking the binary problem as example, the overall prediction error is the total number of the misclassified cases, including class 1 predicted to class 2 and the reverse, divided by the sample size. However, sometimes low overall prediction error cannot assure a good classification method. For instance, the ratio of two classes in the population is 0.1:0.9. The overall prediction error for the first method is 0.18 with error for each class as 0.9 and 0.1 respectively. The overall prediction error for the second method is 0.22 with error for each class as 0.4 and 0.2 respectively. Though the overall error of the first method is lower than that of the second one, it almost misclassifies all class-1 cases. In this sense, we cannot say it is a good method. Such dataset is called unbalanced one and is very common in real application. For example, in marketing research, a credit card company is interested in predicting whether or not a new applicant is a bad customer who will fail to pay back the money. Though it is only a small proportion of such kind of people, successfully detecting them in advance will prevent great benefit loss. Lots of work has been done to deal with this problem by adjusting the class proportions [1],[2],[3],[4]. Recently, Qiao and Liu [5] discuss the reason why minority class can be ignored if the overall misclassification rate is used as the evaluation criterion. Instead of aiming for a classification rule with a
small overall misclassification error, they take into account of each within group error.
In this paper, we propose a novel approach reducing each within group error, BABoost, that is a variant of AdaBoost. Simulations on different unbalanced distribution data and experiments performed on several real datasets show that the new method is able to achieve a lower within group error (especially for minority class) and higher margin than Adaboost. Furthermore, as the prediction error of minority class gets smaller and smaller, the prediction error of majority class increases only an insignificant amount.
The rest of this article is organized as follows. Section 2 gives a brief introduction of AdaBoost algorithm. Section 3 brings the new method. Section 4 shows the results of simulation studies and real applications. The paper is concluded in Section 5.
II. ADABOOST ALGORITHM AdaBoost was originally proposed by Freund and Schapire ([6], [7]) as an ensemble method which relies on the principle of generating multiple predictors and weighted voting among the individual weak classifiers. Different with bagging which generates base predictor with bootstrap replicate of the learning set, AdaBoost proceeds in a sequential steps with equal probabilities of each case in the learning dataset at the very beginning. At each step, the new learning set is selected by sampling from the original learning set using probabilities with replacement. After the classifier based on this resampled learning set is constructed, the are updated depending on the misclassifications up to the present step. That is, the points being misclassified in previous steps will be assigned heavier sampling probabilities and have more chance to be selected into the learning set for next step.
It has attracted much attention in the machine learning community as well as in related areas in statistics. Various versions of the AdaBoost algorithm have proven to be very competitive in terms of prediction accuracy in a variety of applications. Numerous researchers try to explain in theory why it works so well [8]. Nowadays the well accepted explanation is AdaBoost is an additive model and can be viewed as a gradient descent algorithm in function space [9].
AdaBoost aims at reducing the overall prediction error without taking the class proportions into consideration. When the minority class has a very small size, it might misclassify all the cases in this class. Chawla et al. [10]
978-0-7695-3735-1/09 $25.00 © 2009 IEEE DOI 10.1109/FSKD.2009.608
109
propose an improved AdaBoost method by adjusting the class proportions. One of the limitations is that it’s difficult to specify the parameters. This paper will adopt Qiao and Liu’s [5] approach to consider the misclassification of each class to propose an improved AdaBoost algorithm: BABoost.
III. BABOOST ALGORITHM

A. Algorithm
In this paper, we propose a new algorithm called BABoost based on dividing the overall misclassification error into several parts. We want to utilize BABoost to improve the accuracy over the minority class without much sacrificing the accuracy over the majority class.
Adaboost algorithm gives equal weight to each misclassified example. But the misclassification error of each class is not same. Generally, the misclassification error of the minority class will larger than the majority’s. So Adaboost algorithm will lead to higher bias and smaller margin when encountering skew distribution. Our goal is to reduce the bias of Adaboost algorithm and increase the margin between each two classes. The proposed BABoost algorithm (Figure 1) in each round of boosting assigns more weights to the misclassified examples, especially those in the minority class. More generally, we focus on multiclass (J-class) problems in which in this paper. Following Schapire and Singer’s [11], [12] approach to multiclass problems, we change the multiclass problem into two-class problems. That is, if equals , we set it equal to a 1 by vector with the element as +1 and -1 for others; if equals , then it equals a 1 by J-1 vector with all elements as -1. D denotes the resampling probabilities for each case and H is the matrix for the ensemble predictor.
The differences between BABoost and Adaboost are the calculation of , , and the update of the H. indicates the prediction error for the predictor when predicting the cases into the class. is the weight for the
predictor and class. For example, instead of the overall error in the AdaBoost, it will be two within group prediction errors: and for binary problems.
Except that and will lead to different weights to majority class and minority class, also give a strong impact to reweight the distribution of samples. Different class corresponds to its own . The value of should be positive and larger for majority class, smaller for minority class in order to emphasize more on minority class: The larger the is, the smaller the is. So the corresponding misclassified objects of the class get lower weights.

B. The Margin
Margin is another concept for explaining the ability of classification method ([13], [14]). It is defined as:
Thus, margin is the total vote for the correct class minus the total vote for the next highest class. Intuitively, if the margins over a training set are generally high, then the misclassifications, corresponding to all test set inputs such that mgi<0, will be low.
Figure 2 shows the empirical density estimation of margins for AdaBoost (left and dashed curve) and BABoost (right and solid curve) for a simulation dataset with the degree of unbalanced proportions as 10:1 and equal to 50 (the detailed simulation procedure is given in the next section). We can see that BABoost produces higher margin values than AdaBoost, which means that it’s a better classification method.
We can have similar results (not shown here) for other degrees of unbalanced data (20:1 and 5:1). The higher the degree of unbalanced data is, the better the BABoost increases the margin.
IV. EMPIRICAL STUDY In this section, we will show the results on both simulation and real datasets with different degrees of unbalance. Different values of for BABoost are selected in order to find the best one.

A. Simulations
Consider a simple two-class two-dimensional example. The first class is from a bivariate normal
distribution , and the second
. In total, 440 points are generated with the
ratio of two classes as 10:1. That is, 400 from the first population and 40 from the second one. Class 1 is used to stand for the majority class and class 2 is used to stand for the minority class here. The scatter plot is shown in Figure 3.
Half of the points is used as learning set, the rest as test set. We choose C4.5, an unstable algorithm, as the base weak classifier. Results are shown in Table 1, which is averaged over 100 experiments on new randomly generated learning sets and test sets each time. The parameter is set equal to 1 for class 2, the minority class. Different values of (2, 10, 50, 100, 200, 500, and 800) for majority class are tried in order to search the optimal one. Figure 4 shows the box
plot of the 100 second class errors with different values of . Table 1 shows the mean of three errors (for test set, class 1, and class 2) of AdaBoost and BABoost with 100 replicates. We can see that mean test set error, class 1 error, and class 2 error for AdaBoost is 0.065, 0.030, and 0.419. The class 2 error is relatively high. For BABoost, small values of (2 and 10) give lower test error, class 1 error, and class 2 error than AdaBoost. However the absolute class 2 error is still high. As increases to 50, the test set error and class 1 error increase slightly (the absolute value is not very high), class 2 error drops to an accepted level. Large values of do not improve too much.
We also simulate the data with the degrees of unbalanced proportions as 20:1 and 5:1 to get similar results as Table 1 and Figure 2. Regarding the selection of the values , we notice that the within group errors under BABoost algorithm is monotony with . In binary classification problem, we can control the classification error of the minority class at a satisfied level and then select the value of which minimizes the classification error of majority class. For multiple classification problem, we can set the value of for the minority group as 1. For the value of for other class, we can choose it as the sample size of this class divided by the sample size of the minority class.

B. Application to Real Data Sets
In this section, we apply the proposed method to four real data sets obtained from the UCI machine learning website
http://www.ics.uci.edu/~mlearn/. Thyroid dataset is to determine whether a patient referred to the clinic is hypothyroid. Three classes are subnormal functioning (class 1), hyperfunction (class 2), and normal (class 3). In total, there are 7200 observations. The ratio of three classes is equal to 1:2.2:40.2. We randomly sample 200 subjects as training set and the rest as test set. Glass dataset includes 208 cases. Each case consists of 9 chemical measurements on one of 6 types of glass. The ratio is 70:76:17:13:9:29. For illustration, we select the second (76), third (17) and fifth (9) classes to do analysis. Satimage dataset was generated from Landsat Multi-Spectral Scanner image data. For this dataset, we increased the degree of skew by converting all but the smallest class into a single class. Sonar dataset is to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock. There are two classes: rock and metal cylinder. Table 2 presents the characteristics of the data sets used for the experiments such as the numbers of cases, the class distribution, and the type of the features. The first two datasets are three class classification problems, the rest are binary problems.
We compare the proposed method with C4.5, bagging, RandomForest and Adaboost. For the base learner, we employ unstable C4.5 algorithm. Each ensemble algorithm is iterated 15 times. Results for the above datasets (Table 3) are averaged over five 10-fold cross validation experiments, except for dataset Thyroid, which results are averaged over 100 experiments on new randomly selected learning sets and test sets each time. For all datasets, the values of in BaBoost for the minority classes are set to 1, the values of other classes are set to five different values.
The results indicate that BABoost algorithm performs well for unbalanced data sets. For all data sets, the improvement for the minority class is significant. In some cases such as the Sonar dataset, when the value of is proper, here is 1.3, the test error and the within class errors of BABoost will be lower than AdaBoost. Although random forest, Bagging and Adaboost always lead to lower overall error, but the error of the minority class is very high, even equals 1. Our approach greatly deceases the error of the minority class, but only increases the error of majority gently. Furthermore, no matter to what degree the unbalance is, BABoost can always achieve better results in terms of error for minority class. The values shown in the table 3 confirm that BABoost algorithm benefits from separately computing the error of each class in the prediction and the introduction of parameter .
V. CONCLUSION This paper introduces a novel approach for classification problem with reducing each within group error, BABoost, that is a variant of AdaBoost. This method gives different weights to the misclassified objects of different classes. It can produce higher margin which indicates a better classifier. Empirical results show that it is a more achievable method than other four methods in terms of prediction error, especially for the minority class. Optimal value of parameter
depends on the degree of unbalanced proportion. Future work can be done to discuss how to select in a more
rigorous way. Also the proposed algorithm can be combined with those methods by adjusting the class proportions.

ACKNOWLEDGMENT
The research is supported by the NSFC Grant (no. 10431010), the Research Grant for the Key Institutes of Ministry of Education (no. 05JJD910001), and the Center for Applied Statistics at Renmin University of China.

References
[1]N.V. Chawla,N. Japkowicz,A. KolczEditorial: Special issue on learning from imbalanced data setsACM SIGKDD Explorations Newsletter,2004
[2]C. Chen,A. Liaw,L. BreimanUsing random forest to learn imbalanced dataTechnical report, Department of Statistics, University of California, Berkeley, 2004.2004
[3]G.H. Nguyen,A. BouzerdoumPhung.”A supervised learning approach for imbalanced data sets,Pattern Recognition,2008
[4]H. Guo,H.L. ViktorLearning from imbalanced data sets with boosting and data generation: The DataBoost-IM approachSIGKDD Explorations, 2004, 6(1):30-39.2004
[5]X. Qiao,Y. LiuAdaptive weighted learning for unbalanced multicategory classification2008
[6]Y. Freund,R. SchapireA decision-theoretic generalization of online learning and an application to boostingproceedings of the second European conference on computational learning theory, 1995.1995
[7]Y. Freund,R. SchapireExperiments with a new boosting algorithmproceedings of the thirteenth international conference on machine learning, 1996.1996
[8]L. BreimanBias, variance, and Arcing classifiers,Tech. Rep. 460,1996
[9]J.H. Friedman,T. Hastie,R. TibshiraniAdditive logistic regression: A statistical view of boostingAnnals of Statistics, 2000,28:337–407.2000
[10]N.V. Chawla,K.W. Bowyer,L.O. Hall,W.P. KegelmeyerSMOTE: Synthetic Minority Over-Sampling TechniqueJournal of Artificial Intelligence Research, 2002,16:321-357.2002
[11]R. Schapire,Y. SingerImproved boosting algorithms using confidence-rated predictionsProceedings of the Eleventh Annual Conference on Computational Learning Theory, 1998, pp. 80–91.1998
[12]R.E. Schapire,Y. SingerBoosTexter: A boosting-based system for text categorization,”MachineLearning, May/Jun 2000,2000
[13]R. Schapire,Y. Freund,P. Bartlett,W. LeeBoosting the Margin: A New Explanation for the Effectiveness of Voting MethodsThe Annuals of Statistics, 1998, 26 (5), 1651-1686.1998
[14]L. BreimanPrediction Games and Arcing AlogrithmTechnical Report 504, Statistics Department, University of California, Berkeley, 1997. 1131997
