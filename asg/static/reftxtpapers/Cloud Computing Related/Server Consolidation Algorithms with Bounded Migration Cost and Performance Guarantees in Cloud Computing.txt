Server Consolidation Algorithms with Bounded Migration Cost and Performance Guarantees in Cloud Computing
Yufan Ho,Pangfeng Liu,Jan-Jan Wu
r98922056@csie.ntu.edu.tw,pangfeng@csie.ntu.edu.tw,wuj@iis.sinica.edu.tw

Keywords-Energy Optimization; Server Consolidation; VM Relocation;
I. INTRODUCTION
During recent years web service such as Amazon Elastic Compute Cloud (Amazon EC2) [1] provides users the computation capacity in the cloud. Users can rent “computers” tailored to their needs, like the number of cores, the amount of memory, and the amount of disk storage, etc. The computation infrastructure service is provided by Internet, therefore it is also called Infrastructure as a Service, or IaaS.
Instead of providing physical machines, IaaS cloud service providers create and provide virtual machines to users. The reasons for using virtualization techniques in cloud is flexibility, and power saving. Virtual machines are created according to user specification, and deployed in an ondemand manner on physical machines. A virtual machines
can be deployed in any physical server that supports virtualization, therefore the deployment becomes very flexible, and easy to manage. In addition, we can power on only those physical machines that are hosting virtual machines, and shut down idle servers to conserve energy. To Reduce power consumption of data centers is an important issue, since cloud computing is becoming increasingly popular, and more data center will be built.
This paper focuses on deployment of virtual machines with static resource requirement, like the number of virtual CPUs and the amount of memory and disk storage. For example, when we want to acquire virtual machines from Amazon EC2 [1] services, we must specify these resource requirements so that EC2 can proper can calculate the usage rate, and allocate resources to generate these virtual machines accordingly.
Energy optimization is an important issue in cloud computing environments. To reduce power consumption, a key idea is to reduce the idle power wasted by underutilized servers. The reason is that a server, even running a virtual machine with a very small workload, still consume over 50% of the peak power [4]. As a result the focus of conserving energy is to turn on as few servers as possible by consolidating the workload. This problem is referred to as server consolidation.
Server consolidation problem is NP-complete. The problem can be formally stated as follows. We use virtual machines to run jobs that incur workloads. We want to map virtual machines that have different hardware specifications, such as the number of cores and the amount of memory, to physical servers that have given hardware capacity, so that the total amount of required resources from virtual machines mapped to the same server will not exceed the amount of resource of that physical servers, and the total number of physical servers used is minimized. One can easily argue that the consolidation problem is as hard as the bin packing problem [13], which is NP-complete [7].
For the purpose of decreasing the number of underutilized
978-0-7695-4592-9/11 $26.00 © 2011 IEEE DOI 10.1109/UCC.2011.30
154
servers, many studies on consolidation of workloads have been done. However, as mentioned above, even a very simplified model of servers consolidation problem – the bin packing problem, is NP-complete. Fortunately, several well-known approximation algorithms for bin packing are presented and have been analyzed in the literature, such as First Fit [14], Best Fit [5], and First Fit Decreasing [6]. These algorithms are easy to implement and have performance guarantee so that we can have a solution that will not be very far away from the optimal one.
Despite that given a set of virtual machines we can use previously mentioned algorithm, e.g., First Fit, to obtain good solutions, the virtual machines in data centers are dynamically changing. As old jobs finish and new jobs keep coming, we cannot apply those static bin packing algorithms mentioned above, to cope with the dynamic virtual machine requirements. Therefore we must derive new algorithms that can dynamically relocate the virtual machines among servers so that we can still have performance guarantees in our solutions.
We need to relocate virtual machines among servers in order to maintain good system utilization in a dynamic workload environment. For instance, we assume that there are 100 virtual machines deployed to 40 servers initially, and each virtual machine requires only a server. After a period of time 80 virtual machines finished and we need to relocate the remaining 20 virtual machines, and turn off servers that are not running virtual machines. If we do not do so there will be at least 20 servers that become idle, which will waste energy.
Relocating virtual machines incurs overheads. In order to relocate an virtual machine from one server to another, one must save the status of the running virtual machine in the original server, transfer these execution information to the new server by network, and restore the execution information at the new server so that the virtual machine can restart. These information saving, transferring, and restoring incur huge runtime overheads.
We would like to propose the following problem – how to relocate a small percentage of virtual machines among servers and still guarantee the solution quality? That is, how to relocate only a small portion of virtual machines, and still achieve server consolidation? This is a very important problem for cloud computing since we do need to relocate virtual machines in data center to conserve energy, but we do not want to relocate a large portion of the virtual machines because of the huge overhead, and extra power consumption, in relocating them. We refer to this problem as bounded relocation cost server consolidation problem.
We model the bounded relocation cost server consolidation problem as a dynamic bin packing problem. Traditional static bin packing algorithms only concerns about the number of bins used. In our dynamic bin packing model, we not only need to reduce the number of bin used, but
also the amount of virtual machines we need to relocate from one bin to another. These concerns complicate the bin packing problem greatly. Nevertheless, we propose an algorithm that guarantees to relocate only a small fraction of virtual machines, and still maintain performance guarantee after the relocation.
The algorithm will work in the following scenario. Initially virtual machines were deployed to servers arbitrarily to model that virtual machines enter and leave the system in an arbitrary manner. Then our algorithm will relocate virtual machines so that the resulting configuration will be the same as if we used the First Fit method to place these virtual machines. Since First Fit guarantees that the number of bin used will be no more than 1.7 times of the optimal solution plus 1 [14], we can be certain that our solution also gives the same level of performance guarantees. In addition, we show that the cost of relocation in our algorithm is bounded, so that we will not spend a large amount of energy in relocating virtual machines, which may take away the benefits of energy saving from server consolidation.
We also conduct simulations and compare our algorithm with other algorithms of relocation, including a modified First Fit method [14] and Best Fit [5] method.. The experiment results indicate that our consolidation algorithm uses only slightly more servers than the previous algorithms, but dramatically reduces the number of relocation and the extra energy needed for relocation. This suggests an interesting trade-off between server consolidation and relocation cost. The administrator of a cloud system can apply different server consolidating strategies to cope with the hardware cost characteristics on different cloud systems.
The contributions of this paper are as follow. • A new server consolidation algorithm that guarantees
server consolidation with bounded relocation costs. • A detailed analysis on the complexity of the server
consolidation problem, and a upper bound on the cost of relocation. • A set of experiments that compare the performance of proposed algorithm and other bin packing algorithms from the literature.
The rest of the paper is organized as follows. Section II describes related works. Section III describes the system model. Section IV describes the algorithm we propose and other comparing algorithms used in experiments. Section V gives analysis of our algorithm. Section VI describes the experiment results, and Section VII summaries our contribution and suggests possible future extensions.

II. RELATED WORK
Data centers provide essential computing power for the operations of business, scientific organizations, and academic institutes. However, recent data centers consume significant amount of energy to sustain the system. As energy consumption and associated costs become increasingly
significant, energy management in data center becomes more and more important. As a result, researchers have been investigating mechanism for reducing resource requirements (e.g., number of servers) to decrease energy consumption in cloud data centers.
Server consolidation is a common method for energy optimization in cloud computing environments. There have been numerous works regarding energy conservation by server consolidation in data centers. Srikantaiah et al. [12] investigate the inter-relationship between energy consumption, resource utilization, and performance of consolidated workloads. The study reveals the energy performance tradeoffs for consolidation and shows that optimal operating points exist.
Li et al. [10] propose EnaCloud, which places applications dynamically on servers, with consideration of energy efficiency in a cloud platform. The application placement is abstracted as a bin packing problem, and an energyaware heuristic algorithm is proposed to get an appropriate solution.
Beloglazov and Buyya [3] propose a resource management policy for virtualized cloud data centers. They propose and evaluate heuristics for dynamic reallocation of virtual machines to minimize energy consumption, while providing reliable quality of services. The heuristics are based on the idea of setting upper and lower utilization thresholds for hosts and keeping total utilization of CPU by all virtual machines between these thresholds.
Liao et al. [11] use live migration to transfer loads among servers on a multi-layer ring-based overlay to reduce power consumption. Active servers are organized into 3-layer rings, and each ring consists of servers that have similar workloads within a specific load interval, so that the inner ring has the servers with the heavy loads, the outer ring has the the servers with light workloads, and the middle ring has the rest of the servers. They move servers, along the workloads at the servers, from the outer and the inner rings toward the middle ring. The idea is to reduce power consumption without affecting the performance of servers.
Hanson et al. [8] propose AMP, an autonomic manager in charge of the power states of servers. AMP is designed to work in conjunction with other autonomic managers, and is responsible for cutting excess power use and preserving the lifespan of servers it manages. AMP considers broader metrics in its decision, which may include power consumption, server lifespan, and interactions with other application managers. In contrast this paper focuses on computation power as a measurement of resources that a server can provide, and a task can consume. The computation power could be a function of standard metrics like CPU, memory, and disk storage. This focus of a single objective function enables us to analyze the complex trade-off among various standard metrics, so that we can analyze the relocation cost and the quality of consolidation simultaneously.
There are also theoretical works for the server consolidation problem in the literature. The consolidation problems in homogeneous server environments are mostly modeled as a bin packing problem. The bin packing problem is a combinatorial NP-hard problem, and several well-known approximation algorithms have been developed. Let N be the number of bins in optimal solution of a bin packing problem. Dósa and György [6] proves that the bound of a First Fit Decreasing method is 1.222N + 0.667 and this bound is tight. Xia and Tan [14] present bounds for the First Fit algorithm. They prove the bound of a First Fit method is 1.7N + 0.7, and the absolute performance ratio of First Fit is at most 1.714.
The online bin packing problem is also studied in the literature. Lee and Lee [9] give an algorithm for online bin packing with a worst-case performance ratio of less than 1.636. Babel [2] presents two online algorithms for online bin packing problems with cardinality constraints.
To achieve the goal of server consolidation in dynamic environments, we must relocate virtual machines among servers. In this paper, we focus on reducing the relocation costs introduced by relocation of virtual machines, while still guaranteeing solution quality. The relocation is to relocate virtual machines in such a way that the performance guarantee of the First Fit is still valid after relocation. Note that the First Fit method not only produces a theoretically good solution in the worst case, but also a good solution in the average case. As a result we choose to maintain a First Fit ordering when we relocate virtual machines.

III. MODEL
We model the virtual machine relocation problem in cloud computing as a modified bin packing problem. Virtual machines in the virtual machine relocation problem are treated as items in the bin packing problem. Servers in the virtual machine relocation problem are treated as bins in the bin packing problem. Each virtual machine (item) has weight no more than 1, and each server (bin) has capacity 1.

A. State of Items and Bins
A state describes the status of items, bins, and the mapping function from items to bins. We use S = {T,B, F} to denote a state as follows.
• T = {t1, . . . , tn} is the set of items, and s(t) ∈ (0, 1] is the weight of item t. • B = {b1, . . . , bm} is the set of bins. Each bin has capacity 1. For ease of notation for b ∈ B we define H(b) to be the sum of weights of items in bin b, i.e., H(b) = ∑ F (t)=b s(t). • F :T → B is a mapping function from items to bins. F (t) = b means that item t is in bin b. The function F follows capacity constraint of bins, i.e., H(b) ≤ 1, for all b ∈ B, since each bin has capacity 1.
Also for ease of notation, for a state S = {T,B, F} we define D(S) to be the ”degree of saturation” of S, i.e., D(S) = s(T )/|B|, where s(T ) = ∑t∈T s(t).

B. First Fit Possible
The First Fit method works as follows. When we pack an item set T into a bin set B using the First Fit method, we need to determine an orderings of T (denoted by T ) and an order of B (denoted by B). Then we place the first item t in T into the first bin in B that has sufficient remaining capacity to accommodate t, and remove t from T . We repeat this process until T becomes empty.
We define a state S = {T,B, F} be “First Fit possible” if it could be the result of a First Fit placement, i.e., we can find a way to order items and bins in T and B so that the resulting mapping from First Fit is as same as F . For ease of presentation we define a condition that describes this fact.
Definition 1: A state S = {T,B, F} is First Fit possible if there exist an ordering T of items in T , and an ordering B of bins in B, such that if we use the First Fit method to place items in T to bins in B, the resulting mapping function F ′ will be as same as F .
If a state S = {T,B, F} is First Fit possible, then we can apply the approximation bound of First Fit on S, as in the following theorem.
Theorem 1: [14] If a state S = {T,B, F} is First Fit possible, than |B| ≤ 1.7OPT (T ) + 0.7, where OPT (T ) is the minimal number of bins that all items in T can be packed into.

C. Relocation Problem
A relocation is a transition from a state S = {T,B, F} to a new state S′ = {T,B, F ′}, by changing the mapping function from F to F ′. That is, we will relocate some items in T to their new destination bins.
Relocating items to new destination bins incurs relocation costs. We assume that the cost of relocating an item t is s(t), the weight of t. In the context of server consolidation, the relocation cost of a virtual machine is usually proportional to its resource requirement, e.g., CPU, memory, etc. The more resources a virtual machine requires, the more cost to relocate it. In addition, if a item t is relocated more than once, the relocation cost of t should be multiplied by the times of relocation. In practice each relocation of a virtual machine incurs a separate cost, i.e., to save, transfer, and restore the virtual machines, therefore we should consider each relocation separately.
Now we formulate the relocation problem as follows. For a given state S = {T,B, F}, we want to relocate the items with minimal relocation cost, so that the new resulting state S′ = {T,B, F ′} becomes First Fit possible.
We give a summary of notations in our problem model in table I.

IV. ALGORITHMS
We now describe our relocating algorithm. The algorithm works in phases. We use a set G to denote those bins that have not been packed, and initially every bin is in G. In each phase we remove a bin from G and pack it. We repeat this process until every bin is packed or becomes empty.
The packing is as follows. In each phase we remove and pack the bin b that has the highest weight in G. We do so by checking all items in other bins in G to see if they can fit into b. If we find any item t that can be added into b, we add t to b. We repeat this process until no such t can be found. During packing some bins might become empty. These empty bins are removed from G.
The intuition of our algorithm is as follows. By relocating items toward bins that have large weights, the amount of relocation can be reduced. That is, we do not relocate items out of b, which has the highest weight in G, so the choice of bin to pack is consistent with our intuition. Also note that any item will be relocated at most once in our algorithm, since once an item is relocated, it will be in a bin not in G, and we never relocate items out of a bin not in G.
Because of the intuition of choosing the Heaviest bin in each phase, we call this algorithm as “Heaviest First” relocation method. The pseudo code of Heaviest First relocation method is in Algorithm 1.

A. Algorithms for Comparison
We also describe the algorithms we used for comparison purpose. Note that we need to modify them to fit into the context of dynamic relocation, not static assignment, as they originally designed for in the bin packing model.
1) Naive First Fit: Naive First Fit [14] algorithm first orders bins arbitrarily, and then processes bins in this order. For each bin b, Naive First Fit checks every item t in b to see if t can be relocated to any previous bin in the ordering. If so, Naive First Fit will relocate t to the first bin that can accommodate t. Pseudo code of Naive First Fit is in Algorithm 2
2) Best Fit: The Best Fit [5] algorithm is similar to the Naive First Fit algorithm. However, when there are multiple previous bins that can accommodate t, the Best Fit method will choose the one with the least remaining capacity. That
Algorithm 1 Heaviest First Relocation Method 1: Place all bins into G 2: while there are bins in G do 3: choose the bin b in G that has the highest weight 4: for every bin b′ in G other than b do 5: for each item t in b′ do 6: if t could be added into b then 7: relocate t from b′ to b 8: end if 9: end for 10: if b′ becomes empty then 11: remove b′ from G 12: end if 13: end for 14: remove b from G 15: end while
Algorithm 2 Modified First Fit method for Relocating Problem
1: Choose an arbitrary ordering B of bins 2: for each bin b in B do 3: for each item t in b do 4: if t could be added into any non-empty bin that appears before b in B then 5: relocate t from b to the first non-empty bin that can accommodate t 6: end if 7: end for 8: end for
is, it will choose the bin that Best Fit item t. Pseudo code of Best Fit is in Algorithm 3
Algorithm 3 Modified Best Fit method for Relocating Problem
1: Choose an arbitrary ordering B of bins 2: for each bin b in B do 3: for each item t in b do 4: if t could be added into any non-empty bin that appears before b in B then 5: choose the bin b′ that has heaviest weight among
those that can accommodate t and appear before b in B
6: relocate t from b to b′ 7: end if 8: end for 9: end for

V. ANALYSIS
This section describes the property of the First Fit method, verifies that Heaviest First relocation method produces First Fit possible state, and analyzes the relocation cost.

A. Witness of First Fit
To verify that a state S = {T,B, F} is First Fit possible, it is necessary to find an ordering of bins (B), as in Definition 1. We define such an ordering of bins B as a witness to the state S. It is now easy to verify whether a state S is First Fit possible – we just need to find a witness B for S, as suggested in the following theorem.
Theorem 2: A state S = {T,B, F} is First Fit possible if and only if there exist an witness B = (b′1, . . . , b′m), i.e., an ordering of B, such that every bin b does not have enough remaining capacity to accommodate any item in a bin that appears later than b in B.
Formally let t be an item in bin b′j , i.e., F (t) = b ′ j . Then
for any bin b′i where i < j, we have Equation 1.
s(t) +H(b′i) > 1, F (t) = b ′ j, i < j (1)
Proof: We first prove the if direction. If there exists a witness B = (b′1, . . . , b′m) that satisfies inequality 1, we can generate an ordering T of T by putting items in b′1 at the front of T , then append items in b′2 to T , and so on. It is easy to prove by an induction on the number of bins that when we apply the First Fit method on B and T , the resulting mapping will be the same as F . As a result S is First Fit possible.
The induction works as follows. Consider those items t with F (t) = b′1. After applying First Fit on T and B, all items will be in b′1 since the sum of their wights is no more than 1, the capacity of b′1.
From the induction hypothesis, the mapping after applying the First Fit method on T and B is still consistent with F for items in b′k with k ≤ i. Now consider the items in bi+1. None of them can fit into a previous bin because of Equation 1. The sum of their weight is no more than 1 since they were taken from bi+1, so they will go to bi+1, as suggested by F . The induction completes.
Now we prove the only if direction by a contradiction. If S is generated from the First Fit method, but Equation 1 is invalid. That is, we can find i < j such that s(t)+H(b′i) ≤ 1 and F (t) = b′j . This could not happen in a First Fit method because t would have been placed into b′i, not b ′ j .

B. Correctness of Heaviest First
We now prove that the resulting state of Heaviest First relocation method is First Fit possible.
Theorem 3: The resulting state of Heaviest First relocation method is First Fit possible.
Proof: Let B = (b′1, . . . , b′m) be the ordering of bins that was chosen by Heaviest First Relocation Method. The i-th phase ends only after we have checked all remaining items in G, while try to filling the remaining capacity of bin b′i, so Inequality 1 holds. By theorem 2 the resulting state from Heaviest First relocation method is First Fit possible.

C. Analysis of Relocation Cost
Let S and S′ be the input and output states of Heaviest First relocation method.
We now classify the bins in S into three categories according to the number of steady items. A steady item is one that were not relocated by Heaviest First relocation method. For ease of notation, we use N1, N2, and N3 to denote the number of bins in Group 1, 2 and 3 respectively.
• Group 1 Bins that contain at least 12 steady items. • Group 2 Bins that contain less than 12 steady items. • Group 3 Bins that become empty after Heaviest First
relocation method.
Figure 1 illustrate three categories of bins. Dark areas indicate steady items, light gray areas indicate the remaining capacity for each bin, and white bins are those that were eliminated by Heaviest First relocation method.
We first describe a lemma about the relationship between N2 and N3. This lemma will be used in analysis of relocation cost incurred by Heaviest First relocation method later.
Lemma 1: For any resulting state of Heaviest First relocation method, the number of bins in Group 3 is at least the number of bins in Group 2 minus 1, i.e., N3 ≥ N2 − 1.
Proof: Without lose of generality let B = (b1, . . . , bm) be the order by which bins were chosen from G to pack by Heaviest First relocation method.
We prove the lemma by finding a matching category 3 bin for every category 2 bin. Let bin bi be a group 2 bin chosen in the i-th iteration of Heaviest First relocation method. Since bi is the bin having the heaviest weight in G at the beginning of the i-th phase, we can find a bin bj such that j > i and H(bi) ≥ H(bj), under the condition that i is not the last bin. Note that there are only steady items in bin bi at the beginning of phase i, since items was never relocated into bi before. Also Since bi is in group 2, H(bi) is less than 12 by definition. We conclude that both H(bi) and H(bj) are less than 12 since H(bi) ≥ H(bj). We then
conclude that H(bi)+H(bj) ≤ 1, which means all items in bj will be relocated into bi, and bj will become empty. This makes bj a categories 3 bin, just the matching category 3 bin we are looking for for bin bi.
Now every category 2 bin, except the last one, can find a different matching category 3 bin, and Theorem 1 follows.
We now analyze the relocation cost incurred by Heaviest First relocation method.
Theorem 4: The total relocation cost for Heaviest First relocation method to relocate a state S = {T,B, F} is bounded by |B|2 .
Proof: We first consider the set of relocated items that were relocated into category 1 bins, and we use R1 to denote these items. Since by definition the weight of steady items in each category 1 bin is at least 12 , the total cost for relocating items in R1 is at most N12 .
Now we consider the set of relocated items that were relocated into category 2 bins. Note that we do not need to consider the relocation cost into category 3 bins since no items will be relocated into them. We use R2 to denote these items that were relocated into category 2 bins, and use X to denote the total cost of relocating items in R2.
From Lemma 1 N3 ≥ N2 − 1. We consider two cases of N3. The first case is when N3 ≥ N2, it is obvious that X ≤ N2+N3
2 since X is at most N2 in this case. The second case is when N3 = N2− 1, there will be no items relocated into the last category 2 bin, otherwise N3 should be at least N2. We conclude that X ≤ N2− 1, which implies X ≤ N2+N32 , given the assumption that N3 = N2 − 1,.
Combining the cost analysis of R1 and R2, we conclude that the total relocation size is bounded by N1+N2+N32 =|B| 2 , The theorem follows.
Corollary 1: When applying Heaviest First relocation method to relocate a state S = {T,B, F}, the ratio between relocation cost and total weight of items is less than or equal to 12D(S) .
Proof: Let the relocation cost be C, then the ratio between relocation cost and total weight of item is Cs(T ) . By definition D(S) = s(T )/|B|, and by theorem 4 C ≤ |B|2 . Thus, Cs(T ) ≤ |B|/2 D(S)×|B| = 1 2D(S) .

VI. EXPERIMENTS
We conduct experiments to compare Heaviest First relocation method with other algorithms in the literature. The algorithms we used in the comparison are well-known approximation algorithms for bin packing problem, including Naive First Fit [14] algorithm and Best Fit [5] algorithm. However, we need to modify them to fit into the context of dynamic relocation, not static assignment, as in their original bin packing model.

A. Experiment Setup
We set the experiment parameters as follow. The number of bins is from 10 to 500. The weight of each item is randomly chosen from 0.01 to 1. Each bin contains items whose total weight is from 0.5 to 1.
We implemented Heaviest First relocation method, Naive First Fit, and Best Fit algorithms. For each algorithm we record the number of bins used to accommodate all the items, and the relocation cost incurred. We measure these performance data by running 100 different cases for each number of bins, and take the average of the quantities we wish to measure. In addition, for each number of bins we also measure the maximum ratio between the relocation cost and the total bin capacity among these 100 test cases.

B. Experiment Results
Figure 2 shows the number of bins used by all three algorithms under different number of bins, and Figure 3 shows the relocation cost. We observe from Figure 2 and Figure 3 that Heaviest First Relocation method uses slightly more bins but incurs much less relocation cost when compared with other algorithms. More precisely, Heaviest First relocation method uses only 1% more bins, but reduces the relocation costs by 58% when compared with Naive First Fit algorithm, and 48% with Best Fit algorithm. Note that the relocation cost incurred in Heaviest First Relocation method is much less than the theoretical bound provided in Section V. The reason is that we overestimate the amount of relocation in the analysis of Section V, and the actual amount of relocation found from simulation is much less than the worst-case bound in theoretical analysis.
Figure 4 and Figure 5 show the average and the maximum ratio of relocation cost to the number of bins respectively. The average ratio is more stable as the number of bins increase than the maximum ratio. The ratio is about 15% in Heaviest First relocation method, 29% in Best Fit algorithm, and 36% in Naive First Fit algorithms.
Theorem 4 states that the ratio between the relocation cost and the number of bins in Heaviest First relocation method is at most 50%. However, in practice the ratio is much less than the theoretical bound. As Figure 4 and Figure 5 suggest, the maximum and the average ratio is about 15% in average, and 20% in maximum.
The experiment results suggest an interesting trade-off
between relocation cost and level of consolidations. If a high level of consolidation is required, we have to pay more relocations. On the other hand, if the cost of relocations is more important, Heaviest First relocation method can trade a small quality of consolidation for a large reduction in relocation costs.

VII. CONCLUSIONS
In this paper, we model the problem of relocating virtual machines for consolidation. We propose a Heaviest First relocation method for scheduling the relocations of virtual machines as a solution of the relocation problem. We also give an analysis of Heaviest First relocation method, prove that there is a theoretical bound of relocation cost in Heaviest First relocation method.
We implements Heaviest First relocation method in a simulating environment, and compare it to some other algorithms. As the simulating result shows, Heaviest First relocation method can trades a little quality of consolidation for a large amount of relocation cost.
In the future we would like to improve the theoretical bounds in this paper, or prove that these bound are tight. We also would like to extend the bounds to other models. For example, we may be able to improve the bounds if the state S was originally first fit possible, but some items were taken out and some items were added. Now is it possible to relocate only a few items in S so that it becomes first fit possible again? This problem is different from the one in this paper in which the initial state could be any state. It would be very interesting if one can relate the amount of added/removed items with the relocation efforts to maintain first fit possible state.

References
[1]L. Babel,B. Chen,H. Kellerer,V. KotovAlgorithms for on-line bin-packing problems with cardinality constraintsDiscrete Applied Mathematics,2004
[2]A. Beloglazov,R. uyyaEnergy efficient resource management in virtualized cloud data centers. Cluster Computing and the GridIEEE International Symposium on,2010
[3]G. Chen,W. He,J. Liu,S. Nath,L. Rigas,L. Xiao,F. ZhaoEnergy-aware server provisioning and load dispatching for connection-intensive internet servicesIn Proceedings of the 5th USENIX Symposium on Networked Systems Design and Implementation,2008
[4]E.G. Coffman,Jr.,M.R. Garey,D.S. JohnsonApproximation algorithms for bin packing: a survey, pages 46–93PWS Publishing Co.,1997
[5]G. DósaThe tight bound of first fit decreasing binpacking algorithm is FFD(I) ≤ 11/9OPT (I) + 6/9Combinatorics, Algorithms, Probabilistic and Experimental Methodologies,2007
[6]M.R. Garey,D.S. JohnsonComputers and Intractability; A Guide to the Theory of NP-Completeness1990
[7]J. Hanson,I. Whalley,M. Steinder,J. KephartMultiaspect hardware management in enterprise server consolidationIn Network Operations and Management Symposium (NOMS),2010
[8]C.C. Lee,D.T. LeeA simple on-line bin-packing algorithmJ. ACM,1985
[9]B. Li,J. Li,J. Huai,T. Wo,Q. Li,L. ZhongEnacloud: An energy-saving application live placement approach for cloud computing environmentsIn Proceedings of the 2009 IEEE International Conference on Cloud Computing,2009
[10]X. Liao,L. Hu,H. JinEnergy optimization schemes in cluster with virtual machinesCluster Computing,2010
[11]S. Srikantaiah,A. Kansal,F. ZhaoEnergy aware consolidation for cloud computingIn Proceedings of the 2008 conference on Power aware computing and systems, Hot-2008
[12]V.V. VaziraniApproximation Algorithms, chapter Bin Packing, pages 74–782001
[13]B. Xia,Z. TanTighter bounds of the first fit algorithm for the bin-packing problemDiscrete Appl. Math.,2010
